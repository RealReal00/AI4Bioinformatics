{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4oB7eeTug5zb"
      },
      "source": [
        "# LAB: Multimodal Learning WSI + Genomics\n",
        "Authors:\n",
        "- Vittorio Pipoli (vittorio.pipoli@unimore.it)\n",
        "- Francesca Miccolis (francesca.miccolis@unimore.it)\n",
        "\n",
        "### Assignment Goals\n",
        "1. Familiarity with the ‚ÄúSurvival Prediction from WSI and Genomics‚Äù task\n",
        "2. Familiarity with multimodal architectures\n",
        "3. Implementation of a customised model for ‚ÄúSurvival Prediction from WSI and Genomics‚Äù\n",
        "\n",
        "### References\n",
        "1. ABMIL (paper: https://proceedings.mlr.press/v80/ilse18a/ilse18a.pdf)\n",
        "3. MCAT (paper: https://openaccess.thecvf.com/content/ICCV2021/papers/Chen_Multimodal_Co-Attention_Transformer_for_Survival_Prediction_in_Gigapixel_Whole_Slide_ICCV_2021_paper.pdf)\n",
        "2. SurvPath (paper: https://openaccess.thecvf.com/content/CVPR2024/papers/Jaume_Modeling_Dense_Multimodal_Interactions_Between_Biological_Pathways_and_Histology_for_CVPR_2024_paper.pdf)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sTV0IrGpg5zd"
      },
      "source": [
        "### install missing packages"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 23,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "collapsed": true,
        "execution": {
          "iopub.execute_input": "2024-12-13T16:55:30.143803Z",
          "iopub.status.busy": "2024-12-13T16:55:30.143541Z",
          "iopub.status.idle": "2024-12-13T16:56:11.900409Z",
          "shell.execute_reply": "2024-12-13T16:56:11.899255Z",
          "shell.execute_reply.started": "2024-12-13T16:55:30.143767Z"
        },
        "id": "oRXzaQmUg5zd",
        "outputId": "7c5d1f04-8b20-46c8-f553-0217446ad270",
        "trusted": true
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: pytorch_model_summary in c:\\users\\ricca\\venvs\\bio_inf_2\\lib\\site-packages (0.1.2)\n",
            "Requirement already satisfied: tqdm in c:\\users\\ricca\\venvs\\bio_inf_2\\lib\\site-packages (from pytorch_model_summary) (4.67.1)\n",
            "Requirement already satisfied: torch in c:\\users\\ricca\\venvs\\bio_inf_2\\lib\\site-packages (from pytorch_model_summary) (2.5.1+cu121)\n",
            "Requirement already satisfied: numpy in c:\\users\\ricca\\venvs\\bio_inf_2\\lib\\site-packages (from pytorch_model_summary) (2.0.1)\n",
            "Requirement already satisfied: filelock in c:\\users\\ricca\\venvs\\bio_inf_2\\lib\\site-packages (from torch->pytorch_model_summary) (3.13.1)\n",
            "Requirement already satisfied: typing-extensions>=4.8.0 in c:\\users\\ricca\\venvs\\bio_inf_2\\lib\\site-packages (from torch->pytorch_model_summary) (4.12.2)\n",
            "Requirement already satisfied: networkx in c:\\users\\ricca\\venvs\\bio_inf_2\\lib\\site-packages (from torch->pytorch_model_summary) (3.3)\n",
            "Requirement already satisfied: jinja2 in c:\\users\\ricca\\venvs\\bio_inf_2\\lib\\site-packages (from torch->pytorch_model_summary) (3.1.4)\n",
            "Requirement already satisfied: fsspec in c:\\users\\ricca\\venvs\\bio_inf_2\\lib\\site-packages (from torch->pytorch_model_summary) (2024.6.1)\n",
            "Requirement already satisfied: sympy==1.13.1 in c:\\users\\ricca\\venvs\\bio_inf_2\\lib\\site-packages (from torch->pytorch_model_summary) (1.13.1)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in c:\\users\\ricca\\venvs\\bio_inf_2\\lib\\site-packages (from sympy==1.13.1->torch->pytorch_model_summary) (1.3.0)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in c:\\users\\ricca\\venvs\\bio_inf_2\\lib\\site-packages (from jinja2->torch->pytorch_model_summary) (2.1.5)\n",
            "Requirement already satisfied: colorama in c:\\users\\ricca\\venvs\\bio_inf_2\\lib\\site-packages (from tqdm->pytorch_model_summary) (0.4.6)\n",
            "Requirement already satisfied: munch in c:\\users\\ricca\\venvs\\bio_inf_2\\lib\\site-packages (4.0.0)\n",
            "Requirement already satisfied: scikit-survival in c:\\users\\ricca\\venvs\\bio_inf_2\\lib\\site-packages (0.24.1)\n",
            "Requirement already satisfied: ecos in c:\\users\\ricca\\venvs\\bio_inf_2\\lib\\site-packages (from scikit-survival) (2.0.14)\n",
            "Requirement already satisfied: joblib in c:\\users\\ricca\\venvs\\bio_inf_2\\lib\\site-packages (from scikit-survival) (1.5.1)\n",
            "Requirement already satisfied: numexpr in c:\\users\\ricca\\venvs\\bio_inf_2\\lib\\site-packages (from scikit-survival) (2.10.1)\n",
            "Requirement already satisfied: numpy in c:\\users\\ricca\\venvs\\bio_inf_2\\lib\\site-packages (from scikit-survival) (2.0.1)\n",
            "Requirement already satisfied: osqp<1.0.0,>=0.6.3 in c:\\users\\ricca\\venvs\\bio_inf_2\\lib\\site-packages (from scikit-survival) (0.6.7.post3)\n",
            "Requirement already satisfied: pandas>=1.4.0 in c:\\users\\ricca\\venvs\\bio_inf_2\\lib\\site-packages (from scikit-survival) (2.3.0)\n",
            "Requirement already satisfied: scipy>=1.3.2 in c:\\users\\ricca\\venvs\\bio_inf_2\\lib\\site-packages (from scikit-survival) (1.15.3)\n",
            "Requirement already satisfied: scikit-learn<1.7,>=1.6.1 in c:\\users\\ricca\\venvs\\bio_inf_2\\lib\\site-packages (from scikit-survival) (1.6.1)\n",
            "Requirement already satisfied: qdldl in c:\\users\\ricca\\venvs\\bio_inf_2\\lib\\site-packages (from osqp<1.0.0,>=0.6.3->scikit-survival) (0.1.7.post5)\n",
            "Requirement already satisfied: threadpoolctl>=3.1.0 in c:\\users\\ricca\\venvs\\bio_inf_2\\lib\\site-packages (from scikit-learn<1.7,>=1.6.1->scikit-survival) (3.6.0)\n",
            "Requirement already satisfied: python-dateutil>=2.8.2 in c:\\users\\ricca\\venvs\\bio_inf_2\\lib\\site-packages (from pandas>=1.4.0->scikit-survival) (2.9.0.post0)\n",
            "Requirement already satisfied: pytz>=2020.1 in c:\\users\\ricca\\venvs\\bio_inf_2\\lib\\site-packages (from pandas>=1.4.0->scikit-survival) (2025.2)\n",
            "Requirement already satisfied: tzdata>=2022.7 in c:\\users\\ricca\\venvs\\bio_inf_2\\lib\\site-packages (from pandas>=1.4.0->scikit-survival) (2025.2)\n",
            "Requirement already satisfied: six>=1.5 in c:\\users\\ricca\\venvs\\bio_inf_2\\lib\\site-packages (from python-dateutil>=2.8.2->pandas>=1.4.0->scikit-survival) (1.17.0)\n",
            "Requirement already satisfied: lifelines in c:\\users\\ricca\\venvs\\bio_inf_2\\lib\\site-packages (0.30.0)\n",
            "Requirement already satisfied: numpy>=1.14.0 in c:\\users\\ricca\\venvs\\bio_inf_2\\lib\\site-packages (from lifelines) (2.0.1)\n",
            "Requirement already satisfied: scipy>=1.7.0 in c:\\users\\ricca\\venvs\\bio_inf_2\\lib\\site-packages (from lifelines) (1.15.3)\n",
            "Requirement already satisfied: pandas>=2.1 in c:\\users\\ricca\\venvs\\bio_inf_2\\lib\\site-packages (from lifelines) (2.3.0)\n",
            "Requirement already satisfied: matplotlib>=3.0 in c:\\users\\ricca\\venvs\\bio_inf_2\\lib\\site-packages (from lifelines) (3.10.3)\n",
            "Requirement already satisfied: autograd>=1.5 in c:\\users\\ricca\\venvs\\bio_inf_2\\lib\\site-packages (from lifelines) (1.8.0)\n",
            "Requirement already satisfied: autograd-gamma>=0.3 in c:\\users\\ricca\\venvs\\bio_inf_2\\lib\\site-packages (from lifelines) (0.5.0)\n",
            "Requirement already satisfied: formulaic>=0.2.2 in c:\\users\\ricca\\venvs\\bio_inf_2\\lib\\site-packages (from lifelines) (1.1.1)\n",
            "Requirement already satisfied: interface-meta>=1.2.0 in c:\\users\\ricca\\venvs\\bio_inf_2\\lib\\site-packages (from formulaic>=0.2.2->lifelines) (1.3.0)\n",
            "Requirement already satisfied: typing-extensions>=4.2.0 in c:\\users\\ricca\\venvs\\bio_inf_2\\lib\\site-packages (from formulaic>=0.2.2->lifelines) (4.12.2)\n",
            "Requirement already satisfied: wrapt>=1.0 in c:\\users\\ricca\\venvs\\bio_inf_2\\lib\\site-packages (from formulaic>=0.2.2->lifelines) (1.17.2)\n",
            "Requirement already satisfied: contourpy>=1.0.1 in c:\\users\\ricca\\venvs\\bio_inf_2\\lib\\site-packages (from matplotlib>=3.0->lifelines) (1.3.2)\n",
            "Requirement already satisfied: cycler>=0.10 in c:\\users\\ricca\\venvs\\bio_inf_2\\lib\\site-packages (from matplotlib>=3.0->lifelines) (0.12.1)\n",
            "Requirement already satisfied: fonttools>=4.22.0 in c:\\users\\ricca\\venvs\\bio_inf_2\\lib\\site-packages (from matplotlib>=3.0->lifelines) (4.58.4)\n",
            "Requirement already satisfied: kiwisolver>=1.3.1 in c:\\users\\ricca\\venvs\\bio_inf_2\\lib\\site-packages (from matplotlib>=3.0->lifelines) (1.4.8)\n",
            "Requirement already satisfied: packaging>=20.0 in c:\\users\\ricca\\venvs\\bio_inf_2\\lib\\site-packages (from matplotlib>=3.0->lifelines) (25.0)\n",
            "Requirement already satisfied: pillow>=8 in c:\\users\\ricca\\venvs\\bio_inf_2\\lib\\site-packages (from matplotlib>=3.0->lifelines) (11.0.0)\n",
            "Requirement already satisfied: pyparsing>=2.3.1 in c:\\users\\ricca\\venvs\\bio_inf_2\\lib\\site-packages (from matplotlib>=3.0->lifelines) (3.2.3)\n",
            "Requirement already satisfied: python-dateutil>=2.7 in c:\\users\\ricca\\venvs\\bio_inf_2\\lib\\site-packages (from matplotlib>=3.0->lifelines) (2.9.0.post0)\n",
            "Requirement already satisfied: pytz>=2020.1 in c:\\users\\ricca\\venvs\\bio_inf_2\\lib\\site-packages (from pandas>=2.1->lifelines) (2025.2)\n",
            "Requirement already satisfied: tzdata>=2022.7 in c:\\users\\ricca\\venvs\\bio_inf_2\\lib\\site-packages (from pandas>=2.1->lifelines) (2025.2)\n",
            "Requirement already satisfied: six>=1.5 in c:\\users\\ricca\\venvs\\bio_inf_2\\lib\\site-packages (from python-dateutil>=2.7->matplotlib>=3.0->lifelines) (1.17.0)\n"
          ]
        }
      ],
      "source": [
        "!pip install pytorch_model_summary\n",
        "!pip install munch\n",
        "!pip install scikit-survival\n",
        "!pip install lifelines"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 24,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "True NVIDIA GeForce RTX 4060 Laptop GPU\n"
          ]
        }
      ],
      "source": [
        "import torch\n",
        "\n",
        "cuda_available = torch.cuda.is_available()\n",
        "gpu_name = torch.cuda.get_device_name(0) if cuda_available else \"Nessuna GPU CUDA trovata\"\n",
        "\n",
        "print(cuda_available, gpu_name)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 25,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Torch con CUDA: 12.1\n"
          ]
        }
      ],
      "source": [
        "import torch\n",
        "print(\"Torch con CUDA:\", torch.version.cuda)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PH2JaOtdg5zd"
      },
      "source": [
        "### import packages"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 26,
      "metadata": {
        "execution": {
          "iopub.execute_input": "2024-12-13T16:56:11.902959Z",
          "iopub.status.busy": "2024-12-13T16:56:11.902566Z",
          "iopub.status.idle": "2024-12-13T16:56:17.180251Z",
          "shell.execute_reply": "2024-12-13T16:56:17.179585Z",
          "shell.execute_reply.started": "2024-12-13T16:56:11.902921Z"
        },
        "id": "HZwrY34og5ze",
        "trusted": true
      },
      "outputs": [],
      "source": [
        "import os\n",
        "import torch\n",
        "from torch import nn\n",
        "import torch.optim as optim\n",
        "from torch.backends import cudnn\n",
        "import torch.nn.init as init\n",
        "from pytorch_model_summary import summary\n",
        "import torch.nn.functional as F\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "from torch.utils.data import Dataset, DataLoader, Subset\n",
        "import time\n",
        "import logging\n",
        "from tqdm import tqdm\n",
        "import math\n",
        "from scipy import stats\n",
        "import matplotlib\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "from munch import Munch\n",
        "from sksurv.metrics import concordance_index_censored\n",
        "from copy import deepcopy\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from lifelines import KaplanMeierFitter\n",
        "from sklearn.metrics import roc_auc_score, confusion_matrix, f1_score\n",
        "import random\n",
        "from lifelines.statistics import logrank_test"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 27,
      "metadata": {
        "execution": {
          "iopub.execute_input": "2024-12-13T16:56:46.678219Z",
          "iopub.status.busy": "2024-12-13T16:56:46.677868Z",
          "iopub.status.idle": "2024-12-13T16:56:46.684734Z",
          "shell.execute_reply": "2024-12-13T16:56:46.683837Z",
          "shell.execute_reply.started": "2024-12-13T16:56:46.678187Z"
        },
        "id": "rZpJaqxQg5ze",
        "trusted": true
      },
      "outputs": [],
      "source": [
        "def setup(seed):\n",
        "    os.environ['PYTHONHASHSEED'] = str(seed)\n",
        "    random.seed(seed)\n",
        "    np.random.seed(seed)\n",
        "    torch.manual_seed(seed)\n",
        "    torch.cuda.manual_seed(seed)  # If using CUDA.\n",
        "    torch.cuda.manual_seed_all(seed)  # If using multi-GPU.\n",
        "    torch.backends.cudnn.benchmark = False\n",
        "    torch.backends.cudnn.deterministic = True\n",
        "### Fix random seed for reproducibility (Try different random seeds)\n",
        "SEED = 42\n",
        "setup(SEED)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WqSM4ylDg5ze"
      },
      "source": [
        "# Download Multimodal Survival Dataset (TCGA BRCA)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UWWzD7W3g5ze"
      },
      "source": [
        "### downaload takes approx. 10 to 20 minutes..."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5JMWdwrHg5zf"
      },
      "source": [
        "### Multimodal Survival Dataset Class"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "üß™ Uso nel modello\n",
        "Il modello multimodale riceve un bag di patch + profilo genico\n",
        "\n",
        "Pu√≤ usare strategie come MIL (Multiple Instance Learning) per fare predizioni a livello di paziente\n",
        "\n",
        "üß† Il modello multimodale usa questo .pt come input:\n",
        "Input immagine = tutte le patch della slide (caricate dal .pt)\n",
        "\n",
        "Input genomico = profilo genico dal .csv\n",
        "\n",
        "Output = predizione (es. rischio, tempo di sopravvivenza, classe, ecc.)\n",
        "\n",
        "Ogni file .pt in pt_files/ rappresenta una slide istopatologica WSI ed √® trattato come un bag di patch nel contesto di Multiple Instance Learning (MIL)."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 28,
      "metadata": {},
      "outputs": [],
      "source": [
        "#cella che userai per caricare i dati e usarli\n",
        "TCGA_BRCA_dataset_config = {\n",
        "    \"name\": \"TCGA_BRCA\",\n",
        "    \"parameters\": {\n",
        "        \"dataframe_path\": \"G:/Il mio Drive/datasets/LAB_WSI_Genomics/TCGA_BRCA/TCGA_BRCA_labels_multimodal.tsv\",\n",
        "        \"pt_files_path\": \"G:/Il mio Drive/datasets/LAB_WSI_Genomics/TCGA_BRCA/Data/wsi/features_UNI/pt_files\",\n",
        "        \"genomics_path\": \"G:/Il mio Drive/datasets/LAB_WSI_Genomics/TCGA_BRCA/Data/genomic/tpm_unstranded.csv\",\n",
        "        \"tissue_type_filter\": [],\n",
        "        \"label_name\": \"FUT\",\n",
        "        \"censorships_name\": \"Survival\",\n",
        "        \"case_id_name\": \"case_id\",\n",
        "        \"slide_id_name\": \"slide_id\",\n",
        "    }\n",
        "}\n",
        "TCGA_BRCA_dataset_config = Munch.fromDict(TCGA_BRCA_dataset_config)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cjr2KHYsnxKY"
      },
      "source": [
        "SOTTO HAI:\n",
        "üî¨ 1. Prima tabella: Dati di espressione genica\n",
        "üìç Contenuto:\n",
        "\n",
        "Riga = paziente (ID tipo TCGA-XX-XXXX)\n",
        "\n",
        "Colonna = gene (es. ENSG00000000003.15)\n",
        "\n",
        "Valori = livello di espressione (normalizzato, log(x + 0.1))\n",
        "\n",
        "üìå Fonte: file tipo tpm_unstranded.csv\n",
        "üìå Usato per: fornire il modulo genomico (input numerico al modello)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3LvD3SqGg5zg"
      },
      "source": [
        "### inspect genomic data"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "W2WQSsfIzbC1"
      },
      "source": [
        "üîç Cosa significa FPKM?\n",
        "FPKM sta per Fragments Per Kilobase of transcript per Million mapped reads. √à una misura della quantit√† relativa di espressione di un gene in un campione. Viene usata per normalizzare i dati di espressione genica, tenendo conto di:\n",
        "\n",
        "La lunghezza del gene o trascritto (pi√π √® lungo, pi√π frammenti pu√≤ generare),\n",
        "\n",
        "Il numero totale di frammenti sequenziati (per confrontabilit√† tra campioni con diversa profondit√† di sequenziamento).\n",
        "\n",
        "üßÆ Formula FPKM\n",
        "FPKM\n",
        "=\n",
        "Number¬†of¬†fragments\n",
        "Length¬†of¬†transcript¬†(kb)\n",
        "√ó\n",
        "Total¬†fragments¬†(millions)\n",
        "FPKM=\n",
        "Length¬†of¬†transcript¬†(kb)√óTotal¬†fragments¬†(millions)\n",
        "Number¬†of¬†fragments\n",
        "‚Äã\n",
        "\n",
        "üìÅ Sul file fpkm_uq_unstranded.csv\n",
        "Basandoci sul nome:\n",
        "\n",
        "fpkm: contiene valori FPKM\n",
        "\n",
        "uq: sta per Upper Quartile normalization, una variante che migliora la comparabilit√† tra campioni\n",
        "\n",
        "unstranded: indica che non √® stata considerata la strand information (cio√® il filamento di DNA da cui l'RNA √® stato trascritto)\n",
        "\n",
        "0 --> gene non espresso\n",
        "0.01-1 bassa espressione\n",
        "1-10 espressione moderata\n",
        ">10 alta espressione\n",
        ">100 molto alta espressione"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 29,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 666
        },
        "id": "M9-I7ayughYE",
        "outputId": "e69f5b63-1170-461a-fcdc-689da528ddbb"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>ENSG00000000003.15</th>\n",
              "      <th>ENSG00000000005.6</th>\n",
              "      <th>ENSG00000000419.13</th>\n",
              "      <th>ENSG00000000457.14</th>\n",
              "      <th>ENSG00000000460.17</th>\n",
              "      <th>ENSG00000000938.13</th>\n",
              "      <th>ENSG00000000971.16</th>\n",
              "      <th>ENSG00000001036.14</th>\n",
              "      <th>ENSG00000001084.13</th>\n",
              "      <th>ENSG00000001167.14</th>\n",
              "      <th>...</th>\n",
              "      <th>ENSG00000288649.1</th>\n",
              "      <th>ENSG00000288654.1</th>\n",
              "      <th>ENSG00000288656.1</th>\n",
              "      <th>ENSG00000288658.1</th>\n",
              "      <th>ENSG00000288660.1</th>\n",
              "      <th>ENSG00000288661.1</th>\n",
              "      <th>ENSG00000288669.1</th>\n",
              "      <th>ENSG00000288671.1</th>\n",
              "      <th>ENSG00000288674.1</th>\n",
              "      <th>ENSG00000288675.1</th>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Unnamed: 0</th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>TCGA-5L-AAT0</th>\n",
              "      <td>18.8059</td>\n",
              "      <td>0.1004</td>\n",
              "      <td>22.5429</td>\n",
              "      <td>2.9239</td>\n",
              "      <td>1.2015</td>\n",
              "      <td>3.2076</td>\n",
              "      <td>6.4220</td>\n",
              "      <td>11.5534</td>\n",
              "      <td>2.7377</td>\n",
              "      <td>11.2851</td>\n",
              "      <td>...</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0000</td>\n",
              "      <td>0.0100</td>\n",
              "      <td>0.0408</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0154</td>\n",
              "      <td>0.1764</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>TCGA-A2-A04U</th>\n",
              "      <td>28.1036</td>\n",
              "      <td>0.3642</td>\n",
              "      <td>81.6555</td>\n",
              "      <td>1.9173</td>\n",
              "      <td>1.0850</td>\n",
              "      <td>1.1046</td>\n",
              "      <td>2.0680</td>\n",
              "      <td>12.8385</td>\n",
              "      <td>2.3671</td>\n",
              "      <td>14.9513</td>\n",
              "      <td>...</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0000</td>\n",
              "      <td>1.2410</td>\n",
              "      <td>0.0000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0363</td>\n",
              "      <td>0.1440</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>TCGA-A7-A13D</th>\n",
              "      <td>11.1499</td>\n",
              "      <td>0.0185</td>\n",
              "      <td>44.3259</td>\n",
              "      <td>2.9034</td>\n",
              "      <td>4.6663</td>\n",
              "      <td>1.2610</td>\n",
              "      <td>5.3923</td>\n",
              "      <td>13.8049</td>\n",
              "      <td>2.4426</td>\n",
              "      <td>17.0157</td>\n",
              "      <td>...</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0000</td>\n",
              "      <td>0.0921</td>\n",
              "      <td>0.0000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0142</td>\n",
              "      <td>0.0000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>TCGA-BH-A201</th>\n",
              "      <td>11.9087</td>\n",
              "      <td>0.3088</td>\n",
              "      <td>31.9381</td>\n",
              "      <td>4.1172</td>\n",
              "      <td>2.2652</td>\n",
              "      <td>3.1944</td>\n",
              "      <td>8.2867</td>\n",
              "      <td>11.7111</td>\n",
              "      <td>4.3585</td>\n",
              "      <td>15.1350</td>\n",
              "      <td>...</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0000</td>\n",
              "      <td>0.0410</td>\n",
              "      <td>0.0000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0174</td>\n",
              "      <td>0.2532</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>TCGA-BH-A0H6</th>\n",
              "      <td>24.3593</td>\n",
              "      <td>0.3923</td>\n",
              "      <td>24.9951</td>\n",
              "      <td>2.6949</td>\n",
              "      <td>1.0033</td>\n",
              "      <td>1.4877</td>\n",
              "      <td>3.9207</td>\n",
              "      <td>16.9523</td>\n",
              "      <td>6.8670</td>\n",
              "      <td>12.9826</td>\n",
              "      <td>...</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0051</td>\n",
              "      <td>0.0135</td>\n",
              "      <td>0.1373</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0145</td>\n",
              "      <td>0.1902</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>TCGA-A8-A07O</th>\n",
              "      <td>11.5273</td>\n",
              "      <td>0.0095</td>\n",
              "      <td>32.9329</td>\n",
              "      <td>4.1108</td>\n",
              "      <td>5.8366</td>\n",
              "      <td>2.2484</td>\n",
              "      <td>2.9732</td>\n",
              "      <td>9.1498</td>\n",
              "      <td>5.0707</td>\n",
              "      <td>16.4606</td>\n",
              "      <td>...</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0000</td>\n",
              "      <td>0.5590</td>\n",
              "      <td>0.0193</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0117</td>\n",
              "      <td>0.1004</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>TCGA-A2-A1FV</th>\n",
              "      <td>6.8917</td>\n",
              "      <td>0.7166</td>\n",
              "      <td>22.6665</td>\n",
              "      <td>9.9951</td>\n",
              "      <td>3.1676</td>\n",
              "      <td>0.8495</td>\n",
              "      <td>5.2142</td>\n",
              "      <td>11.9031</td>\n",
              "      <td>4.8050</td>\n",
              "      <td>19.4060</td>\n",
              "      <td>...</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0183</td>\n",
              "      <td>0.0193</td>\n",
              "      <td>0.0000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0072</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0119</td>\n",
              "      <td>0.2382</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>TCGA-C8-A275</th>\n",
              "      <td>9.0502</td>\n",
              "      <td>0.0975</td>\n",
              "      <td>35.7034</td>\n",
              "      <td>8.4364</td>\n",
              "      <td>3.4478</td>\n",
              "      <td>7.8937</td>\n",
              "      <td>8.9764</td>\n",
              "      <td>13.0280</td>\n",
              "      <td>3.8271</td>\n",
              "      <td>13.8441</td>\n",
              "      <td>...</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0037</td>\n",
              "      <td>0.0291</td>\n",
              "      <td>0.0000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0060</td>\n",
              "      <td>0.0856</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>TCGA-A2-A0CS</th>\n",
              "      <td>10.7295</td>\n",
              "      <td>0.1443</td>\n",
              "      <td>36.7334</td>\n",
              "      <td>3.8794</td>\n",
              "      <td>1.7724</td>\n",
              "      <td>2.1768</td>\n",
              "      <td>6.0752</td>\n",
              "      <td>17.3218</td>\n",
              "      <td>4.4773</td>\n",
              "      <td>10.4725</td>\n",
              "      <td>...</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0000</td>\n",
              "      <td>0.1755</td>\n",
              "      <td>0.0326</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0123</td>\n",
              "      <td>0.1550</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>TCGA-AR-A0TU</th>\n",
              "      <td>31.1416</td>\n",
              "      <td>0.1070</td>\n",
              "      <td>34.2998</td>\n",
              "      <td>4.1399</td>\n",
              "      <td>6.2150</td>\n",
              "      <td>4.9040</td>\n",
              "      <td>1.4568</td>\n",
              "      <td>9.8791</td>\n",
              "      <td>6.9135</td>\n",
              "      <td>16.5539</td>\n",
              "      <td>...</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0000</td>\n",
              "      <td>0.1810</td>\n",
              "      <td>0.0217</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0033</td>\n",
              "      <td>0.1410</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>1059 rows √ó 19962 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "              ENSG00000000003.15  ENSG00000000005.6  ENSG00000000419.13  \\\n",
              "Unnamed: 0                                                                \n",
              "TCGA-5L-AAT0             18.8059             0.1004             22.5429   \n",
              "TCGA-A2-A04U             28.1036             0.3642             81.6555   \n",
              "TCGA-A7-A13D             11.1499             0.0185             44.3259   \n",
              "TCGA-BH-A201             11.9087             0.3088             31.9381   \n",
              "TCGA-BH-A0H6             24.3593             0.3923             24.9951   \n",
              "...                          ...                ...                 ...   \n",
              "TCGA-A8-A07O             11.5273             0.0095             32.9329   \n",
              "TCGA-A2-A1FV              6.8917             0.7166             22.6665   \n",
              "TCGA-C8-A275              9.0502             0.0975             35.7034   \n",
              "TCGA-A2-A0CS             10.7295             0.1443             36.7334   \n",
              "TCGA-AR-A0TU             31.1416             0.1070             34.2998   \n",
              "\n",
              "              ENSG00000000457.14  ENSG00000000460.17  ENSG00000000938.13  \\\n",
              "Unnamed: 0                                                                 \n",
              "TCGA-5L-AAT0              2.9239              1.2015              3.2076   \n",
              "TCGA-A2-A04U              1.9173              1.0850              1.1046   \n",
              "TCGA-A7-A13D              2.9034              4.6663              1.2610   \n",
              "TCGA-BH-A201              4.1172              2.2652              3.1944   \n",
              "TCGA-BH-A0H6              2.6949              1.0033              1.4877   \n",
              "...                          ...                 ...                 ...   \n",
              "TCGA-A8-A07O              4.1108              5.8366              2.2484   \n",
              "TCGA-A2-A1FV              9.9951              3.1676              0.8495   \n",
              "TCGA-C8-A275              8.4364              3.4478              7.8937   \n",
              "TCGA-A2-A0CS              3.8794              1.7724              2.1768   \n",
              "TCGA-AR-A0TU              4.1399              6.2150              4.9040   \n",
              "\n",
              "              ENSG00000000971.16  ENSG00000001036.14  ENSG00000001084.13  \\\n",
              "Unnamed: 0                                                                 \n",
              "TCGA-5L-AAT0              6.4220             11.5534              2.7377   \n",
              "TCGA-A2-A04U              2.0680             12.8385              2.3671   \n",
              "TCGA-A7-A13D              5.3923             13.8049              2.4426   \n",
              "TCGA-BH-A201              8.2867             11.7111              4.3585   \n",
              "TCGA-BH-A0H6              3.9207             16.9523              6.8670   \n",
              "...                          ...                 ...                 ...   \n",
              "TCGA-A8-A07O              2.9732              9.1498              5.0707   \n",
              "TCGA-A2-A1FV              5.2142             11.9031              4.8050   \n",
              "TCGA-C8-A275              8.9764             13.0280              3.8271   \n",
              "TCGA-A2-A0CS              6.0752             17.3218              4.4773   \n",
              "TCGA-AR-A0TU              1.4568              9.8791              6.9135   \n",
              "\n",
              "              ENSG00000001167.14  ...  ENSG00000288649.1  ENSG00000288654.1  \\\n",
              "Unnamed: 0                        ...                                         \n",
              "TCGA-5L-AAT0             11.2851  ...                0.0                0.0   \n",
              "TCGA-A2-A04U             14.9513  ...                0.0                0.0   \n",
              "TCGA-A7-A13D             17.0157  ...                0.0                0.0   \n",
              "TCGA-BH-A201             15.1350  ...                0.0                0.0   \n",
              "TCGA-BH-A0H6             12.9826  ...                0.0                0.0   \n",
              "...                          ...  ...                ...                ...   \n",
              "TCGA-A8-A07O             16.4606  ...                0.0                0.0   \n",
              "TCGA-A2-A1FV             19.4060  ...                0.0                0.0   \n",
              "TCGA-C8-A275             13.8441  ...                0.0                0.0   \n",
              "TCGA-A2-A0CS             10.4725  ...                0.0                0.0   \n",
              "TCGA-AR-A0TU             16.5539  ...                0.0                0.0   \n",
              "\n",
              "              ENSG00000288656.1  ENSG00000288658.1  ENSG00000288660.1  \\\n",
              "Unnamed: 0                                                              \n",
              "TCGA-5L-AAT0             0.0000             0.0100             0.0408   \n",
              "TCGA-A2-A04U             0.0000             1.2410             0.0000   \n",
              "TCGA-A7-A13D             0.0000             0.0921             0.0000   \n",
              "TCGA-BH-A201             0.0000             0.0410             0.0000   \n",
              "TCGA-BH-A0H6             0.0051             0.0135             0.1373   \n",
              "...                         ...                ...                ...   \n",
              "TCGA-A8-A07O             0.0000             0.5590             0.0193   \n",
              "TCGA-A2-A1FV             0.0183             0.0193             0.0000   \n",
              "TCGA-C8-A275             0.0037             0.0291             0.0000   \n",
              "TCGA-A2-A0CS             0.0000             0.1755             0.0326   \n",
              "TCGA-AR-A0TU             0.0000             0.1810             0.0217   \n",
              "\n",
              "              ENSG00000288661.1  ENSG00000288669.1  ENSG00000288671.1  \\\n",
              "Unnamed: 0                                                              \n",
              "TCGA-5L-AAT0                0.0             0.0000                0.0   \n",
              "TCGA-A2-A04U                0.0             0.0000                0.0   \n",
              "TCGA-A7-A13D                0.0             0.0000                0.0   \n",
              "TCGA-BH-A201                0.0             0.0000                0.0   \n",
              "TCGA-BH-A0H6                0.0             0.0000                0.0   \n",
              "...                         ...                ...                ...   \n",
              "TCGA-A8-A07O                0.0             0.0000                0.0   \n",
              "TCGA-A2-A1FV                0.0             0.0072                0.0   \n",
              "TCGA-C8-A275                0.0             0.0000                0.0   \n",
              "TCGA-A2-A0CS                0.0             0.0000                0.0   \n",
              "TCGA-AR-A0TU                0.0             0.0000                0.0   \n",
              "\n",
              "              ENSG00000288674.1  ENSG00000288675.1  \n",
              "Unnamed: 0                                          \n",
              "TCGA-5L-AAT0             0.0154             0.1764  \n",
              "TCGA-A2-A04U             0.0363             0.1440  \n",
              "TCGA-A7-A13D             0.0142             0.0000  \n",
              "TCGA-BH-A201             0.0174             0.2532  \n",
              "TCGA-BH-A0H6             0.0145             0.1902  \n",
              "...                         ...                ...  \n",
              "TCGA-A8-A07O             0.0117             0.1004  \n",
              "TCGA-A2-A1FV             0.0119             0.2382  \n",
              "TCGA-C8-A275             0.0060             0.0856  \n",
              "TCGA-A2-A0CS             0.0123             0.1550  \n",
              "TCGA-AR-A0TU             0.0033             0.1410  \n",
              "\n",
              "[1059 rows x 19962 columns]"
            ]
          },
          "execution_count": 29,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "genomics = pd.read_csv(\"G:/Il mio Drive/datasets/LAB_WSI_Genomics/TCGA_BRCA/Data/genomic/fpkm_uq_unstranded.csv\", sep=\"\\t\")#√® lo stesso che trovi in\n",
        "#genomics_path nella cella superiore ma semplicemente hai un altro formato di gene expression\n",
        "\n",
        "#per inizializzare il codice sarebbe stato meglio scrivere\n",
        "#genomics = pd.read_csv(TCGA_BRCA_dataset_config.parameters.genomics_path, sep=\"\\t\")\n",
        "\n",
        "genomics = genomics.set_index(\"Unnamed: 0\").dropna()\n",
        "genomics"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-Q6YgPaQzynI"
      },
      "source": [
        "üîÅ Connessione con l'altro file\n",
        "Nel file TCGA_BRCA_labels_multimodal.tsv, l‚Äôidentificativo paziente √® tipo:\n",
        "\n",
        "case_id = TCGA-BH-A0C0\n",
        "Nel dataset genomico, l‚ÄôID √®:\n",
        "\n",
        "TCGA-BH-A0H6\n",
        "üß† Nota importante:\n",
        "\n",
        "I primi 12 caratteri di questi ID (TCGA-XX-XXXX) rappresentano il case_id.\n",
        "\n",
        "Puoi usare questi per mappare/integrare i due dataset.\n",
        "\n",
        "Esempio: da slide_id = TCGA-BH-A0C0-01A ‚Üí ottieni case_id = TCGA-BH-A0C0, e puoi cercare quel case_id nel dataset genomico.\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8oCiAJ7feL6S"
      },
      "source": [
        "Hai notato una cosa importante! Nel dizionario TCGA_BRCA_dataset_config abbiamo:\n",
        "\n",
        "\n",
        "*\"genomics_path\": \"LAB_WSI_Genomics/TCGA_BRCA/Data/genomic/*tpm_unstranded.csv\"\n",
        "Mentre nel codice dove carichiamo i dati genomici, leggiamo un altro file:\n",
        "\n",
        "\n",
        "*genomics = pd.read_csv(\"LAB_WSI_Genomics/TCGA_BRCA/Data/genomic/fpkm_uq_unstranded.csv\", sep=\"\\t\")*\n",
        "\n",
        "üí° La differenza sta nel tipo di dati genomici contenuti in questi file!\n",
        "Sono due formati di normalizzazione dell'espressione genica."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CIJUumbNn6GO"
      },
      "source": [
        "SOTTO HAI:\n",
        "üß¨ 2. Seconda tabella: Metadati clinici + slide\n",
        "üìç Contenuto:\n",
        "\n",
        "Colonna\tSignificato\n",
        "case_id\tID del paziente (es. TCGA-5L-AAT0)\n",
        "slide_id\tID unico della vetrina istopatologica\n",
        "True_Label\tVivo (Alive) o morto (Dead)\n",
        "FUT\tTempo di follow-up (es. 375 giorni)\n",
        "Survival\tEtichetta binaria (1 = censurato/vivo, 0 = evento/morto)\n",
        "\n",
        "üìå Fonte: TCGA_BRCA_labels_multimodal.tsv\n",
        "üìå Usato per: task clinico (Survival o Treatment_Response)\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "E57GC52ag5zg"
      },
      "source": [
        "### inspect main dataframe"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 30,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 423
        },
        "execution": {
          "iopub.execute_input": "2024-12-13T17:12:42.799624Z",
          "iopub.status.busy": "2024-12-13T17:12:42.798972Z",
          "iopub.status.idle": "2024-12-13T17:12:42.816502Z",
          "shell.execute_reply": "2024-12-13T17:12:42.815642Z",
          "shell.execute_reply.started": "2024-12-13T17:12:42.799587Z"
        },
        "id": "HxFoOSXTg5zg",
        "outputId": "d518aad2-486f-44f9-abb7-92fef2fc865e",
        "trusted": true
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>case_id</th>\n",
              "      <th>slide_id</th>\n",
              "      <th>True_Label</th>\n",
              "      <th>FUT</th>\n",
              "      <th>Survival</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>TCGA-C8-A1HO</td>\n",
              "      <td>TCGA-C8-A1HO-01A-01-TSA.5331126c-9810-4054-902...</td>\n",
              "      <td>Alive</td>\n",
              "      <td>375.0</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>TCGA-AQ-A0Y5</td>\n",
              "      <td>TCGA-AQ-A0Y5-01A-01-MSA.e8612b52-6969-4d03-aa7...</td>\n",
              "      <td>Dead</td>\n",
              "      <td>172.0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>TCGA-EW-A2FW</td>\n",
              "      <td>TCGA-EW-A2FW-01A-01-TSA.93F3FA5A-4797-489A-B86...</td>\n",
              "      <td>Alive</td>\n",
              "      <td>672.0</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>TCGA-C8-A1HI</td>\n",
              "      <td>TCGA-C8-A1HI-01Z-00-DX1.C6D0F8B8-55ED-477F-BAF...</td>\n",
              "      <td>Alive</td>\n",
              "      <td>343.0</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>TCGA-AR-A2LL</td>\n",
              "      <td>TCGA-AR-A2LL-01A-01-TSA.DB96FA2A-150F-4387-9F4...</td>\n",
              "      <td>Alive</td>\n",
              "      <td>2012.0</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1054</th>\n",
              "      <td>TCGA-LL-A6FP</td>\n",
              "      <td>TCGA-LL-A6FP-01A-01-TS1.E618EA84-C425-4B27-BCC...</td>\n",
              "      <td>Alive</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1055</th>\n",
              "      <td>TCGA-5L-AAT1</td>\n",
              "      <td>TCGA-5L-AAT1-01A-01-TS1.140261A5-268A-4C22-9E3...</td>\n",
              "      <td>Alive</td>\n",
              "      <td>1471.0</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1056</th>\n",
              "      <td>TCGA-AR-A2LR</td>\n",
              "      <td>TCGA-AR-A2LR-01A-01-TSA.E8716040-4787-4C4B-903...</td>\n",
              "      <td>Alive</td>\n",
              "      <td>1742.0</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1057</th>\n",
              "      <td>TCGA-A8-A06U</td>\n",
              "      <td>TCGA-A8-A06U-01A-01-BS1.1182603b-20e7-4a0e-a68...</td>\n",
              "      <td>Dead</td>\n",
              "      <td>883.0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1058</th>\n",
              "      <td>TCGA-B6-A1KC</td>\n",
              "      <td>TCGA-B6-A1KC-01B-01-TS1.af22665c-5cc1-4c93-a95...</td>\n",
              "      <td>Alive</td>\n",
              "      <td>1326.0</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>1058 rows √ó 5 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "           case_id                                           slide_id  \\\n",
              "0     TCGA-C8-A1HO  TCGA-C8-A1HO-01A-01-TSA.5331126c-9810-4054-902...   \n",
              "1     TCGA-AQ-A0Y5  TCGA-AQ-A0Y5-01A-01-MSA.e8612b52-6969-4d03-aa7...   \n",
              "2     TCGA-EW-A2FW  TCGA-EW-A2FW-01A-01-TSA.93F3FA5A-4797-489A-B86...   \n",
              "3     TCGA-C8-A1HI  TCGA-C8-A1HI-01Z-00-DX1.C6D0F8B8-55ED-477F-BAF...   \n",
              "4     TCGA-AR-A2LL  TCGA-AR-A2LL-01A-01-TSA.DB96FA2A-150F-4387-9F4...   \n",
              "...            ...                                                ...   \n",
              "1054  TCGA-LL-A6FP  TCGA-LL-A6FP-01A-01-TS1.E618EA84-C425-4B27-BCC...   \n",
              "1055  TCGA-5L-AAT1  TCGA-5L-AAT1-01A-01-TS1.140261A5-268A-4C22-9E3...   \n",
              "1056  TCGA-AR-A2LR  TCGA-AR-A2LR-01A-01-TSA.E8716040-4787-4C4B-903...   \n",
              "1057  TCGA-A8-A06U  TCGA-A8-A06U-01A-01-BS1.1182603b-20e7-4a0e-a68...   \n",
              "1058  TCGA-B6-A1KC  TCGA-B6-A1KC-01B-01-TS1.af22665c-5cc1-4c93-a95...   \n",
              "\n",
              "     True_Label     FUT  Survival  \n",
              "0         Alive   375.0         1  \n",
              "1          Dead   172.0         0  \n",
              "2         Alive   672.0         1  \n",
              "3         Alive   343.0         1  \n",
              "4         Alive  2012.0         1  \n",
              "...         ...     ...       ...  \n",
              "1054      Alive     0.0         1  \n",
              "1055      Alive  1471.0         1  \n",
              "1056      Alive  1742.0         1  \n",
              "1057       Dead   883.0         0  \n",
              "1058      Alive  1326.0         1  \n",
              "\n",
              "[1058 rows x 5 columns]"
            ]
          },
          "execution_count": 30,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "#guarda caso √® lo stesso che hai sopra:\n",
        "#\"parameters\": {\n",
        " #     \"dataframe_path\": \"LAB_WSI_Genomics/TCGA_BRCA/TCGA_BRCA_labels_multimodal.tsv\", #dati genomici associati a immagini\n",
        "dataframe = pd.read_csv(\"G:/Il mio Drive/datasets/LAB_WSI_Genomics/TCGA_BRCA/TCGA_BRCA_labels_multimodal.tsv\", sep=\"\\t\")\n",
        "dataframe = dataframe.dropna()\n",
        "dataframe\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UGMrZ7Gd03_C"
      },
      "source": [
        "IL CODICE DI SOTTO:\n",
        "Hai condiviso una classe chiamata Multimodal_WSI_Genomic_Dataset, progettata per caricare dataset multimodali contenenti:\n",
        "\n",
        "Immagini istopatologiche (WSI = Whole Slide Image),\n",
        "\n",
        "Dati genomici (espressione genica),\n",
        "\n",
        "Etichette cliniche (come la sopravvivenza o la risposta al trattamento).\n",
        "\n",
        "üß† Obiettivo della classe\n",
        "Costruire un oggetto PyTorch Dataset capace di gestire input multimodali (immagini + genomica) per task clinici come predizione della sopravvivenza o risposta al trattamento."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "quyjRnDzeOxX"
      },
      "source": [
        "TASK SUPPORTATI:\n",
        "üß† I due task supportati\n",
        "Task\tDescrizione\n",
        "\"Survival\"\tPredire quanto tempo sopravviver√† un paziente (es. in giorni) e se √® deceduto o censurato. √à un task di regressione censurata.\n",
        "\"treatment_response\"\tPredire come risponder√† un paziente a un trattamento (es. chemioterapia): risposta positiva/negativa. √à un task di classificazione."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "s8vxgn4RgeIo"
      },
      "source": [
        "üîç Premessa: cosa vogliamo predire nel Survival Analysis\n",
        "In Survival Analysis non predici se una persona morir√† (spoiler: prima o poi tutti), ma:\n",
        "\n",
        "\"Quanto tempo passer√† fino all‚Äôevento\" (es. morte, recidiva, fallimento del trattamento...)\n",
        "\n",
        "üì¶ Dati disponibili\n",
        "Paziente\tTempo (days)\tEvento (morte)\tInterpretazione\n",
        "A\t1000\t‚úÖ (1)\t√à morto dopo 1000 giorni ‚Üí informazione completa\n",
        "B\t1500\t‚ùå (0)\t√à vivo a 1500 giorni ‚Üí dato censurato\n",
        "\n",
        "üìå Perch√© anche i morti servono alla predizione\n",
        "Nel task di sopravvivenza:\n",
        "\n",
        "I morti forniscono esempi completi: sappiamo quanto hanno vissuto e che l‚Äôevento √® avvenuto.\n",
        "\n",
        "I vivi (censurati) forniscono informazioni parziali: sono vivi fino a un certo punto, ma non sappiamo cosa succeder√† dopo.\n",
        "\n",
        "Quindi √® esattamente l‚Äôopposto di quello che hai detto:\n",
        "\n",
        "üîÑ I morti sono fondamentali per l‚Äôaddestramento, mentre i vivi danno solo limiti inferiori (\"√® vissuto almeno fino a X\")."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bzoxj41hgiuc"
      },
      "source": [
        "if task_type == \"Survival\":\n",
        "    dataframe[\"time\"] = dataframe[\"time\"].astype(int)\n",
        "    dataframe[\"censorship\"] = dataframe[\"censorship\"].astype(int) *testo in corsivo*\n",
        "\n",
        "\"time\" = tempo osservato\n",
        "\n",
        "\"censorship\" = 0 se morto, 1 se censurato (cio√® ancora vivo alla fine dell‚Äôosservazione)\n",
        "\n",
        "Durante l‚Äôallenamento:\n",
        "\n",
        "Per i non censurati (censorship = 0): il modello sa quando √® successo l‚Äôevento\n",
        "\n",
        "Per i censurati (censorship = 1): il modello sa che non √® successo ancora, quindi sa solo che \"sopravvive almeno fino a quel tempo\""
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0Le2TH2JhHT_"
      },
      "source": [
        "Entrambi sono usati nel training.\n",
        "\n",
        "I morti danno supervision completa,\n",
        "\n",
        "I vivi danno supervision parziale (censurata)."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yDgPw0JgrVT7"
      },
      "source": [
        "![image.png](data:image/png;base64,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)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KiUk1AO2sqUU"
      },
      "source": [
        "üéØ Perch√© concatenare patch di slide diverse per uno stesso paziente?\n",
        "Risposta breve:\n",
        "Perch√© il modello non distingue tra le slide, ma lavora con tutte le patch del paziente come se fossero un unico ‚Äúbag of patches‚Äù.\n",
        "\n",
        "√à un approccio tipico nel Multiple Instance Learning (MIL) o nei modelli multimodali di deep learning per immagini mediche.\n",
        "\n",
        "üß† Ragionamento concettuale\n",
        "Tu vuoi fare una previsione per il paziente, non per la singola slide.\n",
        "\n",
        "Se un paziente ha una sola slide, prendi tutte le sue patch ‚Üí tutto ok.\n",
        "\n",
        "Se ne ha pi√π di una, tutte le patch sono comunque immagini dello stesso paziente.\n",
        "\n",
        "‚û°Ô∏è Quindi:\n",
        "\n",
        "Ha senso ragionare a livello di paziente, non a livello di singola slide.\n",
        "\n",
        "üë®‚Äç‚öïÔ∏è Esempio clinico:\n",
        "Un paziente ha due sezioni del tumore in due vetrini diversi (due slide_id), ma sono dello stesso tumore.\n",
        "\n",
        "Quindi, nel modello:\n",
        "\n",
        "Le patch delle due slide vengono unite\n",
        "\n",
        "E trattate come ‚Äútutte le informazioni visive disponibili per quel paziente‚Äù"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 31,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 211
        },
        "execution": {
          "iopub.execute_input": "2024-12-13T17:12:46.655119Z",
          "iopub.status.busy": "2024-12-13T17:12:46.654753Z",
          "iopub.status.idle": "2024-12-13T17:12:46.681432Z",
          "shell.execute_reply": "2024-12-13T17:12:46.680565Z",
          "shell.execute_reply.started": "2024-12-13T17:12:46.655053Z"
        },
        "id": "xQCuYguvg5zg",
        "outputId": "c9f63a9f-5c21-46a3-db56-18e02eaf410c",
        "trusted": true
      },
      "outputs": [],
      "source": [
        "class Multimodal_WSI_Genomic_Dataset(Dataset): #Dataset √® una classe base astratta che PyTorch fornisce per creare dataset personalizzati.\n",
        "    #‚ÄúSto costruendo un dataset personalizzato che PyTorch pu√≤ usare in un DataLoader, e implementer√≤ i metodi necessari (__getitem__, __len__, ecc.)‚Äù\n",
        "    def __init__(self,  datasets_configs = [TCGA_BRCA_dataset_config],\n",
        "                        task_type=\"Survival\", # Survival or treatment_response\n",
        "                        max_patches=4096,\n",
        "                        n_bins=4,\n",
        "                        eps=1e-6,\n",
        "                        sample=True, #Se ci sono troppe patch, ne seleziona a caso un sottoinsieme (sample = True)\n",
        "                        #Se ce ne sono meno, fa padding (aggiunge righe di zeri)\n",
        "                         #‚Üí e costruisce una mask per distinguere le patch vere da quelle \"finte\"\n",
        "                        load_slides_in_RAM=False, #Ad ogni accesso (__getitem__), i file .pt vengono letti da disco:\n",
        "                        ):\n",
        "        self.task_type = task_type\n",
        "        self.load_slides_in_RAM = load_slides_in_RAM\n",
        "        if self.load_slides_in_RAM:\n",
        "            self.slides_cache = {}\n",
        "\n",
        "        self.datasets = {} # Qui inizializziamo un dizionario vuoto per salvare le configurazioni dei dataset.\n",
        "        for i, dataset_config in enumerate(datasets_configs):#Questo ci permette di aggiungere pi√π dataset senza doverli passare direttamente nel costruttore.\n",
        "            # config = yaml.load(open(dataset_config, \"r\"), yaml.FullLoader)\n",
        "            # config = munchify(config)\n",
        "            config = dataset_config\n",
        "            if config.name in self.datasets:#assegniamo i parametri corretti del dataset pescato una sola volta\n",
        "                raise ValueError(\"Dataset name {} already exists\".format(config.name))\n",
        "            self.datasets[config.name] = config.parameters # asser config.name in datasets  #qui devi capire che datasets √® un dizionario che fino a poco fa era vuoto e quindi\n",
        "            #stai dicendo che la prima chiave √® config.name(quindi il nome del dataset di riferimento) e il valore sono i parametri dello stesso\n",
        "            #questa sintassi √® permessa dal fatto che abbiamo definito TCGA_BRCA_dataset_config che passa per config e poi all'interno del diz \"datasets\" creiamo\n",
        "            #questa nuova associazione del tipo config.name ( nome del diz) --> e i relativi parametri\n",
        "\n",
        "            dataframe = pd.read_csv(config.parameters.dataframe_path, sep=\"\\t\",dtype={'case_id': str}) #ricordati che sei in un ciclo for quindi config.name si riferisce al\n",
        "            #diz di questa iterazione, quindi anche dataframe cambier√† in base a quale config hai\n",
        "            dataframe = dataframe.dropna()\n",
        "            #dataframe[\"dataset_name\"]--> creo una nuova colonna\n",
        "            #Per ogni riga del dataframe, assegna lo stesso valore: config.name (es. \"TCGA_BRCA\")\n",
        "            dataframe[\"dataset_name\"] = [config.name for _ in range(len(dataframe))] #serve per identificare il dataset a cui stiamo facendo riferimento\n",
        "            #utile per dataet multipli# nella riga sopra andiamo a creare una nuova colonna in cui avremo tutti i valori del dataset a cui stiamo facendo riferimento\n",
        "            #andiamo a rinominare i nomi delle colonne in modo da standardizzare i nomi per tutti i possibili dataset che useremmo, cos√¨ da avere\n",
        "            #sempre gli stessi nomi\n",
        "            if task_type == \"Survival\": #per adattare le colonne del dataframe a seconda del tipo di task (Survival o treatment_response).\n",
        "                rename_dict = { self.datasets[config.name].label_name: \"time\",\n",
        "                                self.datasets[config.name].censorships_name: \"censorship\",\n",
        "                                self.datasets[config.name].case_id_name: \"case_id\",\n",
        "                                self.datasets[config.name].slide_id_name: \"slide_id\"}\n",
        "                dataframe.rename(columns=rename_dict, inplace=True)\n",
        "                dataframe[\"time\"] = dataframe[\"time\"].astype(int)\n",
        "                self.case_id_name = \"case_id\"\n",
        "                self.slide_id_name = \"slide_id\"\n",
        "            else:\n",
        "                self.case_id_name = self.datasets[config.name].case_id_name\n",
        "                self.slide_id_name = self.datasets[config.name].slide_id_name\n",
        "            # dataframe = self.filter_by_tissue_type(config.name, dataframe, config.parameters.tissue_type_filter)\n",
        "\n",
        "            # load genomics data\n",
        "            genomics = pd.read_csv(config.parameters.genomics_path, sep=\"\\t\", dtype={'Unnamed: 0': str})#carichiamo i dati di espressione genica\n",
        "            genomics = genomics.set_index(\"Unnamed: 0\").dropna()#pulizia\n",
        "            genomics = np.log(genomics+0.1)#normalizzazione logaritmica per diminuire l'ampiezza delle variazioni tra geni +\n",
        "            #+0.1 che serve per evitare il logartimo di 0 che √® indefinito\n",
        "\n",
        "            if i==0: # Se i == 0, significa che stiamo caricando il primo dataset.\n",
        "                self.dataframe = dataframe\n",
        "                self.genomics = genomics\n",
        "            else:#Se stiamo caricando pi√π dataset, li concatenamo (pd.concat()) ignore_index=True serve per riallineare gli indici dopo la concatenazione.\n",
        "                self.dataframe = pd.concat([self.dataframe, dataframe], ignore_index=True)\n",
        "                self.genomics = pd.concat([self.genomics, genomics], ignore_index=True)\n",
        "\n",
        "        #{'pAdnL', 'pOvaR', 'pMes1', 'pOth', 'pTubL', 'pPer', 'pAdnR', 'pTubL1', 'pOva', 'pTubR', 'p2Ome2', 'pPer2', 'pVag', 'pLNR', 'pUte1',\n",
        "        # 'pPerR1', 'pOvaL1', 'pOvaL', 'p2Oth', 'pPer ', 'pTub', 'pOme2', 'p0Ome', 'pUte2', 'pOva2', 'pMes', 'pOme ', 'pBow', 'pOme1', 'pOth2',\n",
        "        # 'pAdnR1', 'pOth1', 'p2Ome1', 'pOme', 'p2Per1', 'pPer3', 'pOvaR1', 'pPerL ', 'pUte', 'pOme3', 'pAndL', 'pTub2', 'pPer1'}\n",
        "        # self.pt_files_path = pt_files_path\n",
        "        self.max_patches = max_patches # Quante patch usare da ogni Whole Slide Image (WSI). Utile per controllare il carico computazionale o per campionamento.\n",
        "        self.sample = sample #Se True, campiona le patch casualmente, invece di prendere tutte le patch disponibili.\n",
        "        self.n_bins = n_bins #Numero di intervalli (bins) per la discretizzazione del tempo di sopravvivenza.\n",
        "        # self.label_name = label_name\n",
        "        # self.censorships_name = censorships_name\n",
        "        self.eps = eps #Valore molto piccolo per evitare errori numerici nelle operazioni matematiche (es. logaritmi o divisioni).\n",
        "        # self._filter_by_tissue_type()\n",
        "\n",
        "        #Queste due funzioni a seguire servono a organizzare i pazienti e le loro informazioni.\n",
        "        self._compute_patient_dict() # Creare un dizionario che associa ogni case_id (paziente) alla lista delle sue slide_id (immagini).\n",
        "        self._compute_patient_df()# Tieni una sola riga per paziente nel caso ci fossero pi√π slide_id.\n",
        "        if self.task_type == \"Survival\":\n",
        "            self._compute_labels()\n",
        "        else:\n",
        "            self.patient_df[\"label\"] = self.patient_df[\"Treatment_Response\"]\n",
        "        print(\"Dataset loaded with {} slides and {} patients\".format(len(self.dataframe), len(self.patient_df)))\n",
        "\n",
        "    #Qui creiamo un dizionario in cui ogni paziente ha la sua lista di immagini (slide).\n",
        "    #In teoria nel dataset abbiamo una corrsipoindenza uno a uno tra l'immagine e il paziente ma questo codice vuole generalizzare il caso in cui\n",
        "    #avessimo pi√π immagini per un paziente\n",
        "\n",
        "    def _compute_patient_dict(self):\n",
        "        self.patient_list = list(self.dataframe[self.case_id_name].unique())#Creiamo una lista di pazienti unici,  contiene tutti gli ID paziente senza duplicati. case_id_name sarebbe il paziente\n",
        "        self.patient_dict = {patient: list(self.dataframe[self.dataframe[self.case_id_name] == patient][self.slide_id_name]) for patient in self.patient_list} #dizionario con le\n",
        "        #immagini per ogni paziente\n",
        "        #sopra abbiamo creato , per ogni paziente, una lista con tutte le immagini associate a lui.\n",
        "\n",
        "    def _compute_patient_df(self):# Creiamo il DataFrame pulito\n",
        "        # Qui prendiamo il dataframe e lo trasformiamo in un dataset in cui ogni paziente appare solo una volta.\n",
        "        self.patient_df = self.dataframe.drop_duplicates(subset=self.case_id_name) #Se un paziente ha pi√π di un record (perch√© ha pi√π immagini), ne teniamo solo uno.\n",
        "        self.patient_df = self.patient_df.reset_index(drop=True)#riordina l'indice\n",
        "        self.patient_df = self.patient_df.set_index(self.case_id_name, drop=False) #Ora case_id √® l‚Äôindice del DataFrame, quindi possiamo\n",
        "        #cercare velocemente i dati di un paziente.\n",
        "\n",
        "        #Il dizionario (self.patient_dict) serve per mappare ogni paziente alle sue immagini.\n",
        "        #Il DataFrame (self.patient_df) serve per avere un dataset pulito con un solo record per paziente e per fare analisi.\n",
        "\n",
        "    def get_train_test_val_splits(self, train_size=0.7, val_size=0.15, test_size=0.15, random_state=42): #Obiettivo: Creare un dataset bilanciato, normalizzare i dati genomici e restituire le liste di pazienti nei tre gruppi.\n",
        "        np.random.seed(random_state) #Imposta il seme per la riproducibilit√†\n",
        "        patients = np.array(self.patient_list) # Converte la lista dei pazienti in un array NumPy\n",
        "        # Qui creiamo una lista con tutti i pazienti e la mescoliamo casualmente.\n",
        "        np.random.shuffle(patients)\n",
        "\n",
        "        #Qui dividiamo i pazienti in tre gruppi in base alle proporzioni scelte.\n",
        "        n = len(patients) # Numero totale di pazienti\n",
        "        train_end = int(n * train_size)# Numero di pazienti per il training set\n",
        "        val_end = int(n * (train_size + val_size)) # Numero di pazienti per training + validation\n",
        "        train_patients = patients[:train_end] # Primi pazienti nel training set\n",
        "        val_patients = patients[train_end:val_end] # Pazienti successivi nel validation set\n",
        "        test_patients = patients[val_end:] # Ultimi pazienti nel test set\n",
        "\n",
        "        train_patients_idx = pd.Index(train_patients)\n",
        "        val_patients_idx = pd.Index(val_patients)\n",
        "        test_patients_idx = pd.Index(test_patients)\n",
        "        # for name in self.genomics.columns.tolist():\n",
        "        #     scaler  = StandardScaler()\n",
        "        #     self.genomics.loc[train_patients_idx, name] = scaler.fit_transform(self.genomics.loc[train_patients_idx, name].values.reshape(-1,1)).ravel()\n",
        "        #     self.genomics.loc[val_patients_idx, name]   = scaler.transform(self.genomics.loc[val_patients_idx, name].values.reshape(-1,1)).ravel()\n",
        "        #     self.genomics.loc[test_patients_idx, name]  = scaler.transform(self.genomics.loc[test_patients_idx, name].values.reshape(-1,1)).ravel()\n",
        "\n",
        "\n",
        "        #I dati genomici possono avere valori con scale molto diverse\n",
        "        #Dobbiamo ridimensionare tutti i valori in un range simile, altrimenti il modello potrebbe dare pi√π importanza ai geni con numeri grandi.\n",
        "        self.normalized_genomics = deepcopy(self.genomics) #Creiamo una copia dei dati genomici per non modificare quelli originali.\n",
        "        X_train = self.normalized_genomics.loc[train_patients_idx, :]\n",
        "        X_val = self.normalized_genomics.loc[val_patients_idx, :]\n",
        "        X_test = self.normalized_genomics.loc[test_patients_idx, :]\n",
        "\n",
        "        scaler = StandardScaler()\n",
        "        scaler.fit(X_train)  # fit on train set\n",
        "\n",
        "        # Transform entire subsets of the copied DataFrame\n",
        "        self.normalized_genomics.loc[train_patients_idx, :] = scaler.transform(X_train)\n",
        "        self.normalized_genomics.loc[val_patients_idx, :] = scaler.transform(X_val)\n",
        "        self.normalized_genomics.loc[test_patients_idx, :] = scaler.transform(X_test)\n",
        "\n",
        "        # train_indices = [i for i, patient in enumerate(self.patient_list) if patient in train_patients]\n",
        "        # val_indices = [i for i, patient in enumerate(self.patient_list) if patient in val_patients]\n",
        "        # test_indices = [i for i, patient in enumerate(self.patient_list) if patient in test_patients]\n",
        "        print(\"Train: {}, Val: {}, Test: {}\".format(len(train_patients), len(val_patients), len(test_patients)))\n",
        "        assert len(train_patients) + len(val_patients) + len(test_patients) == len(self.patient_list) #\tControlla che tutto sia andato bene\n",
        "        return train_patients, val_patients, test_patients #In modo che il resto del codice possa usarli per allenare e testare il modello.\n",
        "\n",
        "\n",
        "    #la funzione qui sotto: per assegnare un'etichetta (label) di sopravvivenza a ciascun paziente,\n",
        "    #dividendo i pazienti in fasce di tempo (bin) in base alla durata di sopravvivenza.\n",
        "\n",
        "    #Hai un dataset con una colonna \"time\" che rappresenta i mesi di sopravvivenza di ciascun paziente.\n",
        "    #L‚Äôobiettivo √® trasformare questi numeri in classi (etichette) da dare al modello, es.:\n",
        "\n",
        "    #Pazienti che vivono poco ‚Üí classe 0\n",
        "    #Pazienti che vivono tanto ‚Üí classe 3\n",
        "    #(dipende da quante classi scegli)\n",
        "\n",
        "    #0 ‚Üí evento osservato ‚Üí non censurato ‚úÖ, cio√® sappaimo data in cui l'evento inizia e data di morte ( es: ha vissuto 24 mesi)\n",
        "    #1 ‚Üí evento non osservato ‚Üí censurato ‚ùå\n",
        "\n",
        "    #Quando calcoli le etichette di sopravvivenza, ha senso usare solo i pazienti non censurati (censorship == 0) perch√© sai quanto hanno vissuto davvero.\n",
        "\n",
        "    #I censurati non puoi usarli per calcolare bin temporali precisi, perch√© il valore che hai potrebbe essere solo un minimo (il paziente potrebbe essere ancora vivo, ma non sai per quanto).\n",
        "    def _compute_labels(self): #Obiettivo --> Trasformare i tempi di sopravvivenza (time) in classi discrete (label) da usare come etichette nel modello.\n",
        "  #üìå Questo √® utile quando vuoi formulare la sopravvivenza come problema di classificazione\n",
        "  # (es. predire in quale intervallo temporale morir√† il paziente).\n",
        "        #Prende solo i pazienti non censurati (cio√® quelli per cui sappiamo il tempo di sopravvivenza reale).\n",
        "        #Divide i loro time in n_bins con lo stesso numero di pazienti (quasi).\n",
        "      #Ritorna:\n",
        "        #q_bins = lista dei confini temporali tra i gruppi.\n",
        "        #disc_labels = etichetta assegnata a ciascun paziente (ma solo ai non censurati).\n",
        "      #üéØ Obiettivo: trovare dei bin con una distribuzione bilanciata tra i pazienti. Quindi come puoi intuire per far entrare un numero di\n",
        "      #pazienti pi√π o meno uguale in tutti i bin bisogna avere dei bin non equidistanti tra loro\n",
        "\n",
        "        uncensored_df = self.patient_df[self.patient_df[\"censorship\"] == 0] #Usa solo i pazienti non censurati per calcolare le soglie di tempo.\n",
        "        disc_labels, q_bins = pd.qcut(uncensored_df[\"time\"], q=self.n_bins, retbins=True, labels=False, duplicates='drop') #pd.qcut() divide\n",
        "        #la colonna time in quantili, cio√® cerca di fare gruppi con lo stesso numero di pazienti.\n",
        "        # retbins=True ‚Üí restituisce anche i valori di soglia dei bin.\n",
        "        # labels=False ‚Üí restituisce numeri (0, 1, 2...) come etichette.  Chi ha vissuto poco ‚Üí label 0   Se n_bins = 4\n",
        "\n",
        "        # duplicates='drop' ‚Üí evita crash se ci sono troppi valori uguali.\n",
        "        #qcut ha calcolato questi bin solo usando i pazienti non censurati.\n",
        "        #Quindi: quei bin potrebbero non includere i valori estremi dell'intero dataset, soprattutto i censurati. Per questo motivo facciamo max e min\n",
        "        #quindi per calcolare massimo e minimo stiamo usando tutti i pazienti\n",
        "        q_bins[-1] = self.patient_df[\"time\"].max() + self.eps #‚Üí l‚Äôultimo valore del bin diventa il massimo tempo di tutti i pazienti + qualcosa di piccolo (eps) per includere l‚Äôestremo.\n",
        "        q_bins[0] = self.patient_df[\"time\"].min() - self.eps #‚Üí il primo valore diventa il minimo - eps, per includere anche il minimo.\n",
        "\n",
        "        # assign patients to different bins according to their months' quantiles (on all data)\n",
        "        # cut will choose bins so that the values of bins are evenly spaced. Each bin may have different frequncies\n",
        "\n",
        "        #qui sotto facciamo l'assegnazione finale delle etichette con cut\n",
        "\n",
        "        #Prende tutti i pazienti (censurati e non).\n",
        "        #Usa i bin calcolati prima (q_bins) per assegnare a ciascuno una label corrispondente al suo tempo di sopravvivenza.\n",
        "      #üéØ Obiettivo: usare i bin calcolati in modo \"intelligente\" per assegnare un'etichetta anche ai censurati.\n",
        "\n",
        "#usiamo prima qcut per creare classi bilanciate e poi visto che per farlo si usano solo i non censurati dobbiamo usare cut per dare\n",
        "# una etichetta a tutti quanti ( anche quelli censurati )\n",
        "        disc_labels, q_bins = pd.cut(self.patient_df[\"time\"], bins=q_bins, retbins=True, labels=False, right=False, include_lowest=True) # il label = False ti permette di restituirti non i bin cos√¨ come sono ma in termini di 0 = primo bin, 1 = secondo bin ecc\n",
        "        self.patient_df.insert(2, 'label', disc_labels.values.astype(int))#Inserisce una nuova colonna label nella posizione 2 del DataFrame\n",
        "        #Ogni paziente riceve il suo bin temporale come etichetta\n",
        "        self.bins = q_bins # qui salviamo i bin per non perderli, cio√® vogliamo sempre sapere eventualmente il primo bin che range copre realmente\n",
        "\n",
        "\n",
        "#obiettivo di questa funzione: Caricare i file .pt che contengono le feature estratte dalle immagini istologiche (WSI) di un paziente (o meglio, di tutte le sue slide),\n",
        "# metterle tutte insieme in un unico tensor PyTorch e, se serve, campionarle per limitarne il numero.\n",
        "    def _load_wsi_embs_from_path(self, dataset_name, slide_names): #slide_names -->lista degli slide_id di un paziente (anche se spesso √® solo uno)\n",
        "            #questa funzione viene chiamata gi√π da patch_features, mask = self._load_wsi_embs_from_path(dataset_name, slide_list)\n",
        "            #dove slide_list sono tutte le slide di un singolo paziente\n",
        "            \"\"\"\n",
        "            Load all the patch embeddings from a list a slide IDs.\n",
        "\n",
        "            Args:\n",
        "                - self\n",
        "                - slide_names : List\n",
        "\n",
        "            Returns:\n",
        "                - patch_features : torch.Tensor\n",
        "                - mask : torch.Tensor\n",
        "\n",
        "            \"\"\"\n",
        "            patch_features = [] #un tensore con tutte le patch visive, Inizializza lista per le feature, qui andr√≤ a concatenerare tutte le feature\n",
        "            #della patch di quella slide andando avanti nel modo in cui √® mostrata l'immagine sopra\n",
        "            pt_files_path = self.datasets[dataset_name].pt_files_path #Recupera il path dei file .pt dalle config relativo al dataset che ci interessa,\n",
        "            #dal momento che possono esserci pi√π dataset. Ricordati che abbiamo creato una colonna per identificare il dataset\n",
        "            #Ogni slide ha il suo file .pt che contiene le feature visive pre-estratte (es. da un modello CNN tipo ResNet o Vision Transformer).\n",
        "            # load all slide_names corresponding for the patient, Cicla su ogni slide del paziente\n",
        "\n",
        "            #ricordati che il file .pt:\n",
        "            #Se una slide √® stata divisa in 1200 patch, e ogni patch √® stata passata in una ResNet/Vision Transformer\n",
        "            # che genera un vettore di 1024 feature, allora il .pt contiene: torch.Size([1200, 1024])\n",
        "\n",
        "            for slide_id in slide_names:\n",
        "                if self.load_slides_in_RAM: #Questo serve per non rileggere dallo storage ogni volta, ma tenere tutto in RAM (pi√π veloce, ma serve memoria).\n",
        "                    if slide_id in self.slides_cache:\n",
        "                        wsi_bag = self.slides_cache[slide_id]\n",
        "                    else:\n",
        "                        wsi_path = os.path.join(pt_files_path, '{}.pt'.format(slide_id))\n",
        "                        wsi_bag = torch.load(wsi_path, weights_only=True) #wsi_bag √® un tensore che contiene le feature di tutte\n",
        "                        #le patch di quella slide.\n",
        "                        self.slides_cache[slide_id] = wsi_bag #qui dopo averla presa dal path la metto in cache\n",
        "                else:\n",
        "                    wsi_path = os.path.join(pt_files_path, '{}.pt'.format(slide_id))\n",
        "                    wsi_bag = torch.load(wsi_path, weights_only=True) # changed to True due to python warning\n",
        "                    #carichi le feature (wsi_bag) da .pt, che √® un tensore di shape es. [num_patch_slide_i, embedding_dim]\n",
        "                patch_features.append(wsi_bag) #Aggiunge le feature della slide a patch_features\n",
        "            patch_features = torch.cat(patch_features, dim=0) # Concatena tutto in un solo tensore\n",
        "            # print(\"patch_features.shape[0]: \", patch_features.shape[0])\n",
        "            #‚ùó E qui succede la parte chiave MIL:\n",
        "\n",
        "            #Concateni tutte le patch in un unico tensore,\n",
        "            #che rappresenta il bag completo del paziente.\n",
        "            #quindi se hai:\n",
        "                #patch_features = [\n",
        "                  #tensor(1000, 1024),\n",
        "                  #tensor(600, 1024)\n",
        "                    #]\n",
        "            #dopo torch.cat --> patch_features = tensor(1600, 1024)\n",
        "\n",
        "            if self.sample: #e self.sample=True, fai campionamento (per limitare il numero di patch)\n",
        "                max_patches = self.max_patches\n",
        "\n",
        "                n_samples = min(patch_features.shape[0], max_patches) #si limita il campionamento a max_patches\n",
        "                #Se hai meno patch di max_patches, le tieni tutte\n",
        "                #Se hai pi√π patch, ne scegli max_patches a caso\n",
        "                idx = np.sort(np.random.choice(patch_features.shape[0], n_samples, replace=False))\n",
        "                patch_features = patch_features[idx, :]\n",
        "                #Estrai n_samples righe (patch) a caso\n",
        "                #Le ordini (opzionale)\n",
        "                #E tieni solo quelle\n",
        "\n",
        "\n",
        "                # make a mask--> una maschera che indica quali patch sono reali e quali sono padding (se serve)\n",
        "                if n_samples == max_patches: #  Se hai esattamente max_patches allora: Niente padding, Tutte le patch sono reali ‚Üí maschera tutta di 0\n",
        "                    # sampled the max num patches, so keep all of them\n",
        "                    mask = torch.zeros([max_patches]) #Qui stai indicando se una patch √® reale o finta: 0 ‚Üí patch reale ‚úÖ, 1 ‚Üí patch finta (padding) ‚ùå\n",
        "                else:\n",
        "                    # sampled fewer than max, so zero pad and add mask-->#Se campioni meno patch del massimo costruisco la maschera ( 0 patch reale, 1 patch fittizia(padding))\n",
        "                    original = patch_features.shape[0] # numero di patch reali effettive (dopo campionamento)\n",
        "                    how_many_to_add = max_patches - original # quante patch finte (padding) servono\n",
        "                    zeros = torch.zeros([how_many_to_add, patch_features.shape[1]]) #Ogni riga √® una patch con tutti zeri\n",
        "                    #zeros = ... Qui stai creando dati finti, cio√® patch di padding.\n",
        "                    #Valori 0 ‚Üí perch√© vogliamo che non contengano nessuna informazione.\n",
        "                    #‚ö†Ô∏è Non significa che \"sono reali\", significa \"sono vuote\"\n",
        "                    patch_features = torch.concat([patch_features, zeros], dim=0)\n",
        "                    mask = torch.concat([torch.zeros([original]), torch.ones([how_many_to_add])])# Crea una maschera 1D che serve a distinguere:\n",
        "                    #Le patch reali ‚Üí 0, Le patch di padding ‚Üí 1\n",
        "\n",
        "            else:\n",
        "                mask = torch.zeros([patch_features.shape[0]]) #Nessun campionamento, nessun padding ‚Üí tutte patch reali.\n",
        "\n",
        "            return patch_features, mask\n",
        "\n",
        "    def set_sample(self, sample): #√à un metodo setter che serve a modificare il valore di self.sample da fuori la classe, in modo controllato.\n",
        "        self.sample = sample # True ‚Üí campioni (limiti il numero di patch, es. max 4096)\n",
        "                              # False ‚Üí usi tutte le patch disponibili\n",
        "\n",
        "    def __getitem__(self, index):\n",
        "        # Retrieve data from the dataframe based on the index\n",
        "        row  = self.patient_df.loc[index] # Prende la riga del DataFrame patient_df corrispondente all‚Äôindice index.\n",
        "        #patient_df ha un solo record per paziente, quindi qui prendi il paziente index-esimo.\n",
        "\n",
        "        genomics = torch.tensor(self.normalized_genomics.loc[index].values, dtype=torch.float32)#Prende i dati genomici\n",
        "        # normalizzati per quel paziente, li converte in un tensor PyTorch.\n",
        "        dataset_name = row[\"dataset_name\"] # da quale dataset proviene questo paziente.\n",
        "        tissue_type_filter = self.datasets[dataset_name].tissue_type_filter #se presente, specifica filtri sul tipo di tessuto (non sempre usato).\n",
        "        slide_list = self.patient_dict[row[self.case_id_name]] #slide_list: prende tutte le slide_id associate al paziente, da patient_dict.\n",
        "        patch_features, mask = self._load_wsi_embs_from_path(dataset_name, slide_list)#Carica le immagini istologiche (.pt) di\n",
        "        # tutte le slide del paziente ‚Üí concatena le patch ‚Üí campiona se serve ‚Üí crea una maschera per il padding.\n",
        "        label = row['label'] #La label √® quella calcolata prima: ad es. un bin (0‚Äì3) di sopravvivenza.\n",
        "\n",
        "        #Se stai facendo Survival Analysis, servono anche:\n",
        "\n",
        "        if self.task_type == \"Survival\":\n",
        "            censorship = row[\"censorship\"] ##censorship: se il paziente √® censurato (1) o no (0)\n",
        "            time = row[\"time\"] #time: tempo di sopravvivenza in mesi\n",
        "            label_names = [\"time\"] ##label_names: metti \"time\" come nome dell‚Äôetichetta\n",
        "        else: #Se il task non √® \"Survival\", questi campi non servono (ma li metti lo stesso per compatibilit√†).\n",
        "            censorship = torch.tensor(0)\n",
        "            time = torch.tensor(0)\n",
        "            label_names = [\"treatment_response\"]\n",
        "\n",
        "        #Questo √® l'oggetto che verr√† passato al modello di predizione deep learning, come input + target.\n",
        "        #Predire la sopravvivenza (Survival Analysis)\n",
        "        #Predire la risposta a un trattamento (Treatment Response)\n",
        "        #Usando immagini istologiche (WSI) + genomica come input\n",
        "        # per approfondire vai su one note verso la fine spiegato bene\n",
        "\n",
        "        #üîπ Questo √® il dizionario finale che viene passato al modello:\n",
        "        #Input = immagini (patch), mask, dati genomici\n",
        "        #Target = label, tempo, censura\n",
        "        #Info extra = patient_id, dataset_name\n",
        "        data = {\n",
        "                'input':{\n",
        "                            'patch_features': patch_features,\n",
        "                            'mask': mask,\n",
        "                            'genomics':genomics\n",
        "                        },\n",
        "                'label': label,\n",
        "                'censorship': censorship,\n",
        "                'original_event_time': time,\n",
        "                'label_names': label_names,\n",
        "                'patient_id': row[self.case_id_name],\n",
        "                'dataset_name': dataset_name,\n",
        "            }\n",
        "        return data\n",
        "\n",
        "    def __len__(self):\n",
        "        # Return the total number of samples in the dataset\n",
        "        return len(self.patient_df)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KRW3ISH4g5zh"
      },
      "source": [
        "### Multimodal ABMIL"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "M6oljYpfbODO"
      },
      "source": [
        "üåü Premessa: vogliamo \"pesare\" le patch\n",
        "Nel modello che stai studiando, abbiamo tante patch (piccoli pezzi di immagine).\n",
        "\n",
        "L‚Äôidea √®: non tutte le patch sono ugualmente importanti.\n",
        "\n",
        "Quindi vogliamo:\n",
        "\n",
        "Capire cosa c‚Äô√® nella patch ‚Üí V\n",
        "\n",
        "Capire quanto √® importante quella patch ‚Üí U\n",
        "\n",
        "Calcolare un punteggio di attenzione per ciascuna patch\n",
        "\n",
        "üîπ V = torch.tanh(self.attention_V(x))\n",
        "üëâ Cosa fa?\n",
        "Prende la patch x (un vettore di inner_dim numeri)\n",
        "\n",
        "La trasforma linearmente con attention_V\n",
        "\n",
        "Poi la passa attraverso tanh, una funzione non lineare\n",
        "\n",
        "üéØ Obiettivo: generare un vettore contenuto ‚Üí una rappresentazione trasformata di cosa c‚Äô√® nella patch\n",
        "\n",
        "‚ú® Pensalo come: ‚Äúcosa contiene questa patch?‚Äù\n",
        "\n",
        "üî∏ U = self.sigmoid(self.attention_U(x))\n",
        "üëâ Cosa fa?\n",
        "Prende sempre la stessa patch x\n",
        "\n",
        "La trasforma con un altro layer lineare (attention_U)\n",
        "\n",
        "Poi passa tutto in sigmoid, che comprime i numeri tra 0 e 1\n",
        "\n",
        "üéØ Obiettivo: generare un vettore filtro ‚Üí che decide quanto far passare di ogni elemento di V\n",
        "\n",
        "üîç Pensalo come: ‚Äúquanto √® importante questa patch?‚Äù, ma in modo morbido: non tutto o niente, ma un po‚Äô, tanto, poco..."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "C5CEm8wbbVOo"
      },
      "source": [
        "Poi fai V * U che √® Una moltiplicazione elemento per elemento (detta element-wise): ogni numero di V viene modulato da quello corrispondente di U."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8ubi7OnDbeyz"
      },
      "source": [
        "Esempio\n",
        "V = [0.8, 0.1, -0.5]\n",
        "U = [0.9, 0.2, 0.0]\n",
        "allora\n",
        "V * U = [0.72, 0.02, 0.0]\n",
        "üß† Vuol dire: \"la terza informazione di questa patch √® irrilevante, ignorala (0)\", la prima invece √® molto importante (0.72)."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xy_Pm7Ikb8fi"
      },
      "source": [
        "üß† Metafora:\n",
        "Immagina V come la voce della patch:\n",
        "\n",
        "‚ÄúCiao, io sono una patch tumorale!‚Äù\n",
        "\n",
        "E U √® un volume:\n",
        "\n",
        "‚ÄúOk, ti lascio parlare forte (0.9), poco (0.2) o ti silenzio (0.0)‚Äù\n",
        "\n",
        "Quindi V * U √® la voce finale che arriva all‚Äôorecchio del modello.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "execution": {
          "iopub.execute_input": "2024-12-13T17:12:55.068051Z",
          "iopub.status.busy": "2024-12-13T17:12:55.06718Z",
          "iopub.status.idle": "2024-12-13T17:12:55.079783Z",
          "shell.execute_reply": "2024-12-13T17:12:55.078864Z",
          "shell.execute_reply.started": "2024-12-13T17:12:55.068015Z"
        },
        "id": "s1NM9lPHg5zh",
        "trusted": true
      },
      "outputs": [],
      "source": [
        "class ABMIL_Multimodal(nn.Module):\n",
        "    def __init__(self,\n",
        "                     input_dim=1024,\n",
        "                     genomics_input_dim = 19962,\n",
        "                     inner_dim=64,\n",
        "                     output_dim=4,\n",
        "                     use_layernorm=False,\n",
        "                     input_modalities = [\"WSI\", \"Genomics\"],\n",
        "                     genomics_dropout = 0.5,\n",
        "                     dropout=0.0,\n",
        "                ):\n",
        "        super(ABMIL_Multimodal,self).__init__()\n",
        "\n",
        "        self.inner_proj = nn.Linear(input_dim,inner_dim)#Questa √® una rete neurale lineare (chiamata anche \"fully connected\" o \"dense layer\").\n",
        "        #input_dim: √® la dimensione delle patch in input (es. 1024)\n",
        "        #inner_dim: √® la nuova dimensione nascosta che vogliamo (es. 64)\n",
        "        self.output_dim = output_dim #Se stai classificando in 4 classi: output_dim = 4, Non √® un layer, √® solo una variabile che ti tieni da parte.\n",
        "        self.device=\"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
        "        self.input_modalities = input_modalities\n",
        "        self.use_layernorm = use_layernorm #Questa √® una flag (booleana) che ti dice se vuoi usare o no la Layer Normalization.\n",
        "        self.dropout = nn.Dropout(dropout)#Dropout √® una tecnica per evitare che il modello impari \"a memoria\" i dati ‚Üí evita overfitting.\n",
        "        #A ogni passaggio spegne a caso alcune unit√† del modello (con probabilit√† dropout)\n",
        "        if self.use_layernorm:#Se hai attivato use_layernorm, allora costruisci il layer LayerNorm, che:\n",
        "                              #Normalizza ogni input per migliorarne la stabilit√†\n",
        "                              #Serve per rendere l‚Äôapprendimento pi√π stabile e veloce.\n",
        "            self.layernorm = nn.LayerNorm(inner_dim)\n",
        "        #- Stai dicendo al modello:\n",
        "        #‚ÄúOgni patch dell‚Äôimmagine non √® ugualmente importante. Voglio che tu impari **quanto** pesare ciascuna patch.‚Äù\n",
        "        self.attention_V = nn.Linear(inner_dim, inner_dim)#Prendi un vettore e trasformalo linearmente in un altro della stessa dimensione.\"\n",
        "                                                          #`Crea un layer lineare completo (con pesi + bias)\n",
        "                                                          #Riceve un tensore con inner_dim elementi (es. 64)\n",
        "                                                          #Restituisce ancora un tensore con inner_dim elementi (quindi 64 ‚Üí 64)\n",
        "        #V √® usato come contenuto\n",
        "        #U come filtro di pesi tra 0 e 1\n",
        "        #V ‚Üí √® un vettore contenuto, libero di avere anche negativi\n",
        "        #U ‚Üí √® un modulatore, che dice ‚Äúquanto mi interessa questa parte di V‚Äù\n",
        "\n",
        "        self.attention_U = nn.Linear(inner_dim, inner_dim)#`√à un altro layer identico nella forma, ma con pesi indipendenti\n",
        "                                                          #Serve a creare un‚Äôaltra trasformazione diversa su input simili\n",
        "\n",
        "        self.sigmoid = nn.Sigmoid()\n",
        "        self.attention_weights = nn.Linear(inner_dim, 1)#riduce tutto a un **peso singolo**\n",
        "\n",
        "        self.genomics_dropout = nn.Dropout(genomics_dropout)\n",
        "        #Obiettivo: Prendere un vettore molto lungo (con l‚Äôespressione genica di ~20.000 geni), e trasformarlo in un vettore pi√π compatto\n",
        "        #e utile per la classificazione finale.\n",
        "        self.fc_genomics = nn.Sequential(#Una piccola rete neurale per processare i dati genomici\n",
        "                                            nn.Linear(genomics_input_dim, inner_dim),\n",
        "                                            nn.ReLU(),\n",
        "                                            nn.Linear(inner_dim, inner_dim),\n",
        "                                        )\n",
        "\n",
        "        # Output layer\n",
        "        final_layer_input_dim = 0    #Inizializza una variabile che useremo per calcolare la dimensione dell‚Äôinput che ricever√† il layer finale.\n",
        "        if \"WSI\" in input_modalities:#Se nel modello stiamo usando le immagini WSI (Whole Slide Images), allora sappiamo che ci sar√† un vettore\n",
        "                                     #(embedding) di dimensione inner_dim (di solito 64).\n",
        "                                     #Quindi diciamo: ‚ÄúOk, il layer finale ricever√† anche questa parte in input ‚Üí aggiungiamo 64‚Äù.\n",
        "            final_layer_input_dim += inner_dim\n",
        "        if \"Genomics\" in input_modalities:\n",
        "            final_layer_input_dim += inner_dim\n",
        "\n",
        "        self.output_layer = nn.Linear(final_layer_input_dim, output_dim)\n",
        "\n",
        "    def forward(self, data): #data deriva da __getitem__ visto sopra, √® un dizionario\n",
        "        # Extract patch features\n",
        "        if \"WSI\" in self.input_modalities:\n",
        "            x = data['patch_features']  # x is a dictionary with key 'patch_features'\n",
        "            #x: √® un tensore di tutte le patch visive per quel paziente, Esempio forma: [num_patches, input_dim], es. [1000, 1024]\n",
        "            mask = data['mask']#mask: √® un tensore che indica se una patch √® reale (0) o padding (1)\n",
        "            x = x[~mask.bool()].unsqueeze(0)#mask.bool() trasforma i valori in booleani (True = padding), cio√® il padding si mette con degli 1, quindi trasformando in booleano diventa True\n",
        "                                            #~mask.bool() nega ‚Üí tiene solo le patch vere, quindi tiene solo gli zeri che sono quindi \"False\" e quindi vere\n",
        "                                            #unsqueeze(0) aggiunge una dimensione \"batch\" ‚Üí output shape sar√† [1, num_patches, patch_dim]\n",
        "                                        #1 = ovvero un paziente alla volta ( sarebbe il batch)\n",
        "                                        #num_patches: numero di patch (immagini) per quel paziente\n",
        "                                        #inner_dim: dimensione del vettore che rappresenta ogni patch (es. 64)\n",
        "                                        #ricorda che ho tante patch per ogni singolo paziente\n",
        "\n",
        "            x = self.inner_proj(x)#Riduce o trasforma ogni patch da es. 1024 ‚Üí 64 dimensioni (o qualunque sia inner_dim)\n",
        "                                  #ricordati che prima avevamo detto: self.inner_proj = nn.Linear(input_dim,inner_dim)\n",
        "\n",
        "            if self.use_layernorm: #Se richiesto, normalizza le patch (LayerNorm aiuta la stabilit√† durante il training)\n",
        "                x = self.layernorm(x)\n",
        "\n",
        "            # Apply attention mechanism\n",
        "            V = torch.tanh(self.attention_V(x))  # Shape: (batch_size, num_patches, inner_dim)-->Shape: (1, num_patches, inner_dim)\n",
        "            #self.attention_V(x)\n",
        "            #‚Ü≥ √® un layer lineare: nn.Linear(inner_dim, inner_dim)\n",
        "            #‚Ü≥ quindi prende ogni patch (vettore di dimensione 64, per esempio) e lo trasforma in un nuovo vettore di stessa dimensione (64).\n",
        "            #Poi passa il risultato alla funzione torch.tanh\n",
        "            #‚Ü≥ tanh √® una funzione non lineare che comprime ogni valore tra -1 e +1\n",
        "            #‚Ü≥ aiuta a rendere la rete pi√π flessibile, non solo combinazioni lineari\n",
        "\n",
        "            #üß† Che cos‚Äô√® V?\n",
        "            #√à un tensore che rappresenta la versione trasformata delle patch,\n",
        "            #cio√® un modo ‚Äúintelligente‚Äù per codificare cosa contengono le patch dal punto di vista informativo.\n",
        "\n",
        "            #üî∏ V √® il contenuto informativo, \"cosa c‚Äô√® nella patch\".\n",
        "\n",
        "            U = self.sigmoid(self.attention_U(x))  # Shape: (batch_size, num_patches, inner_dim)\n",
        "            #üí° Cosa succede qui?\n",
        "            #self.attention_U(x)\n",
        "            #‚Ü≥ √® un altro layer lineare indipendente, con stessi input/output (64 ‚Üí 64)\n",
        "            #‚Ü≥ anche qui si trasforma ogni patch in un nuovo vettore di dimensione 64\n",
        "\n",
        "            #Poi passa tutto a self.sigmoid\n",
        "            #‚Ü≥ sigmoid √® una funzione non lineare che restituisce valori tra 0 e 1\n",
        "            #‚Ü≥ funziona come un \"filtro\": 0 ‚Üí spegne, 1 ‚Üí lascia passare, valori intermedi = pesa parzialmente\n",
        "\n",
        "            #üß† Che cos‚Äô√® U?\n",
        "            #√à il gate, cio√® un meccanismo che decide quanto del contenuto di ogni patch (quello in V) va fatto ‚Äúpassare‚Äù.\n",
        "\n",
        "            #üî∏ U √® il modulatore, \"quanto lasciar passare della patch\". Perch√© l‚Äôobiettivo non √® bloccare V ma usare U per modulare l'importanza del contenuto.\n",
        "\n",
        "            # Compute attention scores\n",
        "            attn_scores = self.attention_weights(V * U)  # Shape: (batch_size, num_patches, 1)-->Hai una moltiplicazione element-wise ‚Üí\n",
        "            # per ogni patch, moltiplichi V[i] * U[i]\n",
        "            #attentio_weights era un linear (inner_dim, 1) quindi passandogli V*U che √® (batch_size, num_patches, inner_dim)\n",
        "            #pythorc automaticamente gestisce usando solo le ultime due dimensioni di (batch_size, num_patches, inner_dim)\n",
        "            #lasciando batch_size cos√¨ com'√® e facendo poi (num_patches,inner_dim) * (inner_dim, 1) = (num_patches,1)\n",
        "            #infatti attn_scores ha dimensione (batch_size, num_patches, 1)\n",
        "\n",
        "            #Questo √® un processo per stimare i pesi di attenzione, non per applicarli.\n",
        "\n",
        "            attn_scores = torch.softmax(attn_scores, dim=1)  # Shape: (batch_size, num_patches, 1)-->per ogni paziente, la somma dei pesi delle patch = 1\n",
        "            #quel 1 finale sarebbe il nostro output finale, cio√® il punteggio di attenzione per ogni patch\n",
        "#Quindi non c‚Äô√® Q, K, V, ma c‚Äô√® comunque un meccanismo che:\n",
        "#elabora ogni patch\n",
        "#stima quanto pesa (attenzione)\n",
        "#fa una somma pesata\n",
        "#√à lo stesso spirito, ma pi√π leggero ü™∂\n",
        "\n",
        "            # Weighted sum of patch features\n",
        "            #ricordati che x = [1, num_patches, inner_dim]--> cio√®: 1 paziente, 1000 patch, 64 feature ciascuna\n",
        "            #ricordati che attn_scores= (1, num_patches, 1)-->un punteggio per ogni patch (calcolato con un Linear(64, 1) + softmax(dim=1))\n",
        "            #facendo torch.sum(attn_scores *x,dim = 1 ) stai andando a precisare lungo quale dimensione sommi e per questo motivo si annulla\n",
        "            #nella dimensione finale perch√® collassa\n",
        "            weighted_sum = torch.sum(attn_scores * x, dim=1)  # Shape: (batch_size, inner_dim)-->Ora hai ancora [1, num_patches, inner_dim], ma ogni patch √® pesata!\n",
        "            #ricordati che la regola dei tensori breadcasting dice che quando fai la somma ( in questo caso dim=1 ), qualle dimensione collassa; quindi il tensore\n",
        "            #finale sar√† [1,inner_dim]\n",
        "            weighted_sum = self.dropout(weighted_sum)\n",
        "\n",
        "            # Final WSI embedding\n",
        "            wsi_embedding = weighted_sum  #--> visto che hai sommato tutte le patch della wsi di quel paziente, mettiamo il risultato in wsi_embedding\n",
        "\n",
        "        if \"Genomics\" in self.input_modalities:\n",
        "            genomics = data[\"genomics\"]\n",
        "            genomics = self.genomics_dropout(genomics)\n",
        "            # Final Genomic embedding\n",
        "            genomics_embedding = self.fc_genomics(genomics)\n",
        "\n",
        "        if \"WSI\" in self.input_modalities and \"Genomics\" in self.input_modalities:\n",
        "            x = torch.cat([wsi_embedding,genomics_embedding], dim=1)\n",
        "        elif \"WSI\" in self.input_modalities:\n",
        "            x = wsi_embedding\n",
        "        elif \"Genomics\" in self.input_modalities:\n",
        "            x = genomics_embedding\n",
        "\n",
        "        output = self.output_layer(x)  # Shape: (batch_size, output_dim) -->Rappresenta l‚Äôoutput del modello per un singolo batch ‚Üí ha forma (batch_size, n_bins).\n",
        "        #dove batch size rappresenta un certo numero di pazienti e n_bins i bins di morte\n",
        "\n",
        "        return output"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sVS35Z3Wg5zh"
      },
      "source": [
        "### Survival Loss (SurvPath)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qBdEvJvvuntz"
      },
      "source": [
        "Questo blocco definisce una funzione di loss per un modello di sopravvivenza a tempo discreto, usata ad esempio per stimare quanto a lungo una persona sopravvive dopo una diagnosi, o in generale il tempo fino a un evento.\n",
        "\n",
        "Il modello restituisce h, cio√® i logit delle probabilit√† di morte in ciascun intervallo di tempo (hazards = sigmoid(h))."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 33,
      "metadata": {
        "execution": {
          "iopub.execute_input": "2024-12-13T17:12:59.902427Z",
          "iopub.status.busy": "2024-12-13T17:12:59.901681Z",
          "iopub.status.idle": "2024-12-13T17:12:59.912841Z",
          "shell.execute_reply": "2024-12-13T17:12:59.911922Z",
          "shell.execute_reply.started": "2024-12-13T17:12:59.902389Z"
        },
        "id": "1rLemMXUg5zh",
        "trusted": true
      },
      "outputs": [],
      "source": [
        "class NLLSurvLoss(nn.Module):\n",
        "    \"\"\"\n",
        "    The negative log-likelihood loss function for the discrete time to event model (Zadeh and Schmid, 2020).\n",
        "    Code borrowed from https://github.com/mahmoodlab/Patch-GCN/blob/master/utils/utils.py\n",
        "    Parameters\n",
        "    ----------\n",
        "    alpha: float\n",
        "        TODO: document\n",
        "    eps: float\n",
        "        Numerical constant; lower bound to avoid taking logs of tiny numbers.\n",
        "    reduction: str\n",
        "        Do we sum or average the loss function over the batches. Must be one of ['mean', 'sum']\n",
        "    \"\"\"\n",
        "\n",
        "    \"\"\"\n",
        "    Negative Log-Likelihood Loss per modelli di survival analysis in tempo discreto.\n",
        "\n",
        "    Questa loss √® basata sul lavoro di Zadeh e Schmid (2020), ed √® progettata per predire\n",
        "    la distribuzione della sopravvivenza in bin temporali discreti.\n",
        "\n",
        "    Il modello predice le hazard function (probabilit√† di morte a ogni bin),\n",
        "    e la loss misura la probabilit√† negativa (logaritmica) del percorso osservato.\n",
        "\n",
        "    Parameters\n",
        "    ----------\n",
        "    alpha : float, default=0.0\n",
        "        Peso tra censurati e non censurati.\n",
        "        - alpha = 0.0 ‚Üí considera entrambi\n",
        "        - alpha = 1.0 ‚Üí considera solo i non censurati (loss parziale)\n",
        "\n",
        "    eps : float, default=1e-7\n",
        "        Costante per stabilit√† numerica (evita log(0))\n",
        "\n",
        "    reduction : str, default='sum'\n",
        "        Come aggregare la loss sul batch:\n",
        "        - 'sum': somma totale--> restituisce la somma delle loss su tutti i pazienti del batch\n",
        "        - 'mean': media del batch--> restituisce la media delle loss\n",
        "\n",
        "        sum = Se vuoi che ogni batch contribuisca proporzionalmente al numero di esempi\n",
        "        mean = Se vuoi che ogni batch contribuisca allo stesso modo, indipendentemente dalla dimensione\n",
        "\n",
        "\n",
        "    References\n",
        "    ----------\n",
        "    Zadeh, S.G. & Schmid, M. (2020).\n",
        "    \"Bias in Cross-Entropy-Based Training of Deep Survival Networks\".\n",
        "    IEEE Transactions on Pattern Analysis and Machine Intelligence.\n",
        "    https://ieeexplore.ieee.org/document/9098975\n",
        "    \"\"\"\n",
        "\n",
        "    def __init__(self, alpha=0.0, eps=1e-7, reduction='sum'): #con alpha=0.0 --> Usa tutti i pazienti (censurati e non censurati), \n",
        "        #1.0--> Usa solo i non censurati\n",
        "        super().__init__()\n",
        "        self.alpha = alpha\n",
        "        self.eps = eps\n",
        "        self.reduction = reduction\n",
        "\n",
        "        if reduction not in ['mean', 'sum']:\n",
        "            raise ValueError(f\"Invalid reduction mode: {reduction}. Use 'mean' or 'sum'.\")\n",
        "        self.reduction = reduction\n",
        "\n",
        "    def __call__(self, h, y, t, c):\n",
        "        \"\"\"\n",
        "        Parameters\n",
        "        ----------\n",
        "        h: (n_batches, n_classes) -->L‚Äôoutput del tuo modello prima di applicare la sigmoid, Ogni riga √® un paziente, ogni colonna √® un intervallo temporale (un bin)\n",
        "            The neural network output discrete survival predictions such that hazards = sigmoid(h).\n",
        "        y_c: (n_batches, 2) or (n_batches, 3) --> n quale bin √® avvenuto l'evento o la censura\n",
        "            The true time bin label (first column) and censorship indicator (second column).\n",
        "        \"\"\"\n",
        "\n",
        "\n",
        "        \"\"\"\n",
        "        üß© y: label vera per ciascun paziente\n",
        "        √à un vettore (batch_size, 1)\n",
        "\n",
        "        Contiene, per ogni paziente, l‚Äôindice del bin in cui √® avvenuto l‚Äôevento (se c=0) o la censura (se c=1)\n",
        "\n",
        "        Ad esempio:\n",
        "\n",
        "        y = 3 ‚Üí l'evento o la censura √® avvenuto nel bin 3\n",
        "\n",
        "        h[i, :] ‚Üí tutti i logit per il paziente i\n",
        "\n",
        "        h[i, y[i]] ‚Üí logit per il bin effettivo osservato per il paziente i\n",
        "\n",
        "        üîÅ Quindi come si usano insieme?\n",
        "        Convertiamo h in hazards = sigmoid(h) ‚Üí ora ogni hazards[i][t] √® la probabilit√† che il paziente i muoia nel bin t.\n",
        "\n",
        "        Poi usiamo y per dire:\n",
        "\n",
        "        ‚ÄúFammi vedere la probabilit√† prevista per il bin giusto (quello in cui √® morto o censurato)‚Äù\n",
        "\n",
        "        Questa viene confrontata con l‚Äôosservazione reale (usando log probabilit√†) ‚Üí e usata per calcolare la loss.\n",
        "\n",
        "        üß† In pratica:\n",
        "        Per ogni paziente:\n",
        "\n",
        "        Cos‚Äôhai dal modello?\th[i, :] (logits) ‚Üí hazards[i, :] (probabilit√† di morire in ciascun bin)\n",
        "        Cos‚Äôhai dal dataset?\ty[i] = 3 ‚Üí evento/censura osservata nel bin 3\n",
        "        Cosa confronti?\tLa probabilit√† di sopravvivere fino a bin 2 (S(t-1)) e morire a bin 3 (h(t))\n",
        "        Come?\tCon log(S(t-1)) + log(h(t)) ‚Üí se non censurato; solo log(S(t)) se censurato\n",
        "\n",
        "        ‚úÖ Quindi:\n",
        "        h[i]: previsione del modello per il paziente i ‚Üí include tutti i bin\n",
        "\n",
        "        y[i]: dove √® avvenuto l‚Äôevento/censura per quel paziente--> ground truth\n",
        "\n",
        "        c[i]: ti dice se y[i] √® evento reale (morte) o solo censura\n",
        "\n",
        "        \"\"\"\n",
        "\n",
        "        \"\"\"\n",
        "        Parameters\n",
        "        ----------\n",
        "        h : torch.Tensor of shape (batch_size, n_bins)\n",
        "            Logits del modello (output grezzo prima della sigmoid).\n",
        "\n",
        "        y : torch.Tensor of shape (batch_size, 1)\n",
        "            Bin temporale in cui √® avvenuto l‚Äôevento (o la censura).\n",
        "\n",
        "        t : torch.Tensor or None\n",
        "            Tempo assoluto (non usato in questa loss).\n",
        "\n",
        "        c : torch.Tensor of shape (batch_size, 1)\n",
        "            Vettore binario: 0 = non censurato, 1 = censurato\n",
        "\n",
        "        Returns\n",
        "        -------\n",
        "        loss : torch.Tensor\n",
        "            Valore scalare della loss aggregata sul batch\n",
        "        \"\"\"\n",
        "        return nll_loss(h=h, y=y, c=c,\n",
        "                        alpha=self.alpha,\n",
        "                        eps=self.eps,\n",
        "                        reduction=self.reduction)\n",
        "\n",
        "\n",
        "# TODO: document better and clean up\n",
        "def nll_loss(h, y, c, alpha=0.0, eps=1e-7, reduction='sum'):\n",
        "    \"\"\"\n",
        "    The negative log-likelihood loss function for the discrete time to event model (Zadeh and Schmid, 2020).\n",
        "    Code borrowed from https://github.com/mahmoodlab/Patch-GCN/blob/master/utils/utils.py\n",
        "    Parameters\n",
        "    ----------\n",
        "    h: (n_batches, n_classes)\n",
        "        The neural network output discrete survival predictions such that hazards = sigmoid(h).\n",
        "    y: (n_batches, 1)\n",
        "        The true time bin index label.\n",
        "    c: (n_batches, 1)\n",
        "        The censoring status indicator.\n",
        "    alpha: float\n",
        "        The weight on uncensored loss\n",
        "    eps: float\n",
        "        Numerical constant; lower bound to avoid taking logs of tiny numbers.\n",
        "    reduction: str\n",
        "        Do we sum or average the loss function over the batches. Must be one of ['mean', 'sum']\n",
        "    References\n",
        "    ----------\n",
        "    Zadeh, S.G. and Schmid, M., 2020. Bias in cross-entropy-based training of deep survival networks. IEEE transactions on pattern analysis and machine intelligence.\n",
        "    \"\"\"\n",
        "    # print(\"h shape\", h.shape)\n",
        "\n",
        "    # make sure these are ints\n",
        "    #Questo assicura che y e c siano interi, perch√© tra poco useremo y per fare indexing con torch.gather(), e PyTorch richiede indici interi.\n",
        "    y = y.type(torch.int64)\n",
        "    c = c.type(torch.int64)\n",
        "\n",
        "    hazards = torch.sigmoid(h) #Ora hazards[t] = probabilit√† di morire nel bin t ‚Üí come abbiamo detto: ( ricordati che h sono i logit)\n",
        "    # print(\"hazards shape\", hazards.shape)\n",
        "\n",
        "    S = torch.cumprod(1 - hazards, dim=1) #Questo √® il calcolo classico della survival function discreta:\n",
        "    #La probabilit√† di sopravvivere fino al tempo t √® il prodotto delle probabilit√† di non morire a ogni tempo precedente.\n",
        "    #sarebbe la roba cumulativa-->S[t] = probabilit√† di sopravvivere fino al bin t,\n",
        "    #S[i][t] = probabilit√† che il paziente i sia sopravvissuto fino al tempo t\n",
        "    #hazards.shape = (batch_size, n_bins)\n",
        "    #S.shape = (batch_size, n_bins)\n",
        "    # print(\"S.shape\", S.shape, S)--> S √® un matrice dove batch_size sono i paziente e n_bins sono i bin\n",
        "    #S[t] √® la probabilit√† che un paziente sia sopravvissuto fino al tempo t\n",
        "    #Ma... quando calcoliamo la likelihood, abbiamo bisogno di accedere a S[t-1], non S[t].\n",
        "    #P(event at t) = S(t-1) * h(t)\n",
        "    #S(t-1) √® la probabilit√† di essere vivo fino a t-1\n",
        "    #h(t) √® la probabilit√† condizionata di morire proprio in t\n",
        "    #shape di c √® [batch_size, 1]\n",
        "    S_padded = torch.cat([torch.ones_like(c), S], 1) #-->Vogliamo accedere a S(t-1) quando y = t, quindi spostiamo tutto di uno e mettiamo:\n",
        "                                                       #S_padded[0] = 1.0 (vivi al tempo -1 per definizione)\n",
        "    # S(-1) = 0, all patients are alive from (-inf, 0) by definition\n",
        "    # after padding, S(0) = S[1], S(1) = S[2], etc, h(0) = h[0]\n",
        "    # hazards[y] = hazards(1)\n",
        "    # S[1] = S(1)\n",
        "    #[torch.ones_like(c), S]-->Crea un tensore di tutti 1.0, della stessa forma di c,c ha forma (batch_size, 1) ‚Üí quindi anche torch.ones_like(c) ha forma (batch_size, 1)\n",
        "    #Cosa fa [torch.ones_like(c), S]-->Costruisce una lista di due tensori: Uno con 1.0 (per ogni paziente), L‚Äôaltro √® S\n",
        "    #E cosa fa torch.cat(..., 1)?-->Concatena questi due tensori lungo la dimensione 1 (cio√® le colonne).\n",
        "    # Quindi aggiunge 1.0 come prima colonna di S.\n",
        "\n",
        "\n",
        "    #torch.ones_like √à un tensore di 1.0, con forma (batch_size, 1), Per ogni paziente, crea un 1 iniziale (cio√® S(-1) = 1.0)\n",
        "\n",
        "    #QUANDO PER√≤ ABBIAMO CENSURATO QUINDI c=0:\n",
        "    #Non sappiamo quando morir√†, sappiamo solo che √® sopravvissuto fino a un certo bin y. \n",
        "    # ‚ö†Ô∏è NOTA: Qui usiamo S(y) e NON h(y), perch√© non c‚Äô√® morte osservata, quindi il modello non deve \"indovinare quando\" morir√†.\n",
        "    #Deve solo prevedere correttamente che sia ancora vivo fino l√¨.\n",
        "\n",
        "    #üî¢ Esempio concreto\n",
        "    #Supponiamo:\n",
        "\n",
        "    #y = 2 ‚Üí il paziente √® stato censurato tra 2 e 3 anni\n",
        "\n",
        "    #c = 1 ‚Üí censurato\n",
        "\n",
        "    #S = [[0.9, 0.8, 0.6, 0.4]]\n",
        "\n",
        "    #Allora:\n",
        "\n",
        "    #S[y] = S[2] = 0.6\n",
        "    #Il paziente √® arrivato vivo fino al bin 2, quindi la loss sar√†:\n",
        "\n",
        "    #loss = -log(S(y)) = -log(0.6)\n",
        "\n",
        "\n",
        "    # TODO: document and check\n",
        "\n",
        "    # print(\"S_padded.shape\", S_padded.shape, S_padded)\n",
        "\n",
        "\n",
        "    #gather prende dei valori da un tenosore di input ( che ad esempio per s_prev √® S_padded, lungo la dim=1, quindi voglio andare a pescare\n",
        "    #tra le colonne e quindi i bin temporali). In questo caso vogliamo, per ogni paziente (righe), andare a prendere la colonna che corrisponde al bin y.\n",
        "    #Ma siccome S_padded √® costruito cos√¨:\n",
        "        #colonna 0 = S(-1) = 1.0\n",
        "        #colonna 1 = S(0)\n",
        "        #colonna 2 = S(1)\n",
        "        #colonna 3 = S(2)\n",
        "    #Se y = 2, allora S_padded[y] = S(t-1) = S(1)\n",
        "\n",
        "    # TODO: document/better naming\n",
        "    surv_before_event = torch.gather(S_padded, dim=1, index=y).clamp(min=eps)#S(t-1) ‚Üí Probabilit√† di essere vivo prima del bin di evento\n",
        "    #prende i dati da Da S_padded (include S(-1)=1)\n",
        "    hazard_at_event = torch.gather(hazards, dim=1, index=y).clamp(min=eps)#h(t) ‚Üí Hazard, probabilit√† di morire nel bin t\n",
        "    #prende i dati Da hazards = sigmoid(h)\n",
        "    surv_at_bin_end = torch.gather(S_padded, dim=1, index=y+1).clamp(min=eps)#\tS(t) ‚Üí Probabilit√† di essere vivo fino alla fine del bin t\n",
        "    #prende i dati Da S_padded\n",
        "    # print('s_prev.s_prev', s_prev.shape, s_prev)\n",
        "    # print('h_this.shape', h_this.shape, h_this)\n",
        "    # print('s_this.shape', s_this.shape, s_this)\n",
        "\n",
        "    # c = 1 means censored. Weight 0 in this case\n",
        "    #Hai un modello di sopravvivenza discreto che vuole imparare:\n",
        "    #Quando un paziente muore (non censurato), il modello deve:\n",
        "    #Prevedere che era vivo prima\n",
        "    #Prevedere che √® morto in quel bin\n",
        "\n",
        "    uncensored_loss = -(1 - c) * (torch.log(surv_before_event) + torch.log(hazard_at_event))# in questo caso il modello deve:\n",
        "    #1) Prevedere che il paziente era vivo fino a prima\n",
        "    #2) E che √® morto proprio in quel bin\n",
        "    censored_loss = - c * torch.log(surv_at_bin_end) #Il paziente √® vivo fino alla fine del bin t, ma non sappiamo cosa succede dopo. \n",
        "    #Il modello deve solo azzeccare la sopravvivenza.\n",
        "\n",
        "\n",
        "    # print('uncensored_loss.shape', uncensored_loss.shape)\n",
        "    # print('censored_loss.shape', censored_loss.shape)\n",
        "\n",
        "    neg_l = censored_loss + uncensored_loss#Somma delle due loss per ogni paziente. Ma possiamo ponderare con aplha\n",
        "    #Se alpha = 0.0 ‚Üí usi entrambi i tipi di loss\n",
        "    #Se alpha = 1.0 ‚Üí usi solo la parte non censurata\n",
        "    if alpha is not None:\n",
        "        loss = (1 - alpha) * neg_l + alpha * uncensored_loss\n",
        "\n",
        "    #Hai un valore di loss per ogni paziente. Ora lo:\n",
        "    #1)Sommi ‚Üí sum ‚Üí utile per tenere il totale\n",
        "    #2)Medii ‚Üí mean ‚Üí utile per confronti tra batch\n",
        "    if reduction == 'mean':\n",
        "        loss = loss.mean()\n",
        "    elif reduction == 'sum':\n",
        "        loss = loss.sum()\n",
        "    else:\n",
        "        raise ValueError(\"Bad input for reduction: {}\".format(reduction))\n",
        "\n",
        "    return loss"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Vu2MuOu2g5zi"
      },
      "source": [
        "### Select the model and define the hyperparameters"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 34,
      "metadata": {
        "execution": {
          "iopub.execute_input": "2024-12-13T17:37:45.297137Z",
          "iopub.status.busy": "2024-12-13T17:37:45.296209Z",
          "iopub.status.idle": "2024-12-13T17:37:45.323121Z",
          "shell.execute_reply": "2024-12-13T17:37:45.322347Z",
          "shell.execute_reply.started": "2024-12-13T17:37:45.297081Z"
        },
        "id": "-mghK3Rlg5zi",
        "trusted": true
      },
      "outputs": [],
      "source": [
        "# Models\n",
        "# device = \"cpu\"\n",
        "device = \"cuda\"\n",
        "\n",
        "models = {\n",
        "    'ABMIL_Multimodal': ABMIL_Multimodal, #definizione e configurazione dei modelli\n",
        "}\n",
        "model_configs = {  #Ogni modello ha un suo dizionario di parametri che in questo caso sono gli iperparametri del modello\n",
        "    'ABMIL_Multimodal': {\n",
        "         \"input_dim\":1024,\n",
        "         \"genomics_input_dim\" : 19962,\n",
        "         \"inner_dim\":64,\n",
        "         \"output_dim\":4,\n",
        "         \"use_layernorm\":False,\n",
        "         \"input_modalities\" : [\"WSI\", \"Genomics\"], # [\"WSI\", \"Genomics\"] # [\"WSI\"] # [\"Genomics\"]\n",
        "         \"genomics_dropout\": 0.5,\n",
        "         \"dropout\":0.0,\n",
        "    },\n",
        "}\n",
        "\n",
        "# Istantiate Model\n",
        "selected_model = \"ABMIL_Multimodal\"\n",
        "net = models[selected_model](**model_configs[selected_model]) #** √® lo unpacking dei parametri in Python: \n",
        "#Prende ogni coppia chiave: valore dal dizionario e la passa come se fosse scritta a mano:\n",
        "#ABMIL_Multimodal(input_dim=1024, genomics_input_dim=19962, ...)\n",
        "net = net.to(device)\n",
        "\n",
        "# Loss\n",
        "reduction = \"mean\" # sum or mean\n",
        "loss_function = NLLSurvLoss(alpha=0.0, eps=1e-7, reduction=reduction) #qui stai assegnando l'oggetto NLLSurvLoss con i suoi parametri a una variabile\n",
        "#chiamata \"loss_function\", quindi dal momento che in NLLSurvLoss √® presente il metodo __call__ che accetta anche altri parametri te potrai fare\n",
        "#una chiamata del tipo loss_function(h, y, t, c) in cui stai chiamando comunque l'oggetto NLLSurvLoss ma dal momento che dentro c'√® il metodo __call__\n",
        "#viene trattato come una funzione quindi loss_function(h, y, t, c) fa partire def __call__(self, h, y, t, c).\n",
        "#la chiamata a __call__ esegue la vera loss tra predizione e GT\n",
        "\n",
        "# Training Parameters\n",
        "MACHINE_BATCH_SIZE = 1 #  quanti pazienti riesci a elaborare per volta sulla tua GPU/CPU. (Quanti pazienti puoi caricare realmente in RAM/GPU per step (es. 1))\n",
        "TARGET_BATCH_SIZE = 8 #batch \"effettivo\" desiderato per la stabilit√† dell'ottimizzazione.(Quanto vorresti che fosse il batch effettivo (es. 8))\n",
        "NUM_ACCUMULATION_STEPS = TARGET_BATCH_SIZE//MACHINE_BATCH_SIZE #significa che accumuli il gradiente per 8 batch piccoli prima di fare un passo dell'ottimizzatore (simuli un batch pi√π grande).\n",
        "#\tQuanti step da 1 paziente devi fare prima di aggiornare i pesi (es. 8)\n",
        "\n",
        "EPOCHS = 10\n",
        "PATIENCE = 7\n",
        "DEBUG_BATCHES = 4\n",
        "\n",
        "# Optimizer\n",
        "LR = 0.001 #Learning Rate: quanto velocemente il modello aggiorna i pesi\n",
        "WEIGHT_DECAY = 0.0001 #Regolarizzazione L2 ‚Üí evita overfitting penalizzando pesi grandi\n",
        "optimizer = optim.RAdam( #√à una variante di Adam, ma pi√π stabile all'inizio del training (R sta per \"Rectified\"). meno oscillazioni iniziali.\n",
        "                          net.parameters(),\n",
        "                          lr=LR,\n",
        "                          weight_decay=WEIGHT_DECAY,\n",
        "            )\n",
        "# Scheduler\n",
        "scheduler_parameters = {\n",
        "  \"milestones\": [], #qui puoi provare a mettere qualcosa, se ad esempio metti 10 vuol dire che all'epoca 10 avrei moltiplicato il learning rate \n",
        "  #per gamma (0.1) in modo da ridurre il learning rate e quindi rallentare il training\n",
        "  \"gamma\": 0.1 #Fattore di riduzione ‚Üí ogni volta che colpisci una milestone, moltiplichi lr per 0.1\n",
        "}\n",
        "scheduler = torch.optim.lr_scheduler.MultiStepLR(optimizer, **scheduler_parameters)\n",
        "\n",
        "#L‚Äôottimizzatore aggiorna i pesi del modello ad ogni batch.\n",
        "#Il scheduler cambia la velocit√† (learning rate) con cui aggiorni, per adattarsi al progresso del training.\n",
        "#Ad esempio se milestone = 10 Viene ridotta di 10 volte (√ó0.1) a ogni milestone: epoca 10, 20 e 30\n",
        "#Serve per rallentare il learning man mano che il modello si avvicina a una buona soluzione"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cpS465Cig5zi"
      },
      "source": [
        "# Dataset Creation"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "üß† Cosa stiamo facendo in generale?\n",
        "Nel deep learning non possiamo caricare tutti i dati in RAM in una volta sola (troppo pesanti). Allora si usano i DataLoader che:\n",
        "\n",
        "Prendono i dati a blocchi (batch).\n",
        "\n",
        "Possono mischiarli (per il training).\n",
        "\n",
        "Possono usarli in parallelo (pi√π CPU ‚Üí pi√π veloce).\n",
        "\n",
        "Passano i dati gi√† pronti alla rete neurale."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "üîç Cosa fa questa funzione get_dataloaders(...)?\n",
        "Serve per costruire 3 gruppi di pazienti:\n",
        "\n",
        "train_patients: per insegnare al modello.\n",
        "\n",
        "val_patients: per controllare come sta andando durante l‚Äôallenamento.\n",
        "\n",
        "test_patients: per misurare le prestazioni finali."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "üöÇ Il viaggio dei dati dal Dataset al Modello\n",
        "1. Hai un dataset (grande)\n",
        "Immagina di avere 10.000 pazienti salvati nel tuo Dataset, ognuno con immagini e dati genomici.\n",
        "\n",
        "2. Serve un dataloader: il treno dei dati\n",
        "Il DataLoader crea dei ‚Äútreni‚Äù di dati:\n",
        "\n",
        "Ogni vagone √® un batch (es. 8 pazienti).\n",
        "\n",
        "Ogni volta che la rete ha finito un batch, dice: ‚Äúprossimo batch, prego!‚Äù.\n",
        "\n",
        "3. Come carichiamo i batch?\n",
        "üî∏ Caso base ‚Äì num_workers = 0 (solo 1 persona carica a mano)\n",
        "Il DataLoader aspetta che il modello chieda il batch.\n",
        "\n",
        "Poi apre il file, legge i dati, li prepara (es. normalizza), e li manda al modello.\n",
        "\n",
        "Ogni volta deve aspettare.\n",
        "\n",
        "üëâ √à come avere 1 persona che cucina una pizza solo dopo che gliel'hai ordinata.\n",
        "\n",
        "üî∏ Caso avanzato ‚Äì num_workers = 4 (4 persone che cucinano in parallelo)\n",
        "Prima ancora che il modello chieda, 4 cuochi stanno gi√† preparando le pizze (i batch).\n",
        "\n",
        "Appena il modello finisce di mangiare, un altro batch √® gi√† pronto.\n",
        "\n",
        "üëâ Questo √® il prefetch: preparare in anticipo i dati prima che servano.\n",
        "\n",
        "4. Prefetch factor: quanti piatti prepara ogni cuoco?\n",
        "prefetch_factor = 4 = ogni cuoco prepara 4 pizze in anticipo.\n",
        "\n",
        "Quindi hai 16 batch pronti nel forno, pronti da servire üî•.\n",
        "\n",
        "\n",
        "üöö Come funziona davvero?\n",
        "Il DataLoader prende un batch (es. 8 pazienti) dal disco.\n",
        "\n",
        "Lo carica in RAM.\n",
        "\n",
        "Lo passa alla GPU o CPU (dove sta il modello).\n",
        "\n",
        "Quando il modello ha finito, il DataLoader carica il prossimo batch in RAM."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 35,
      "metadata": {
        "execution": {
          "iopub.execute_input": "2024-12-13T17:13:23.11561Z",
          "iopub.status.busy": "2024-12-13T17:13:23.11514Z",
          "iopub.status.idle": "2024-12-13T17:13:23.124625Z",
          "shell.execute_reply": "2024-12-13T17:13:23.123559Z",
          "shell.execute_reply.started": "2024-12-13T17:13:23.115578Z"
        },
        "id": "jzKY623_g5zi",
        "trusted": true
      },
      "outputs": [],
      "source": [
        "def get_dataloaders(dataset, train_patients, val_patients, test_patients, data_loader_config):\n",
        "    #dataset.patient_df.index √® la lista dei pazienti presenti realmente nel dataset. creato all‚Äôinterno\n",
        "    #  della classe Multimodal_WSI_Genomic_Dataset\n",
        "    #train_patients √® una lista (o array) con ID dei pazienti che vuoi usare per il training.\n",
        "    #np.isin(...) crea un array booleano che dice ‚Äúquesto paziente √® davvero presente?‚Äù\n",
        "    mask = np.isin(train_patients, dataset.patient_df.index) #Controlla se alcuni ID in train_patients non esistono realmente nel dataset\n",
        "    #(dopo il filtro con .isin()).\n",
        "    # Filter the array to keep only elements in df.index\n",
        "    filtered_train_patients = train_patients[mask]\n",
        "    if len(filtered_train_patients) != len(train_patients):\n",
        "        print(\"Some train patients are not in the dataset: \", set(train_patients) - set(filtered_train_patients))\n",
        "    prefetch_factor = 4 #prefetch_factor serve per dire quanti batch il DataLoader pu√≤ ‚Äúprecaricare‚Äù in anticipo in background. \n",
        "    #Qui stiamo dicendo 4 batch\n",
        "    if data_loader_config.num_workers == 0: #Se non usi worker multipli (num_workers = 0), non ha senso precaricare ‚Üí lo disabilita con None\n",
        "        prefetch_factor = None\n",
        "    train_dataloader = DataLoader( #Creare un DataLoader per il training, che carica dati dal dataset solo per i pazienti \n",
        "                                    #di training (filtered_train_patients) e li prepara a blocchi per il modello.\n",
        "\n",
        "                                Subset(dataset, filtered_train_patients), #Qui crei un sottoinsieme del dataset contenente solo i pazienti \n",
        "                                #di training.\n",
        "                                #filtered_train_patients √® una lista di indici (ID pazienti presenti sia nel file che nel dataset).\n",
        "                                batch_size=data_loader_config.batch_size, #Quanti pazienti vengono caricati contemporaneamente nella RAM. Esempio: se √® 8, significa 8 pazienti per batch.\n",
        "                                shuffle=True, #Mescola i dati ad ogni epoca (fondamentale per il training).\n",
        "                                drop_last=True, #Se l‚Äôultimo batch ha meno di batch_size pazienti, lo scarta. Serve a mantenere batch sempre uguali per compatibilit√† (es. batch norm).\n",
        "                                pin_memory=True, #Copia pi√π velocemente i dati dalla RAM alla GPU.\n",
        "                                num_workers=data_loader_config.num_workers, #Quanti processi paralleli usi per caricare i dati.\n",
        "                                prefetch_factor=prefetch_factor #Quanti batch caricare in anticipo per ogni worker. \n",
        "                            )\n",
        "    if val_patients is not None: # Se hai specificato dei pazienti per il validation set, allora procedi.\n",
        "        mask = np.isin(val_patients, dataset.patient_df.index) #Tiene solo i pazienti che esistono davvero nel dataset (serve a evitare errori).\n",
        "        filtered_val_patients = val_patients[mask]\n",
        "        if len(filtered_val_patients) != len(val_patients):\n",
        "            print(\"Some val patients are not in the dataset: \", set(val_patients) - set(filtered_val_patients))\n",
        "        batch_size = data_loader_config.batch_size\n",
        "        if data_loader_config.test_sample == False: # Se sei in fase di test (no sampling), il batch size diventa 1.\n",
        "            #Questo serve per processare un paziente alla volta, utile in validazione per evitare mescolamenti e per metriche individuali.\n",
        "            batch_size = 1 #Perch√© in certi esperimenti, la validazione viene fatta paziente per paziente (come nel test) per calcolare metriche individuali.\n",
        "        val_dataloader = DataLoader( #che contiene i dati di validazion set\n",
        "                                        Subset(dataset, filtered_val_patients),\n",
        "                                        batch_size=batch_size,\n",
        "                                        shuffle=False,\n",
        "                                        drop_last=False,\n",
        "                                        pin_memory=True,\n",
        "                                        num_workers=data_loader_config.num_workers,\n",
        "                                        prefetch_factor=prefetch_factor,\n",
        "                                )\n",
        "    else:\n",
        "        val_dataloader = None #Se non hai un validation set, restituisce None.\n",
        "    if test_patients is not None:\n",
        "        mask = np.isin(test_patients, dataset.patient_df.index)\n",
        "        filtered_test_patients = test_patients[mask]\n",
        "        if len(filtered_test_patients) != len(test_patients):\n",
        "            print(\"Some test patients are not in the dataset: \", set(test_patients) - set(filtered_test_patients))\n",
        "        batch_size = data_loader_config.batch_size\n",
        "        if data_loader_config.test_sample == False:\n",
        "            batch_size = 1\n",
        "        test_dataloader = DataLoader(\n",
        "                                        Subset(dataset, filtered_test_patients),\n",
        "                                        batch_size=batch_size,\n",
        "                                        shuffle=False,\n",
        "                                        drop_last=False,\n",
        "                                        pin_memory=True,\n",
        "                                        num_workers=data_loader_config.num_workers,\n",
        "                                        prefetch_factor=prefetch_factor,\n",
        "                                    )\n",
        "    else:\n",
        "        test_dataloader = None\n",
        "    return train_dataloader, val_dataloader, test_dataloader"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "execution": {
          "iopub.execute_input": "2024-12-13T17:13:26.950864Z",
          "iopub.status.busy": "2024-12-13T17:13:26.95053Z",
          "iopub.status.idle": "2024-12-13T17:13:26.956475Z",
          "shell.execute_reply": "2024-12-13T17:13:26.955595Z",
          "shell.execute_reply.started": "2024-12-13T17:13:26.950831Z"
        },
        "id": "1RaSnsskg5zj",
        "trusted": true
      },
      "outputs": [],
      "source": [
        "data_loader_config = {\n",
        "  \"datasets_configs\": [TCGA_BRCA_dataset_config],\n",
        "  \"task_type\": \"Survival\",\n",
        "  \"max_patches\": 4096, \n",
        "  \"batch_size\": MACHINE_BATCH_SIZE,\n",
        "  \"real_batch_size\": TARGET_BATCH_SIZE,\n",
        "  \"n_bins\": 4,\n",
        "  \"sample\": True,        # sample patches during train\n",
        "  \"test_sample\": False,   # use all available patches during testing\n",
        "  \"load_slides_in_RAM\": True,  # load in RAM patches for increasing data loading speed\n",
        "  \"label_name\": \"FUT\",\n",
        "  \"censorships_name\": \"Survival\",\n",
        "  \"eps\": 0.000001,\n",
        "  \"num_workers\": 1,\n",
        "  \"train_size\": 0.7,\n",
        "  \"val_size\": 0.15,\n",
        "  \"test_size\": 0.15,\n",
        "  \"random_state\": 42,\n",
        "}\n",
        "\n",
        "data_loader_config = Munch.fromDict(data_loader_config)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 37,
      "metadata": {
        "execution": {
          "iopub.execute_input": "2024-12-13T17:13:39.385498Z",
          "iopub.status.busy": "2024-12-13T17:13:39.384658Z",
          "iopub.status.idle": "2024-12-13T17:13:49.353589Z",
          "shell.execute_reply": "2024-12-13T17:13:49.352623Z",
          "shell.execute_reply.started": "2024-12-13T17:13:39.385459Z"
        },
        "id": "ewL9Hx2Ag5zj",
        "trusted": true
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Dataset loaded with 1058 slides and 1058 patients\n"
          ]
        }
      ],
      "source": [
        "dataset = Multimodal_WSI_Genomic_Dataset(\n",
        "                        datasets_configs=data_loader_config.datasets_configs,\n",
        "                        task_type=data_loader_config.task_type,\n",
        "                        max_patches=data_loader_config.max_patches,\n",
        "                        n_bins=data_loader_config.n_bins,\n",
        "                        eps=data_loader_config.eps,\n",
        "                        sample=data_loader_config.sample,\n",
        "                        load_slides_in_RAM=data_loader_config.load_slides_in_RAM,\n",
        "                    )"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 38,
      "metadata": {
        "execution": {
          "iopub.execute_input": "2024-12-13T17:13:49.35521Z",
          "iopub.status.busy": "2024-12-13T17:13:49.354907Z",
          "iopub.status.idle": "2024-12-13T17:13:50.588217Z",
          "shell.execute_reply": "2024-12-13T17:13:50.587287Z",
          "shell.execute_reply.started": "2024-12-13T17:13:49.355182Z"
        },
        "id": "-KOD5Jrcg5zj",
        "trusted": true
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Train: 740, Val: 159, Test: 159\n"
          ]
        }
      ],
      "source": [
        "#qui vengono definiti i dati di training, validazione e test, e poi passati ai rispettivi DataLoader\n",
        "#Divide gli ID dei pazienti in tre gruppi:\n",
        "#√à solo una divisione logica, cio√® restituisce 3 liste di ID pazienti.\n",
        "#Parametri:\n",
        "\n",
        "#train_size, val_size, test_size: percentuali o numeri assoluti per definire le dimensioni dei set.\n",
        "#random_state: seme per la riproducibilit√† ‚Üí garantisce sempre la stessa divisione se ri-esegui il codice.\n",
        "\n",
        "\n",
        "\n",
        "# GET INDICES FOR TRAIN, VALIDATION, AND TEST SETS\n",
        "train_patients, val_patients, test_patients = dataset.get_train_test_val_splits(\n",
        "                                                                                train_size=data_loader_config.train_size,\n",
        "                                                                                val_size=data_loader_config.val_size,\n",
        "                                                                                test_size=data_loader_config.test_size,\n",
        "                                                                                random_state=data_loader_config.random_state\n",
        "                                                                            )\n",
        "\n",
        "#Prende le liste di pazienti e il dataset.\n",
        "#Per ogni set (train/val/test), costruisce un DataLoader ‚Üí che sar√† usato per passare i dati al modello.\n",
        "# Questo √® proprio il punto in cui la tua rete inizia a ricevere batch di dati dal dataset, grazie a PyTorch DataLoader.\n",
        "train_dataloader, val_dataloader, test_dataloader = get_dataloaders(\n",
        "                                                                    dataset=dataset,\n",
        "                                                                    train_patients=train_patients,\n",
        "                                                                    val_patients=val_patients,\n",
        "                                                                    test_patients=test_patients,\n",
        "                                                                    data_loader_config=data_loader_config\n",
        "                                                                    )"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GtyC1HiMg5zj"
      },
      "source": [
        "### Utility"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 39,
      "metadata": {
        "execution": {
          "iopub.execute_input": "2024-12-13T17:13:56.582876Z",
          "iopub.status.busy": "2024-12-13T17:13:56.582563Z",
          "iopub.status.idle": "2024-12-13T17:13:56.587735Z",
          "shell.execute_reply": "2024-12-13T17:13:56.586744Z",
          "shell.execute_reply.started": "2024-12-13T17:13:56.582847Z"
        },
        "id": "TUUEnOPNg5zj",
        "trusted": true
      },
      "outputs": [],
      "source": [
        "def __reload_net__(path, device='cuda'):  #path: √® il percorso del file .pt o .pth che contiene i pesi salvati del modello.\n",
        "    if device == 'cuda': #device: specifica se vuoi caricare i pesi sulla GPU (cuda) o sulla CPU.\n",
        "        print(f'\\nRestoring model weigths from: {path}')\n",
        "        return torch.load(path) #torch.load(path) carica direttamente i pesi sul dispositivo di default (in questo caso GPU, se disponibile).\n",
        "    else: #Se stai lavorando su CPU, aggiunge map_location=torch.device('cpu') per forzare il caricamento dei pesi sulla CPU, anche se erano stati salvati da una GPU.\n",
        "        print(f'\\nRestoring model weigths from: {path}')\n",
        "        return torch.load(path, map_location=torch.device('cpu'))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "ella funzione nll_loss facciamo qualcosa di molto simile ‚Äì calcoliamo i hazards e la curva di sopravvivenza (S), proprio come in calculate_risk.\n",
        "\n",
        "In nll_loss:\n",
        "hazards = torch.sigmoid(h)\n",
        "S = torch.cumprod(1 - hazards, dim=1)\n",
        "\n",
        "In calculate_risk:\n",
        "hazards = torch.sigmoid(h)\n",
        "survival = torch.cumprod(1 - hazards, dim=1)\n",
        "\n",
        "Quindi in entrambi i casi:\n",
        "Partiamo dai logits (h)\n",
        "Applichiamo sigmoid per ottenere le hazard probabilities\n",
        "Calcoliamo la curva cumulativa di sopravvivenza\n",
        "\n",
        "La differenza √® nel contesto d'uso:\n",
        "nll_loss --> ha come scopo: Calcolare la loss per training--> Output: loss (scalar)\n",
        "calculate_risk --> ha come scopo: Calcolare la rischiosit√† e S(t) --> Output: risk, survival (2 array)\n",
        "\n",
        "nll_loss √® usata durante l‚Äôaddestramento, per aggiornare i pesi\n",
        "calculate_risk √® usata dopo, per stimare il rischio complessivo e creare metriche.\n",
        "\n",
        "Pensa a calculate_risk come a una funzione di diagnostica sul modello, mentre nll_loss √® la funzione di apprendimento."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 40,
      "metadata": {
        "execution": {
          "iopub.execute_input": "2024-12-13T17:14:00.112267Z",
          "iopub.status.busy": "2024-12-13T17:14:00.111651Z",
          "iopub.status.idle": "2024-12-13T17:14:00.125293Z",
          "shell.execute_reply": "2024-12-13T17:14:00.124369Z",
          "shell.execute_reply.started": "2024-12-13T17:14:00.11223Z"
        },
        "id": "W8o0yNwCg5zj",
        "trusted": true
      },
      "outputs": [],
      "source": [
        "#Questa funzione ( calculate_risk) trasforma i logits del modello (h) in un punteggio di rischio e in una curva di sopravvivenza discreta, per ogni paziente.\n",
        "def calculate_risk(h):\n",
        "    r\"\"\"\n",
        "    Take the logits of the model and calculate the risk for the patient\n",
        "\n",
        "    Args:\n",
        "        - h : torch.Tensor\n",
        "\n",
        "    Returns:\n",
        "        - risk : torch.Tensor\n",
        "\n",
        "    \"\"\"\n",
        "    hazards = torch.sigmoid(h) #Applichi la sigmoid sui logits h per ottenere probabilit√† tra 0 e 1\n",
        "    survival = torch.cumprod(1 - hazards, dim=1) #Costruisci la sequenza cumulativa di sopravvivenza, √à la probabilit√† che il paziente\n",
        "    #sopravviva fino al bin t\n",
        "    risk = -torch.sum(survival, dim=1).detach().cpu().numpy() #Ottieni un punteggio di rischio sommando tutta la curva di sopravvivenza \n",
        "    #(e cambiando segno):\n",
        "    #pi√π alta la somma => tendenza a sopravvivere => rischio basso (valore pi√π negativo)\n",
        "    #pi√π bassa => sopravvivenza breve => rischio alto\n",
        "    return risk, survival.detach().cpu().numpy() #Converti tutto in array NumPy e restituisci entrambi.\n",
        "\n",
        "def initialize_metrics_dict(task_type=\"Survival\"):\n",
        "    #Obiettivo: Creare un contenitore vuoto dove salvare tutte le metriche (per tipo di task).\n",
        "    #Dove viene usata: All‚Äôinizio di una fase di training, validazione o test ‚Äî dentro la funzione step() o all‚Äôinizio dei loop di train()/evaluate().\n",
        "    log_dict = {}\n",
        "    if task_type == \"Survival\": #Esempio: per Survival salva rischi, tempi evento, censura, ecc. Serve per poi fare il calcolo delle metriche.\n",
        "        log_dict[\"all_risk_scores\"] = []\n",
        "        log_dict[\"all_censorships\"] = []\n",
        "        log_dict[\"all_event_times\"] = []\n",
        "        log_dict[\"all_original_event_times\"] = []\n",
        "        log_dict[\"survival_predictions\"] = []\n",
        "    elif task_type == \"Treatment_Response\":\n",
        "        log_dict[\"all_labels\"] = []\n",
        "        log_dict[\"treatment_response_predictions\"] = []\n",
        "        log_dict[\"treatment_response_logits\"] = []\n",
        "    else:\n",
        "        raise Exception(f\"{task_type} is not supported!\")\n",
        "    log_dict[\"patient_ids\"] = []\n",
        "    log_dict[\"dataset_name\"] = []\n",
        "    return log_dict\n",
        "\n",
        "def compute_metrics_dict(log_dict): \n",
        "    #Obiettivo: Dato un log_dict (con i dati salvati durante l'inferenza), calcola il C-Index, una metrica classica della survival analysis.\n",
        "    #Il C-index misura quanto bene il modello ordina i pazienti in base al rischio.\n",
        "    #Quindi confronta le predizioni del modello con la ground_truth e li confronta tramite C-index\n",
        "    #üß† Cos‚Äô√® il C-Index?\n",
        "    #Il Concordance Index verifica:\n",
        "\n",
        "    #‚ÄúIl paziente che √® morto prima ha un rischio predetto pi√π alto?‚Äù\n",
        "\n",
        "    #Se la risposta √® s√¨ per molte coppie ‚Üí buon modello!\n",
        "    #Il C-Index varia da 0.5 (casuale) a 1.0 (perfetto).\n",
        "\n",
        "    # Dove viene usata: Principalmente per logging rapido: bastano rischi, censorship e event_times.\n",
        "    # Cosa fa:\n",
        "    #Estrae dai rispettivi elenchi i vettori numpy.\n",
        "    #Calcola il C-index (metrica di ordinazione del rischio).\n",
        "    #Ritorna un dizionario semplice: {\"c-index\": valore}.\n",
        "\n",
        "\n",
        "    metrics_dict = {} #Inizializza un dizionario dove salveremo le metriche calcolate.\n",
        "\n",
        "    #poi Recupera dal log_dict (che contiene i dati raccolti durante il test):\n",
        "    all_risk_scores = np.array(log_dict[\"all_risk_scores\"]) #i punteggi di rischio previsti per ogni paziente.\n",
        "    all_censorships = np.array(log_dict[\"all_censorships\"]) #1 = censurato, 0 = non censurato.\n",
        "    all_event_times = np.array(log_dict[\"all_event_times\"]) # in che bin √® successo l‚Äôevento (morte, censura...).\n",
        "    c_index = concordance_index_censored((1-all_censorships).astype(bool), all_event_times, all_risk_scores, tied_tol=1e-08)[0]\n",
        "    #la funzione concordance_index_censored deriva da una libreria:\n",
        "    #1 - all_censorships: trasforma: 1 (censurato) ‚Üí 0 (non evento osservato) e 0 (non censurato) ‚Üí 1 (evento osservato)\n",
        "    #Cos√¨ ottieni il booleano ‚Äúevento osservato‚Äù.\n",
        "    #Si calcola il C-Index: Confronta tutte le coppie di pazienti.\n",
        "    #Considera solo quelle non censurate (cio√® dove si sa chi √® morto prima).\n",
        "    #Verifica se il rischio predetto √® coerente con l‚Äôordine reale.\n",
        "    #[0]: estrae solo il valore del C-Index (gli altri valori sono diagnostici).\n",
        "    metrics_dict[\"c-index\"] = c_index\n",
        "    #quind il c index fa bene il suo lavoro se predice un rischio di morire alto per un paziente che dovrebbe morire prima\n",
        "    #Il C-Index (concordance index) √® fatto proprio per valutare quanto bene un modello:\n",
        "    #Ordina i pazienti in base al rischio predetto\n",
        "    # In modo che chi muore prima abbia un rischio pi√π alto\n",
        "\n",
        "    #Se il modello assegna un rischio maggiore a chi morir√† prima (o ha avuto l‚Äôevento prima), allora:\n",
        "    #üëâ √à concordante con la realt√†\n",
        "    #üëâ Il C-Index si avvicina a 1.0 (perfetto)\n",
        "    #Il C-Index non misura quanto sei preciso nel tempo esatto della morte, ma quanto sei bravo a capire chi morir√† prima rispetto agli altri.\n",
        "    return metrics_dict\n",
        "\n",
        "def compute_metrics(log_df, task_type=\"Survival\", device=\"cuda\"): \n",
        "    #Obiettivo: Calcolare le metriche di valutazione in base al tipo di task:\n",
        "    #Dove viene usata: Viene chiamata alla fine di un blocco, passando log_df, ovvero un DataFrame costruito da log_dict.\n",
        "    #üìã Cosa fa:\n",
        "    #Estrae array: all_risk_scores, censorships, event_times, outputs, ecc.\n",
        "    #Ricalcola C-index usando la funzione da compute_metrics_dict.\n",
        "    #Ricalcola la loss chiamando loss_function(...), passando:\n",
        "    #outputs (logits),\n",
        "    #event_times,\n",
        "    #censorships.\n",
        "    #Ritorna un dizionario con {\"c-index\": valore, \"Loss\": valore} (o le metriche di classificazione, se il task √® Treatment_Response).\n",
        "\n",
        "    if task_type == \"Survival\":\n",
        "        #Qui si estraggono i dati salvati durante l‚Äôinferenza:\n",
        "        all_risk_scores = log_df[\"all_risk_scores\"].values\n",
        "        all_censorships = log_df[\"all_censorships\"].values\n",
        "        all_event_times = log_df[\"all_event_times\"].values #tempo (bin) in cui √® avvenuto l‚Äôevento\n",
        "        outputs = log_df[\"survival_predictions\"].values #outputs: la curva di sopravvivenza predetta (i binari da sigmoid(h))\n",
        "        c_index = concordance_index_censored((1-all_censorships).astype(bool), all_event_times, all_risk_scores, tied_tol=1e-08)[0]\n",
        "        loss = loss_function(torch.tensor(outputs.tolist()), torch.tensor(all_event_times).unsqueeze(-1), None, torch.tensor(all_censorships).unsqueeze(-1))\n",
        "        metrics_dict = {\"c-index\": c_index, \"Loss\": loss}\n",
        "    elif task_type == \"Treatment_Response\": #Simile alla classificazione binaria:\n",
        "        all_labels = log_df[\"all_labels\"].values\n",
        "        all_predictions = log_df[\"treatment_response_predictions\"].values\n",
        "        all_logits = torch.tensor(log_df[\"treatment_response_logits\"].tolist())\n",
        "        # Calculate AUC\n",
        "        logits_for_auc = torch.softmax(all_logits, dim=1).numpy()[:, 1] \n",
        "        auc = roc_auc_score(all_labels, logits_for_auc) ##AUC: con softmax e probabilit√† della classe 1\n",
        "        f1 = f1_score(all_labels, all_predictions, average='macro') #F1 Score: media delle F1 sui due classi\n",
        "        accuracy = np.mean(all_labels == all_predictions) #Accuracy: percentuale di predizioni corrette\n",
        "        # Calculate loss --> Qui loss_function sar√† una loss diversa (es. cross entropy), compatibile con task di classificazione.\n",
        "        all_logits = all_logits.to(device)\n",
        "        all_labels = torch.tensor(all_labels).long().to(device)\n",
        "        loss = loss_function(all_logits, all_labels)\n",
        "        metrics_dict = {\"AUC\": auc, \"Loss\": loss, \"Accuracy\": accuracy, \"F1-Score\": f1}\n",
        "    else:\n",
        "        raise Exception(f\"{task_type} is not supported!\")\n",
        "    return metrics_dict\n",
        "\n",
        "def compute_metrics_df(log_df, task_type=\"Survival\"):\n",
        "    #Obiettivo: \n",
        "    # Calcolare le metriche globali (su tutto il dataset) e per ogni sotto-dataset (ad esempio se i dati provengono da ospedali diversi o gruppi distinti).\n",
        "    # Dove viene usata: Generalmente dopo che compute_metrics √® gi√† stata eseguita e abbiamo prodotti globali e per sottoinsiemi.\n",
        "    #üìã Cosa fa:\n",
        "    #Chiama compute_metrics(log_df, ...) per metriche globali.\n",
        "    #Itera su ogni dataset_name presente in log_df, costruendo sotto-DataFrame separati.\n",
        "    #Richiama compute_metrics(...) per ciascun sottoinsieme, generando metriche specifiche per dataset.\n",
        "    #Unisce tutto in un unico dizionario completo.\n",
        "\n",
        "    metrics_dict = {}\n",
        "    curr_metrics_dict = compute_metrics(log_df, task_type) #Chiama la funzione compute_metrics su tutto log_df\n",
        "    metrics_dict.update(curr_metrics_dict) #Salva i risultati (es. {\"c-index\": 0.78, \"Loss\": 0.54}) in metrics_dict\n",
        "\n",
        "    #Calcola le metriche per ogni dataset\n",
        "    dataset_names = log_df[\"dataset_name\"].unique() #Trova i nomi unici dei dataset (es. [\"TCGA\", \"OTHER_HOSPITAL\"]).\n",
        "    #per ciascuno fa:\n",
        "    for dataset in dataset_names:\n",
        "        dataset_df = log_df[log_df[\"dataset_name\"]==dataset]\n",
        "        curr_metrics_dict = compute_metrics(dataset_df, task_type)\n",
        "        for key, value in curr_metrics_dict.items():\n",
        "            metrics_dict[f\"{dataset}_{key}\"] = value\n",
        "            metrics_dict[f\"{dataset}_{key}\"] = value\n",
        "\n",
        "    #Conversione tensori in numeri: Per sicurezza, se una metrica √® un tensore PyTorch, viene convertita in float Python (es. tensor(0.88) ‚Üí 0.88).\n",
        "    metrics_dict = {k: v.item() if isinstance(v, torch.Tensor) else v for k, v in metrics_dict.items()}\n",
        "    return metrics_dict\n",
        "\n",
        "#‚úÖ Quando usarla?\n",
        "#Alla fine della valutazione, per avere un quadro completo delle performance, sia globali che per dataset specifico.\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "üìå Flusso di chiamata\n",
        "Training/validazione/test loop avvia initialize_metrics_dict.\n",
        "\n",
        "Ad ogni batch si chiama step() ‚Üí popola log_dict.\n",
        "\n",
        "Al termine del ciclo:\n",
        "\n",
        "Si converte log_dict in un DataFrame log_df.\n",
        "\n",
        "Si calcolano metriche globali e per dataset con:\n",
        "\n",
        "compute_metrics() + compute_metrics_df().\n",
        "\n",
        "Si registrano (es. su CSV, console o log dashboard).\n",
        "\n",
        "Questo flusso poi si ripete a ogni epoca o fase (train, val, test)\n",
        "\n",
        "\n",
        "‚úÖ In breve\n",
        "initialize_metrics_dict: prepara contenitore vuoto.\n",
        "\n",
        "step: riempie contenitore per ogni batch.\n",
        "\n",
        "compute_metrics: calcola metriche su un intero log_df.\n",
        "\n",
        "compute_metrics_df: calcola metriche globali + breakdown per ogni dataset."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "üß† Differenza tra risk e survival\n",
        "üî∑ survival\n",
        "survival √® la curva di sopravvivenza per ogni paziente. √à una matrice con dimensione:\n",
        "\n",
        "(batch_size, n_bins)\n",
        "Ogni riga rappresenta un paziente, e ogni colonna la probabilit√† che quel paziente sia ancora vivo al tempo del bin t.\n",
        "\n",
        "üëâ Esempio:\n",
        "\n",
        "survival = [\n",
        "  [1.0, 0.9, 0.7, 0.4],  # paziente 1\n",
        "  [1.0, 0.8, 0.5, 0.2],  # paziente 2\n",
        "]\n",
        "‚Üí Il paziente 1 ha 40% di probabilit√† di essere vivo nel bin 4.\n",
        "\n",
        "üî∂ risk\n",
        "risk √® un singolo valore per paziente.\n",
        "\n",
        "risk = -torch.sum(survival, dim=1)\n",
        "Sommi tutta la curva di sopravvivenza (cio√®: quanto \"vive lungo i bin\") ‚Üí poi inverti il segno per avere:\n",
        "\n",
        "üü¢ valore pi√π alto = paziente pi√π a rischio\n",
        "\n",
        "üîµ valore pi√π basso (cio√® pi√π negativo) = sopravvivenza alta\n",
        "\n",
        "üëâ Esempio:\n",
        "\n",
        "survival (paziente 1) = [1.0, 0.9, 0.7, 0.4] ‚Üí somma = 3.0 ‚Üí rischio = -3.0\n",
        "survival (paziente 2) = [1.0, 0.8, 0.5, 0.2] ‚Üí somma = 2.5 ‚Üí rischio = -2.5\n",
        "‚Üí Il paziente 2 ha rischio pi√π alto perch√© sopravvive meno.\n",
        "\n",
        "üìö log_dict[\"all_risk_scores\"] += risk.flatten().tolist()\n",
        "Stai costruendo una lista globale con tutti i punteggi di rischio.\n",
        "\n",
        "risk: √® un tensore tipo [[-3.0], [-2.5]]\n",
        "\n",
        ".flatten(): lo rende [ -3.0, -2.5 ]\n",
        "\n",
        ".tolist(): lo converte in lista Python\n",
        "\n",
        "Infine += lo aggiunge a log_dict[\"all_risk_scores\"], che conterr√† tutti i rischi per tutti i pazienti del dataset.\n",
        "\n",
        "\n",
        "NOTA: Durante il training usi il grafo. Ma quando fai logging, salvataggio, test, o plotting, non ti servono i gradienti: quindi scolleghi il tensore con .detach()."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 41,
      "metadata": {
        "execution": {
          "iopub.execute_input": "2024-12-13T17:14:05.396227Z",
          "iopub.status.busy": "2024-12-13T17:14:05.395868Z",
          "iopub.status.idle": "2024-12-13T17:14:05.405088Z",
          "shell.execute_reply": "2024-12-13T17:14:05.404003Z",
          "shell.execute_reply.started": "2024-12-13T17:14:05.396194Z"
        },
        "id": "jCKIlQY-g5zj",
        "trusted": true
      },
      "outputs": [],
      "source": [
        "def step(net, batch, log_dict, task_type=\"Survival\", device=\"cuda\"): #Il modello produce predizioni dai dati in batch.\n",
        "    #net √® il modello (ad es. ABMIL_Multimodal)\n",
        "    #batch √® un dizionario con dati di input e target (da DataLoader)\n",
        "    #√® il dizionario creato con initialize_metrics_dict(), verr√† popolat\n",
        "    # task_type: \"Survival\" o \"Treatment_Response\"\n",
        "    #device: CPU o GPU\n",
        "    batch_data = batch['input'] #contiene le features del paziente: immagini WSI, dati genomici, ecc.\n",
        "    labels = batch['label'] #  check this casting --> l'evento target (es. tempo bin della morte\n",
        "    batch_data = {key: value.to(device) if isinstance(value, torch.Tensor) else value for key, value in batch_data.items()}\n",
        "    #Chiave (key): il nome del tipo di dato, es. \"wsi_features\" o \"genomic_features\"\n",
        "    #Valore (value): il tensore con i dati di quel tipo, per tutti i pazienti del batch\n",
        "\n",
        "    #√à una dictionary comprehension, cio√® un modo rapido per costruire un nuovo dizionario da uno esistente.\n",
        "    #Per ogni coppia (key, value):\n",
        "    #Se value √® un torch.Tensor, lo sposta sul device (CPU o GPU) con .to(device), Altrimenti, lo lascia com'√®\n",
        "    #Scopo: fare in modo che tutti i dati (tensori) siano sulla stessa GPU (o CPU) del modello\n",
        "    labels = labels.to(device) #Anche labels (cio√® i ground truth) devono essere spostati sullo stesso dispositivo per fare la loss senza errori.\n",
        "    #la roba sopra √® stata fatta per avere modello e dati sullo stesso dispositivo\n",
        "    if len(labels.shape) == 1: #Obiettivo: Questa riga controlla che labels abbia la giusta forma (shape) per essere processata dalla rete o dalla funzione di loss.\n",
        "        #Se labels.shape √® ad esempio (8,), significa che hai un tensore monodimensionale con 8 valori (batch size = 8).\n",
        "        #Ma per alcune operazioni (come loss_function o il confronto con l'output del modello),\n",
        "        #  √® preferibile che i labels siano una matrice di forma (8, 1) ‚Äì cio√® 8 righe, 1 colonna.\n",
        "        labels = labels.reshape(-1,1)#-1 significa \"automaticamente calcolato in base alla dimensione originale\", e 1 √® la nuova seconda dimensione.\n",
        "        #üß† Perch√© √® importante?\n",
        "        #Perch√© l'output del modello in Survival ha forma (batch_size, n_bins), e alcune funzioni (tipo gather, loss, etc.) \n",
        "        # si aspettano che anche i target (label) siano bidimensionali per lavorare correttamente.\n",
        "\n",
        "\n",
        "\n",
        "    outputs = net(batch_data) #Qui si passa batch_data al modello (net) per ottenere l'output del modello\n",
        "\n",
        "    if task_type == \"Survival\": #In Survival, l'output sono i logits per ogni bin temporale, quindi: outputs.shape = (batch_size, n_bins)\n",
        "        censorships = batch['censorship'] #  check this casting --> qui vediamo i pazienti nel batch censurati o no\n",
        "        censorships = censorships.to(device)\n",
        "        if len(censorships.shape) == 1: #si garantisce una forma (batch_size, 1)\n",
        "            censorships = censorships.reshape(-1,1)\n",
        "        risk, survival = calculate_risk(outputs) # output.detach()? --> calculate_risk trasforma in probabilit√† di sopravvivenza e calcola un rischio aggregato per ogni paziente (pi√π rischio = muore prima)\n",
        "        log_dict[\"all_risk_scores\"]+=(risk.flatten().tolist()) #Salva il punteggio di rischio di ogni paziente. Spiegato sopra\n",
        "        log_dict[\"all_censorships\"]+=(censorships.detach().view(-1).tolist())\n",
        "        #Cosa fa: aggiunge l'indicatore di censura di ogni paziente del batch al log_dict.\n",
        "        #censorships: tensore tipo [ [1], [0], [1] ]\n",
        "        #.view(-1): lo rende [1, 0, 1]\n",
        "        #.tolist(): lo converte in lista Python\n",
        "        #+=: aggiunge alla lista complessiva\n",
        "        log_dict[\"all_event_times\"]+=(labels.detach().view(-1).tolist())\n",
        "        #Cosa fa: salva in lista i tempi di evento osservati o censurati per ogni paziente.\n",
        "        #Sono i valori reali (ground truth), cio√® quando √® successo o √® stato censurato il paziente.\n",
        "        log_dict[\"all_original_event_times\"]+=(batch[\"original_event_time\"].detach().view(-1).tolist())\n",
        "        # Cosa fa: salva il tempo di evento non discretizzato (es. 25.4 mesi, anzich√© bin 3). Utile per valutazioni o plot.\n",
        "        log_dict[\"survival_predictions\"] += outputs.detach().tolist()\n",
        "        #Cosa fa: salva direttamente i logits del modello (prima della sigmoid). Servono per ricostruire le predizioni poi (come nel loss o calcolo metrica).\n",
        "        if len(risk.shape) == 1:\n",
        "            risk = risk.reshape(-1,1)\n",
        "    elif task_type == \"Treatment_Response\": #Questo ramo gestisce il caso in cui invece di predire sopravvivenza, il modello fa classificazione (es. \"risponder√† al trattamento?\").\n",
        "        censorships = None #Nel caso classificazione, non si ha censura (√® solo per il caso survival), quindi metti None\n",
        "        treatment_response_predictions = torch.argmax(outputs.detach().cpu(), dim=1).float()\n",
        "        #outputs: √® l'output del modello, di forma (batch_size, n_classi)\n",
        "        #torch.argmax(..., dim=1): per ogni paziente, prendi la classe con logit pi√π alto\n",
        "        #.detach().cpu(): togli dal grafo e porta su CPU\n",
        "        #.float(): converti in float (potrebbe servire per metriche successive)\n",
        "\n",
        "        #Tutte le informazioni vengono aggiunte al log_dict per essere valutate dopo:\n",
        "        log_dict[\"treatment_response_predictions\"] += treatment_response_predictions.numpy().tolist() #Predizioni finali della rete (es. [1, 0, 1])\n",
        "        log_dict[\"treatment_response_logits\"] += outputs.detach().cpu().numpy().tolist() #Logits grezzi (non ancora softmax), usati ad esempio per calcolare AUC\n",
        "        log_dict[\"all_labels\"] += labels.detach().cpu().numpy().flatten().tolist() #Le etichette vere corrispondenti\n",
        "    else:\n",
        "        raise Exception(f\"{task_type} is not supported!\")\n",
        "    #Cos√¨ si sa chi √® chi e da quale dataset proviene ogni dato.\n",
        "    log_dict[\"patient_ids\"]+=(batch['patient_id'])\n",
        "    log_dict[\"dataset_name\"]+=(batch['dataset_name'])\n",
        "    return outputs, labels, censorships, log_dict"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 42,
      "metadata": {
        "execution": {
          "iopub.execute_input": "2024-12-13T17:14:09.125779Z",
          "iopub.status.busy": "2024-12-13T17:14:09.125415Z",
          "iopub.status.idle": "2024-12-13T17:14:09.152821Z",
          "shell.execute_reply": "2024-12-13T17:14:09.151842Z",
          "shell.execute_reply.started": "2024-12-13T17:14:09.125744Z"
        },
        "id": "wkmYu4dbg5zk",
        "trusted": true
      },
      "outputs": [],
      "source": [
        "def train(\n",
        "            net, #\tIl modello neurale (es. ABMIL_Multimodal) da addestrare.\n",
        "            train_dataloader, #\tDataLoader PyTorch per il training\n",
        "            eval_dataloader=None, #\t(opzionale) DataLoader per validation.\n",
        "            test_dataloader=None, #\t(opzionale) DataLoader per testing.\n",
        "            task_type=\"Survival\", #\tTipo di task: \"Survival\" o \"Treatment_Response\".\n",
        "            checkpoint=\"nn_model.pt\", #\tNome del file per salvare il miglior modello.\n",
        "            device=\"cuda\", #\t\"cuda\" o \"cpu\": dove caricare il modello e i tensori.\n",
        "            debug=True, #\tSe True, esegue solo un numero limitato di batch (per debug).\n",
        "            path=\".\", #\tCartella dove salvare file di log.\n",
        "            kfold=\"\", #\tStringa identificativa se usi la cross-validation.\n",
        "            best_model_criterion=\"highest\" #Criterio per salvare il modello: \"lowest\" (loss) o \"highest\" (C-index, AUC, ecc.).\n",
        "):\n",
        "    cudnn.benchmark = False #Stabilizza le prestazioni tra run diversi disabilitando l'ottimizzazione dinamica di cuDNN (utile per comparabilit√† tra esperimenti).\n",
        "    #Liste per salvare le loss ad ogni epoca, da usare per grafici o monitoraggio.\n",
        "    trainLoss = []\n",
        "    validationLoss = []\n",
        "    testLoss = []\n",
        "\n",
        "    lowest_val_loss = np.inf #tiene traccia della miglior loss di validazione.\n",
        "    highest_val_metric = 0 #tiene traccia del miglior C-index/AUC.\n",
        "    STOP = False #serve per interrompere il ciclo se non si migliora per molte epoche.\n",
        "\n",
        "    #Questi due servono a costruire i nomi dei file da salvare, distinguendo i risultati in caso di K-Fold Cross Validation.\n",
        "    df_fold_suffix = f\"_{kfold}\"\n",
        "    log_fold_string = f\"/{kfold}\"\n",
        "\n",
        "    for epoch in range(EPOCHS): #Ciclo principale che scorre per ogni epoca\n",
        "        if STOP: #Se il modello ha gi√† raggiunto la soglia di pazienza (PATIENCE), si ferma prima di completare tutte le epoche.\n",
        "            print(f'\\nSTOPPED at epoch {epoch}')\n",
        "            break\n",
        "        if kfold != \"\": #Stampa utile per distinguere i fold se stai facendo k-fold cross-validation.\n",
        "            print(f'\\nStarting training for {kfold}')\n",
        "        print('\\nStarting epoch {}/{}, LR = {}'.format(epoch + 1, EPOCHS, scheduler.get_last_lr())) #Log della nuova epoca con il learning rate corrente.\n",
        "        tloss = [] #per salvare le loss dei batch.\n",
        "\n",
        "        batch_numb = 0 #conta i batch visti.\n",
        "        log_dict = {} #raccoglie metriche (risk, labels, ecc.).\n",
        "        net.train() #Metti il modello in modalit√† training (abilita dropout, batch norm ecc.).\n",
        "        train_dataloader.dataset.dataset.set_sample(data_loader_config.sample) #Questo metodo probabilmente abilita o disabilita il campionamento interno (es. campionamento delle patch da immagini o gen\n",
        "        for idx, batch in tqdm(enumerate(train_dataloader)): #Scorri sui batch nel dataloader con barra di progresso.\n",
        "            if debug and batch_numb == DEBUG_BATCHES: #Se debug=True, ferma il ciclo dopo un numero limitato di batch (utile per testare velocemente il codice).\n",
        "                print(\"DEBUG_BATCHES value reached\")\n",
        "                break\n",
        "            if idx == 0: #All'inizio della prima iterazione, inizializza il dizionario in cui salverai tutte le predizioni, labels, risk score ecc.\n",
        "                log_dict = initialize_metrics_dict(task_type)#All'inizio della prima iterazione, inizializza il dizionario in cui salverai tutte le predizioni, labels, risk score ecc.\n",
        "\n",
        "            outputs, labels, censorships, log_dict = step(net, batch, log_dict, task_type, device)\n",
        "            #Chiamata alla funzione step(...) che:\n",
        "            #Passa il batch nel modello,\n",
        "            #Calcola predizioni (outputs)\n",
        "            #Estrae labels, censorships\n",
        "            #Calcola rischio e aggiorna log_dict\n",
        "\n",
        "\n",
        "            if MACHINE_BATCH_SIZE <= TARGET_BATCH_SIZE: #Si assicura che il mini-batch corrente (MACHINE_BATCH_SIZE) sia compatibile con il batch effettivo desiderato (TARGET_BATCH_SIZE).\n",
        "                # Serve per usare gradient accumulation (accumulare i gradienti su pi√π batch piccoli).\n",
        "\n",
        "                #Calcolo della loss\n",
        "                if task_type == \"Survival\": #Survival usa anche i dati di censura.\n",
        "                    loss = loss_function(outputs, labels, None, censorships)\n",
        "                elif task_type == \"Treatment_Response\": #Treatment Response √® una classificazione standard.\n",
        "                    loss = loss_function(outputs, labels.squeeze(1))#squeeze(1) serve per togliere la dimensione extra (es. da [B, 1] a [B]).\n",
        "                    #Nel task di classificazione (es. Treatment Response), la loss function (tipo CrossEntropyLoss) si aspetta che i target (labels) abbiano dimensione [B], cio√® un intero per ogni elemento del batch che indica la classe vera.\n",
        "                    #Tuttavia, spesso i dati arrivano con forma [B, 1] \n",
        "                else:\n",
        "                    raise Exception(f\"{task_type} is not supported!\")\n",
        "\n",
        "                loss = loss / NUM_ACCUMULATION_STEPS #La loss viene divisa per il numero di step di accumulo. In questo modo, \n",
        "                #quando faremo il .step(), il gradiente sar√† \"come se\" avessimo usato TARGET_BATCH_SIZE.\n",
        "                #Dividendo la loss per NUM_ACCUMULATION_STEPS (che √® 8), stai simulando il comportamento di:\n",
        "                #loss_batch8 = (loss_1 + loss_2 + ... + loss_8) / 8\n",
        "                #loss_batch8.backward()\n",
        "                #Ma lo fai distribuito su 8 passaggi distinti, invece di uno solo.\n",
        "                tloss.append(loss.item()*NUM_ACCUMULATION_STEPS) #Salva la loss effettiva per logging.\n",
        "                loss.backward() #Calcola i gradienti.\n",
        "                if ((idx + 1) % NUM_ACCUMULATION_STEPS == 0): #Ogni NUM_ACCUMULATION_STEPS, si fa effettivamente lo step dell‚Äôottimizzatore.\n",
        "                    torch.nn.utils.clip_grad_norm_(net.parameters(), max_norm=1) #per evitare esplosione dei gradienti.\n",
        "                    optimizer.step()\n",
        "                    optimizer.zero_grad()#per aggiornare i pesi e azzerare i gradienti.\n",
        "            else:\n",
        "                    raise Exception(\"MACHINE_BATCH_SIZE MUST BE EQUAL OR SMALLER THAN TARGET_BATCH_SIZE!!!\")\n",
        "            batch_numb += 1 #batch_numb += 1 semplicemente incrementa di 1 il contatore batch_numb ogni volta che viene elaborato un batch del train_dataloader.\n",
        "            #NOTA:  I gradienti non sono i pesi:\n",
        "            #Nel training di una rete neurale:\n",
        "            #I pesi (o parametri) sono ci√≤ che il modello impara.\n",
        "            #I gradienti sono solo strumenti per capire come modificare i pesi\n",
        "\n",
        "            #Ogni loss.backward() accumula i gradienti nei parametri del modello.\n",
        "            #Ogni optimizer.step() usa questi gradienti per aggiornare i pesi.\n",
        "            #Poi optimizer.zero_grad() azzera solo i gradienti, non i pesi!\n",
        "\n",
        "        scheduler.step() #Aggiorna il learning rate in base alla politica di scheduling definita (in precedenza con MultiStepLR).\n",
        "        #sarebbe quella roba del milestone []\n",
        "        tloss = np.array(tloss) #tloss raccoglie tutte le loss calcolate sui batch.\n",
        "        tloss = np.mean(tloss) #Qui le trasformi in NumPy, fai la media e la salvi in trainLoss.\n",
        "        trainLoss.append(tloss)\n",
        "        train_df = pd.DataFrame(log_dict) #log_dict √® stato popolato durante l'epoca con le predizioni e le etichette vere, Viene convertito in un DataFrame.\n",
        "        train_df.to_hdf(f\"{path}/train_df{df_fold_suffix}.h5\", key=\"df\", mode=\"w\")#Salvato in un file .h5 (HDF5) per persistenza.\n",
        "        train_metrics_dict = compute_metrics_df(train_df, task_type)\n",
        "        #Questa funzione prende in input il train_df (un DataFrame che contiene:\n",
        "        #ID pazienti,\n",
        "        #predizioni del modello (survival_predictions),\n",
        "        #tempi di evento,\n",
        "        #censorship, ecc\n",
        "        #Calcola le metriche di valutazione, come ad esempio il c-index e la loss, usando le funzioni che hai gi√† visto\n",
        "        # (compute_metrics, concordance_index_censored, ecc.).\n",
        "        #Restituisce un dizionario con le metriche, es:\n",
        "        '''\n",
        "        {\n",
        "            \"c-index\": 0.79,\n",
        "            \"Loss\": 1.52,\n",
        "            \"dataset1_c-index\": 0.78,\n",
        "            \"dataset1_Loss\": 1.60\n",
        "        }\n",
        "        '''\n",
        "        train_metrics_df = pd.DataFrame(train_metrics_dict, index=[0])#Converte quel dizionario in un DataFrame pandas,con una sola riga e \n",
        "        #le metriche come colonne. √à utile per salvare o visualizzare ordinatamente le metriche.\n",
        "        train_metrics_df.to_csv(f\"{path}/train_metrics{df_fold_suffix}.csv\")#Salva il DataFrame come file .csv sul disco\n",
        "        #Cos√¨ puoi tenere traccia delle metriche di ogni epoca durante l'addestramento.\n",
        "        #√à utile sia per analisi successive che per decidere quando fare early stopping o salvare il modello migliore.\n",
        "\n",
        "        # KaplanMeier_plot(log_dict, train_dataloader.dataset.dataset.bins.astype(int))\n",
        "        # predTime_vs_actualTime_confusionMatrix_plot(log_dict)\n",
        "        to_log = { # Costruzione del to_log dictionary\n",
        "                f'Epoch': epoch + 1, #L'epoca corrente (epoch + 1) ‚Äì perch√© epoch parte da 0.\n",
        "                f'LR': optimizer.param_groups[0]['lr'], #Il learning rate attuale del modello\n",
        "                # f'Train/Loss': tloss,\n",
        "                # f'Train/c-index': train_metrics_dict[\"c-index\"],\n",
        "                # f'Valid/Loss': vloss,\n",
        "                # f'Valid/c-index': val_metrics_dict[\"c-index\"],\n",
        "                }\n",
        "        for key, value in train_metrics_dict.items():\n",
        "            to_log[f'Train{log_fold_string}/{key}'] = value #Questo ciclo aggiunge al dizionario to_log tutte le metriche calcolate sul training se\n",
        "            #esempio:\n",
        "            # Se key √® \"c-index\" e log_fold_string √® \"/1\"\n",
        "            # Aggiunge:\n",
        "            #\"Train/1/c-index\": 0.79\n",
        "\n",
        "        train_dataloader.dataset.dataset.set_sample(data_loader_config.test_sample)#data_loader_config.test_sample √® un parametro booleano che indica se usare la modalit√† test per il sampling.\n",
        "        if eval_dataloader is not None: #Si controlla se √® stato passato un eval_dataloader. Se esiste, si procede alla validazione.\n",
        "            net.eval() #net.eval() mette il modello in modalit√† valutazione (disattiva dropout, batchnorm).\n",
        "            vloss = [] #raccoglie le perdite (loss) sui batch di validazione.\n",
        "            vlossWeights = [] #tiene conto del numero di campioni in ogni batch (per media pesata).\n",
        "            batch_numb = 0 #conta i batch processati.\n",
        "            with torch.inference_mode(): # Come torch.no_grad(), evita di costruire il grafo computazionale. √à pi√π veloce e meno pesante in memoria.\n",
        "                for idx, batch in tqdm(enumerate(eval_dataloader)): #Si processano tutti i batch del dataloader di validazione, con barra di avanzamento.\n",
        "                    if debug and batch_numb == DEBUG_BATCHES: #Permette di interrompere anticipatamente il ciclo per debuggin\n",
        "                        break\n",
        "                    if idx == 0: # All'inizio si inizializza un log_dict per raccogliere i risultati.\n",
        "                        log_dict = initialize_metrics_dict(task_type)\n",
        "                    outputs, labels, censorships, log_dict = step(net, batch, log_dict, task_type, device)# Il batch viene passato al modello tramite step, che restituisce:\n",
        "                    #le predizioni (outputs),\n",
        "                    #le etichette (labels),\n",
        "                    #la censura (censorships) (solo per survival),\n",
        "                    #e aggiorna il log_dict.\n",
        "\n",
        "                    # La loss viene calcolata diversamente a seconda del tipo di task.\n",
        "                    if task_type == \"Survival\":\n",
        "                        loss = loss_function(outputs, labels, None, censorships)\n",
        "                    elif task_type == \"Treatment_Response\":\n",
        "                        loss = loss_function(outputs, labels.squeeze(1))\n",
        "                    else:\n",
        "                        raise Exception(f\"{task_type} is not supported!\")\n",
        "                    \n",
        "                    # Aggiunge la loss e la dimensione del batch per mediare correttamente dopo.\n",
        "                    if MACHINE_BATCH_SIZE <= TARGET_BATCH_SIZE:\n",
        "                        vloss.append(loss.detach().item())#loss √® un tensore. .detach() lo stacca dal grafo computazionale. .item() lo converte in un numero Python.\n",
        "                        #üëâ Serve per raccogliere il valore numerico della loss del batch.\n",
        "                    vlossWeights.append(batch[\"label\"].size(dim=0)) # Aggiunge la loss e la dimensione del batch per mediare correttamente dopo.\n",
        "                    #Ogni batch pu√≤ contenere un numero diverso di esempi (dim=0 √® la dimensione della batch). Qui salviamo quanti esempi ci sono nel batch.\n",
        "                    #Lo facciamo perch√® nel Dataloader relativo al validation abbiamo scritto s√¨ batch_size=batch_size ma anche drop_last=False quindi non scarta gli ultimi batch, anche se piccoli.\n",
        "                    #Inoltre, in validazione/test a volte si usa batch_size = 1 per valutare paziente per paziente (pi√π preciso per metriche come c-index).\n",
        "                    #Quindi perch√© serve vlossWeights?\n",
        "                    #Perch√© in validazione/test:\n",
        "                    #i batch possono avere dimensioni diverse\n",
        "                    #e vogliamo fare una media pesata delle loss per essere precisi.\n",
        "                    batch_numb += 1\n",
        "            vloss = np.array(vloss)\n",
        "            vloss = np.average(vloss, weights=vlossWeights)\n",
        "            # vloss = np.sum(vloss)\n",
        "            validationLoss.append(vloss)\n",
        "            val_df = pd.DataFrame(log_dict)\n",
        "            val_df.to_hdf(f\"{path}/val_df{df_fold_suffix}.h5\", key=\"df\", mode=\"w\")\n",
        "            val_metrics_dict = compute_metrics_df(val_df, task_type)\n",
        "            val_metrics_df = pd.DataFrame(val_metrics_dict, index=[0])\n",
        "            val_metrics_df.to_csv(f\"{path}/val_metrics{df_fold_suffix}.csv\")\n",
        "            for key, value in val_metrics_dict.items():\n",
        "                to_log[f'Valid{log_fold_string}/{key}'] = value\n",
        "            vmetric = val_metrics_df[\"c-index\"].values[0]\n",
        "\n",
        "        #Valutare il modello sui dati di test, salvare le metriche e i log, senza aggiornare i pesi.\n",
        "        if test_dataloader is not None: #Controlla se √® stato fornito un test_dataloader. Se s√¨, esegue la fase di test.\n",
        "            net.eval()#mette il modello in modalit√† valutazione (disattiva dropout, batchnorm in training mode, ecc.).\n",
        "            ttloss = []\n",
        "            ttlossWeights = []\n",
        "            batch_numb = 0\n",
        "            with torch.inference_mode():#disattiva il tracciamento dei gradienti (ottimizzazione della memoria e della velocit√†).\n",
        "                for idx, batch in tqdm(enumerate(test_dataloader)):#Per ogni batch nel test_dataloader:\n",
        "                    if debug and batch_numb == DEBUG_BATCHES: \n",
        "                        break\n",
        "                    if idx == 0:#Inizializza log_dict se √® il primo batch.\n",
        "                        log_dict = initialize_metrics_dict(task_type)\n",
        "                    outputs, labels, censorships, log_dict = step(net, batch, log_dict, task_type, device)# ottiene outputs, labels, censorships e aggiorna log_dict.\n",
        "                    if task_type == \"Survival\":\n",
        "                        loss = loss_function(outputs, labels, None, censorships)\n",
        "                    elif task_type == \"Treatment_Response\":\n",
        "                        loss = loss_function(outputs, labels.squeeze(1))\n",
        "                    else:\n",
        "                        raise Exception(f\"{task_type} is not supported!\")\n",
        "                    if MACHINE_BATCH_SIZE <= TARGET_BATCH_SIZE:\n",
        "                        ttloss.append(loss.item())\n",
        "                    else:\n",
        "                        ttloss.append(loss.detach().mean().item())\n",
        "                    ttlossWeights.append(batch[\"label\"].size(dim=0))\n",
        "                    batch_numb += 1\n",
        "            ttloss = np.array(ttloss)\n",
        "            ttloss = np.average(ttloss, weights=ttlossWeights)\n",
        "            # ttloss = np.sum(ttloss)\n",
        "            testLoss.append(ttloss)\n",
        "            test_df = pd.DataFrame(log_dict)\n",
        "            test_df.to_hdf(f\"{path}/test_df{df_fold_suffix}.h5\", key=\"df\", mode=\"w\")\n",
        "            test_metrics_dict = compute_metrics_df(test_df, task_type)\n",
        "            test_metrics_df = pd.DataFrame(test_metrics_dict, index=[0])\n",
        "            test_metrics_df.to_csv(f\"{path}/test_metrics{df_fold_suffix}.csv\")\n",
        "\n",
        "            test_log = { #Crea un dizionario test_log con le metriche test.\n",
        "                # f'Test/Loss': ttloss,\n",
        "                # f'Test/c-index': test_metrics_dict[\"c-index\"],\n",
        "                }\n",
        "            for key, value in test_metrics_dict.items():\n",
        "                test_log[f'Test{log_fold_string}/{key}'] = value\n",
        "\n",
        "            to_log.update(test_log)\n",
        "            # if task_type == \"Treatment_Response\":\n",
        "            #     plot_to_log = {\n",
        "            #         f\"Train{log_fold_string}/Confusion_Matrix\": wandb.Image(train_confusion_matrix),\n",
        "            #     }\n",
        "            #     if eval_dataloader is not None:\n",
        "            #         plot_to_log[f\"Valid{log_fold_string}/Confusion_Matrix\"] = wandb.Image(val_confusion_matrix)\n",
        "            #     if test_dataloader is not None:\n",
        "            #         plot_to_log[f\"Test{log_fold_string}/Confusion_Matrix\"] = wandb.Image(test_confusion_matrix)\n",
        "            #     to_log.update(plot_to_log)\n",
        "\n",
        "\n",
        "        # wandb.log(to_log)\n",
        "        print(f\"EPOCH {epoch+1}\\n\")\n",
        "        for k, v in to_log.items():\n",
        "            pad = ' '.join(['' for _ in range(25-len(k))])\n",
        "            print(f\"{k}:{pad} {v}\", flush=True)\n",
        "\n",
        "\n",
        "        # Early stopping\n",
        "        if eval_dataloader is not None: #Dopo ogni epoca, se si sta usando un eval_dataloader, si valuta il modello sui dati di validazione.\n",
        "            if best_model_criterion == \"lowest\": #Significa che stiamo monitorando la val_loss e vogliamo salvare il modello quando √® pi√π bassa di tutte le epoche precedenti.\n",
        "                if vloss < lowest_val_loss: #Se la validazione attuale ha una loss inferiore al minimo osservato:\n",
        "                    lowest_val_loss = vloss #Si aggiorna lowest_val_loss\n",
        "                    patience_counter = 0 #Si azzera il patience_counter (contatore della pazienza)\n",
        "                    lowest_val_loss_epoch = epoch + 1#Si registra l‚Äôepoca in cui √® stato raggiunto il minimo\n",
        "                    print(\n",
        "                        f\"############################################ New lowest_val_loss reached: {lowest_val_loss} #########################\")\n",
        "                    if kfold != \"\":\n",
        "                        checkpoint_splitted = checkpoint.split(\".\")#Il modello net viene salvato nel file checkpoint\n",
        "                        checkpoint = f\"{checkpoint_splitted[0]}{df_fold_suffix}.pt\"#Se si usa un K-fold, il nome del file viene personalizzato con il numero del fold\n",
        "                    torch.save(net, checkpoint)#Per ogni metrica in val_metrics_dict, viene stampata la nuova metrica valida pi√π bassa\n",
        "                    # wandb.run.summary[\"Lowest_Validation_Loss/Epoch\"] = lowest_val_loss_epoch\n",
        "                    # wandb.run.summary[\"Lowest_Validation_Loss/Validation_Loss\"] = lowest_val_loss\n",
        "                    # wandb.run.summary[\"Lowest_Validation_Loss/Validation_c-index\"] = val_metrics_dict[\"c-index\"],\n",
        "                    for key, value in val_metrics_dict.items():\n",
        "                        # wandb.run.summary[f\"Lowest_Validation_Loss/Valid{log_fold_string}/{key}\"] = value\n",
        "                        print(f\"Lowest_Validation_Loss/Valid{log_fold_string}/{key}: {value}\")\n",
        "                    # # wandb.run.summary[\"Lowest_Validation_Loss/Validation_KM\"] = val_metrics_dict[\"KM\"],\n",
        "\n",
        "                    #poi si salvano:\n",
        "                    train_df.to_hdf(f\"{path}/best_train_df{df_fold_suffix}.h5\", key=\"df\", mode=\"w\")# dataframe dei risultati del training\n",
        "                    train_metrics_df.to_csv(f\"{path}/best_train_metrics{df_fold_suffix}.csv\")\n",
        "                    val_df.to_hdf(f\"{path}/best_val_df{df_fold_suffix}.h5\", key=\"df\", mode=\"w\")#dataframe dei risultati di validazione\n",
        "                    val_metrics_df.to_csv(f\"{path}/best_val_metrics{df_fold_suffix}.csv\")\n",
        "            elif best_model_criterion == \"highest\":\n",
        "                if vmetric > highest_val_metric:\n",
        "                    highest_val_metric = vmetric\n",
        "                    patience_counter = 0\n",
        "                    lowest_val_loss_epoch = epoch + 1\n",
        "                    print(\n",
        "                        f\"############################################ New highest_val_metric reached: {highest_val_metric} #########################\")\n",
        "                    if kfold != \"\":\n",
        "                        checkpoint_splitted = checkpoint.split(\".\")\n",
        "                        checkpoint = f\"{checkpoint_splitted[0]}{df_fold_suffix}.pt\"\n",
        "                    torch.save(net, checkpoint)\n",
        "                    # wandb.run.summary[\"Lowest_Validation_Loss/Epoch\"] = lowest_val_loss_epoch\n",
        "                    # wandb.run.summary[\"Lowest_Validation_Loss/Validation_Loss\"] = lowest_val_loss\n",
        "                    # wandb.run.summary[\"Lowest_Validation_Loss/Validation_c-index\"] = val_metrics_dict[\"c-index\"],\n",
        "                    for key, value in val_metrics_dict.items():\n",
        "                        # wandb.run.summary[f\"Lowest_Validation_Loss/Valid{log_fold_string}/{key}\"] = value\n",
        "                        print(f\"Lowest_Validation_Loss/Valid{log_fold_string}/{key}: {value}\")\n",
        "                    # # wandb.run.summary[\"Lowest_Validation_Loss/Validation_KM\"] = val_metrics_dict[\"KM\"],\n",
        "                    train_df.to_hdf(f\"{path}/best_train_df{df_fold_suffix}.h5\", key=\"df\", mode=\"w\")\n",
        "                    train_metrics_df.to_csv(f\"{path}/best_train_metrics{df_fold_suffix}.csv\")\n",
        "                    val_df.to_hdf(f\"{path}/best_val_df{df_fold_suffix}.h5\", key=\"df\", mode=\"w\")\n",
        "                    val_metrics_df.to_csv(f\"{path}/best_val_metrics{df_fold_suffix}.csv\")\n",
        "            else:\n",
        "                raise Exception(f\"{best_model_criterion} is not supported!\")\n",
        "\n",
        "            if patience_counter == PATIENCE:\n",
        "                print(f\"End of training phase - Patience threshold reached\\nWeights Restored from Lowest val_loss epoch: {lowest_val_loss_epoch}\\nlowest_val_loss: {lowest_val_loss}\")\n",
        "                STOP = True\n",
        "            else:\n",
        "                patience_counter += 1"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 43,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "torch.cuda.is_available(): True\n",
            "torch.version.cuda: 12.1\n",
            "Device usato: cuda\n"
          ]
        }
      ],
      "source": [
        "print(\"torch.cuda.is_available():\", torch.cuda.is_available())\n",
        "print(\"torch.version.cuda:\", torch.version.cuda)\n",
        "print(\"Device usato:\", device)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-cRj6Aqag5zk"
      },
      "source": [
        "# Train the model!"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "execution": {
          "iopub.execute_input": "2024-12-13T17:37:53.499436Z",
          "iopub.status.busy": "2024-12-13T17:37:53.499033Z",
          "iopub.status.idle": "2024-12-13T17:43:42.194202Z",
          "shell.execute_reply": "2024-12-13T17:43:42.19314Z",
          "shell.execute_reply.started": "2024-12-13T17:37:53.499394Z"
        },
        "id": "hCnXRgKdg5zl",
        "trusted": true
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "selected_model:  ABMIL_Multimodal\n",
            "\n",
            "Starting epoch 1/10, LR = [0.001]\n"
          ]
        },
        {
          "ename": "",
          "evalue": "",
          "output_type": "error",
          "traceback": [
            "\u001b[1;31mThe Kernel crashed while executing code in the current cell or a previous cell. \n",
            "\u001b[1;31mPlease review the code in the cell(s) to identify a possible cause of the failure. \n",
            "\u001b[1;31mClick <a href='https://aka.ms/vscodeJupyterKernelCrash'>here</a> for more info. \n",
            "\u001b[1;31mView Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
          ]
        }
      ],
      "source": [
        "print(\"selected_model: \", selected_model)\n",
        "train(\n",
        "      net,\n",
        "      train_dataloader,\n",
        "      val_dataloader,\n",
        "      test_dataloader,\n",
        "      checkpoint=\"best_model.pt\",\n",
        "      device=device,\n",
        "      debug=True,\n",
        "      best_model_criterion=\"highest\", # highest for highest validation metric, lowest for lowest validation loss\n",
        "     )"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Questa funzione KaplanMeier serve a visualizzare la curva di sopravvivenza per due gruppi di pazienti (alto rischio vs basso rischio) e verificare statisticamente se c‚Äô√® una differenza tra di loro\n",
        "\n",
        "üß† Il rischio come complemento alla sopravvivenza\n",
        "In modelli di analisi di sopravvivenza, il rischio √® spesso definito come:\n",
        "\n",
        "üîª Maggiore rischio ‚Üí minore probabilit√† di sopravvivere (curva KM che decresce pi√π in fretta)\n",
        "üî∫ Minore rischio ‚Üí maggiore probabilit√† di sopravvivere (curva KM che resta alta a lungo)\n",
        "\n",
        "üìà Cosa rappresenta la curva Kaplan-Meier?\n",
        "Le curve Kaplan-Meier che vedi (blu e arancione) sono stimate a posteriori: cio√® non sono direttamente il risultato del modello.\n",
        "\n",
        "Il modello fa la predizione ‚Üí i pazienti vengono divisi in due gruppi ‚Üí poi si calcola la probabilit√† empirica di sopravvivenza nel tempo per ciascun gruppo.\n",
        "\n",
        "In sintesi: il modello predice il rischio, e da l√¨ noi costruiamo curve di sopravvivenza usando metodi statistici.\n",
        "\n",
        "\n",
        " Perch√© si usa la mediana per dividere in gruppi?\n",
        "√à una scelta robusta e non arbitraria. Non richiede di fissare soglie soggettive.\n",
        "\n",
        "Permette di generare due gruppi bilanciati, in media (non sempre, ma spesso!).\n",
        "\n",
        "Serve a valutare se il modello produce una graduazione coerente del rischio: i pazienti che il modello considera ad alto rischio muoiono davvero prima?\n",
        "\n",
        "‚ö†Ô∏è Il test non valuta se la soglia √® clinicamente utile, ma se l‚Äôordinamento appreso dal modello ha senso.\n",
        "\n",
        "‚ö†Ô∏è Quali sono i limiti di questo approccio?\n",
        "Distribuzione sbilanciata:\n",
        "\n",
        "Se tutte le predizioni sono molto simili (es. tutte tra 0.4 e 0.6), allora la separazione sar√† debole, e non clinicamente utile.\n",
        "\n",
        "Non considera la censura:\n",
        "\n",
        "Il log-rank test lavora bene solo se il numero di eventi (decessi osservati) √® adeguato nei due gruppi.\n",
        "\n",
        "Non valuta la calibrazione:\n",
        "\n",
        "Un modello pu√≤ separare bene i gruppi ma sovra- o sotto-stimare il rischio assoluto.\n",
        "\n",
        "\n",
        "ChatGPT ha detto:\n",
        "Esatto! Il c-index √® strettamente collegato al discorso sulle curve di Kaplan-Meier perch√© entrambi valutano la capacit√† del modello di:\n",
        "\n",
        "discriminare correttamente tra pazienti ad alto e basso rischio,\n",
        "\n",
        "ma lo fanno con approcci diversi:\n",
        "\n",
        "üî¢ C-index\n",
        "√à una metrica numerica globale.\n",
        "\n",
        "Valuta quante coppie di pazienti sono ordinate correttamente: se il paziente A muore prima del paziente B, il modello dovrebbe dare a A un rischio pi√π alto.\n",
        "\n",
        "Pi√π √® alto, meglio il modello sa ordinare i pazienti.\n",
        "\n",
        "üìà Kaplan-Meier\n",
        "√à una visualizzazione statistica, non una metrica.\n",
        "\n",
        "Suddivide i pazienti in gruppi (es. alto vs basso rischio) usando le predizioni del modello.\n",
        "\n",
        "Mostra visivamente se questi gruppi differiscono in modo statisticamente significativo nella loro sopravvivenza.\n",
        "\n",
        "Usa anche il log-rank test per valutare la significativit√† della separazione.\n",
        "\n",
        "Quindi:\n",
        "\n",
        "Il c-index √® un numero che ti dice quanto il modello sa \"ordinare\".\n",
        "\n",
        "La Kaplan-Meier ti dice \"ok, questa suddivisione √® anche clinicamente significativa?\"\n",
        "\n",
        "Sono complementari: il primo √® globale, il secondo mostra la separazione effettiva su una soglia (es. mediana del rischio)."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "execution": {
          "iopub.execute_input": "2024-12-13T17:20:03.827647Z",
          "iopub.status.busy": "2024-12-13T17:20:03.827283Z",
          "iopub.status.idle": "2024-12-13T17:20:03.835738Z",
          "shell.execute_reply": "2024-12-13T17:20:03.834772Z",
          "shell.execute_reply.started": "2024-12-13T17:20:03.827615Z"
        },
        "id": "694KYXv3g5zl",
        "trusted": true
      },
      "outputs": [],
      "source": [
        "def KaplanMeier(input_df):\n",
        "    df = pd.DataFrame({\n",
        "        \"time\": input_df['all_original_event_times']/365.0, #tempo dell‚Äôevento in anni (era in giorni).\n",
        "        \"event\": input_df['all_censorships'], #1 se censurato, 0 se evento osservato.\n",
        "        \"risk_score\": input_df['all_risk_scores'] #score di rischio calcolato dal modello.\n",
        "    })\n",
        "\n",
        "    # Step 2: Invert the event indicator if needed\n",
        "    # If currently event=1 means censored and event=0 means event occurred:\n",
        "    # KaplanMeierFitter expects 1 for event_occurred and 0 for censored.\n",
        "    df['event_observed'] = 1 - df['event']\n",
        "\n",
        "    # Step 3: Categorize the risk_score into two groups--> Divide i pazienti in due gruppi con il 50% ciascuno:\n",
        "    df['risk_group'] = pd.qcut(df['risk_score'], 2, labels=[\"Low\", \"High\"])\n",
        "\n",
        "    # Step 4: Fit the Kaplan-Meier curves for each group\n",
        "    kmf = KaplanMeierFitter()\n",
        "\n",
        "    plt.figure(figsize=(10, 6))\n",
        "    for group in df['risk_group'].unique(): #Per ogni gruppo (Low e High):\n",
        "        #Stima la curva di sopravvivenza\n",
        "        #La traccia sul grafico\n",
        "        mask = (df['risk_group'] == group) #rea una maschera booleana che seleziona solo i pazienti del gruppo corrente (es. solo \"Low\").\n",
        "        kmf.fit(\n",
        "            durations=df.loc[mask, 'time'], # I tempi di sopravvivenza dei pazienti del gruppo\n",
        "            event_observed=df.loc[mask, 'event_observed'],# Se l'evento √® stato osservato (1) o censurato (0)\n",
        "            label=f\"Risk: {group}\" # Etichetta che sar√† usata nella legenda del grafico\n",
        "        )\n",
        "        #Qui si stima la curva di sopravvivenza usando il modello di Kaplan-Meier, uno dei metodi standard nella survival analysis.\n",
        "        kmf.plot_survival_function(ci_show=True) #Traccia la curva di sopravvivenza stimata\n",
        "        #ci_show=True fa comparire le bande di confidenza (cio√®: l‚Äôincertezza sulla stima).\n",
        "\n",
        "    # Step 5: Perform a log-rank test between the two groups (Low vs High)\n",
        "    low_mask = (df['risk_group'] == \"Low\")\n",
        "    high_mask = (df['risk_group'] == \"High\")\n",
        "\n",
        "    results = logrank_test( #√à un test statistico che serve per confrontare due curve di sopravvivenza, In questo caso:\n",
        "        #Gruppo a basso rischio (\"Low\")\n",
        "        #Gruppo ad alto rischio (\"High\")\n",
        "        #Ti dice se la differenza tra le due curve √® statisticamente significativa.\n",
        "        durations_A=df.loc[low_mask, 'time'], # Tempi di sopravvivenza per il gruppo Low\n",
        "        durations_B=df.loc[high_mask, 'time'],# Tempi per il gruppo High\n",
        "        event_observed_A=df.loc[low_mask, 'event_observed'], #Chi √® morto / censurato nel gruppo Low\n",
        "        event_observed_B=df.loc[high_mask, 'event_observed']# Idem per il gruppo High\n",
        "        #Confronta le distribuzioni temporali degli eventi (es. morti) tra i due gruppi.\n",
        "        #Tiene conto del censoring.\n",
        "    )\n",
        "\n",
        "    p_value = results.p_value #Questo valore ti dice quanto √® probabile che le differenze tra le curve siano dovute al caso:\n",
        "    #üîΩ p < 0.05 ‚Üí le curve sono significativamente diverse ‚áí il tuo modello distingue bene tra Low e High risk\n",
        "    #üîº p ‚â• 0.05 ‚Üí non c'√® abbastanza evidenza statistica\n",
        "    print(\"Log-rank test p-value:\", p_value) #Ti aiuta a valutare visivamente la separazione tra i gruppi\n",
        "\n",
        "    #Se il tuo modello √® buono, il gruppo High dovrebbe avere una curva che scende pi√π rapidamente (cio√®: pi√π morti in meno tempo),\n",
        "    #  e il log-rank test dovrebbe dare p < 0.05.\n",
        "\n",
        "    # Step 6: Customize the plot and include p-value in the title\n",
        "    plt.title(f\"Kaplan-Meier Survival Curves by Risk Group\\nLog-rank p-value: {p_value:.4f}\")\n",
        "    plt.xlabel(\"Time (years)\")\n",
        "    plt.ylabel(\"Survival Probability\")\n",
        "    plt.legend(title='Risk Group')\n",
        "    plt.grid(True)\n",
        "    plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "La funzione evaluate serve per testare un modello gi√† addestrato, usando un DataLoader di test"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "execution": {
          "iopub.execute_input": "2024-12-13T17:20:07.670879Z",
          "iopub.status.busy": "2024-12-13T17:20:07.670361Z",
          "iopub.status.idle": "2024-12-13T17:20:07.685678Z",
          "shell.execute_reply": "2024-12-13T17:20:07.684603Z",
          "shell.execute_reply.started": "2024-12-13T17:20:07.670822Z"
        },
        "id": "relh3cRWg5zl",
        "trusted": true
      },
      "outputs": [],
      "source": [
        "def evaluate(net, test_dataloader, task_type=\"Survival\", checkpoint=None, device=\"cuda\", best=False, path=\".\", kfold=\"\"):\n",
        "    cudnn.benchmark = False\n",
        "    print(\"test\")\n",
        "    #Queste righe servono a preparare i suffissi per salvare i file specifici del fold (se stai usando K-Fold cross-validation).\n",
        "    df_fold_suffix = f\"_{kfold}\" \n",
        "    log_fold_string = f\"/{kfold}\"\n",
        "    if best:\n",
        "        if kfold != \"\": #Carica il modello salvato se vuoi valutare il \"migliore\" (best=True). Altrimenti usa quello gi√† in memoria.\n",
        "            checkpoint_splitted = checkpoint.split(\".\")\n",
        "            checkpoint = f\"{checkpoint_splitted[0]}{df_fold_suffix}.pt\"\n",
        "        net = torch.load(checkpoint)\n",
        "        print(\"\\n Evalate best model\")\n",
        "    else:\n",
        "        net = net\n",
        "        print(\"\\n Evalate last model\")\n",
        "\n",
        "    net = net.to(device)\n",
        "    net.eval() #Mette il modello in modalit√† valutazione e disattiva il calcolo dei gradienti (pi√π veloce e usa meno memoria).\n",
        "    tloss = []\n",
        "    tlossWeights = []\n",
        "    with torch.inference_mode():\n",
        "        for idx, batch  in enumerate(test_dataloader): #Per ogni batch nel test_dataloader:\n",
        "            if idx == 0:\n",
        "                    log_dict = initialize_metrics_dict(task_type)#Inizializza un dizionario (log_dict) in cui salvi tutte le predizioni, i valori reali, le censurazioni, ecc.\n",
        "            # batch_data = torch.squeeze(batch_data, 0)\n",
        "            outputs, labels, censorships, log_dict = step(net, batch, log_dict, task_type, device)#Chiama step per ottenere predizioni\n",
        "            #e aggiorna log_dict.\n",
        "            #Fa forward pass sul batch. Calcola risk e survival se task_type == \"Survival\". Riempie log_dict con le informazioni utili.\n",
        "            if task_type == \"Survival\":\n",
        "                loss = loss_function(outputs, labels, None, censorships)\n",
        "            elif task_type == \"Treatment_Response\":\n",
        "                loss = loss_function(outputs, labels.squeeze(1))\n",
        "            else:\n",
        "                    raise Exception(f\"{task_type} is not supported!\")\n",
        "\n",
        "            if MACHINE_BATCH_SIZE <= TARGET_BATCH_SIZE: #In genere, se MACHINE_BATCH_SIZE √® minore o uguale al target (quello simulato), si salva la loss direttamente.\n",
        "                tloss.append(loss.item())\n",
        "            else:\n",
        "                tloss.append(loss.detach().mean().item()) #Altrimenti si fa la media della loss per batch.\n",
        "            tlossWeights.append(batch[\"label\"].size(dim=0))#Salva quanti esempi ci sono nel batch, per fare poi una media ponderata delle loss.\n",
        "\n",
        "    tloss = np.array(tloss) #rasforma la lista tloss, che contiene le loss calcolate per ciascun batch, in un array NumPy\n",
        "    tloss = np.average(tloss, weights=tlossWeights) #Ogni loss √® pesata per il numero di esempi nel batch corrispondente (preso da tlossWeights).\n",
        "    test_df = pd.DataFrame(log_dict)#Trasforma il log_dict in un DataFrame pandas, con tutte le informazioni raccolte nei vari batch:(risk_scores, event_times, censorships, patient_ids, ecc.)\n",
        "    test_metrics_dict = compute_metrics_df(test_df, task_type)\n",
        "\n",
        "    if best: #Serve per decidere se valutare il miglior modello (quello salvato con prestazioni migliori in validazione) o solo l‚Äôultimo modello allenato.\n",
        "\n",
        "        # wandb.run.summary[\"Lowest_Validation_Loss/Test_Loss\"] = tloss\n",
        "        # wandb.run.summary[\"Lowest_Validation_Loss/Test_c-index\"] = test_metrics_dict[\"c-index\"]\n",
        "        for key, value in test_metrics_dict.items():\n",
        "                # wandb.run.summary[f\"Lowest_Validation_Loss/Test{log_fold_string}/{key}\"] = value\n",
        "                print(f\"Lowest_Validation_Loss/Test{log_fold_string}/{key}: {value}\")#Stampa le metriche ottenute sul set di test (es. c-index) con la dicitura \"Lowest_Validation_Loss/Test...\" per chiarezza.\n",
        "        test_df.to_hdf(f\"{path}/best_test_df{df_fold_suffix}.h5\", key=\"df\", mode=\"w\")#Salva il DataFrame dei risultati (test_df) su disco in formato HDF5 (binario, adatto a dati strutturati):\n",
        "        KaplanMeier(test_df)#Genera e mostra la curva di Kaplan-Meier per testare se il modello ha separato bene i pazienti in gruppi di rischio (Low vs High).\n",
        "        test_metrics_df = pd.DataFrame(test_metrics_dict, index=[0]) #Converte il dizionario delle metriche in un DataFrame, utile per salvarlo in formato leggibile/tabellare.\n",
        "        test_metrics_df.to_csv(f\"{path}/best_test_metrics{df_fold_suffix}.csv\") #Salva le metriche calcolate in un file .csv chiamato best_test_metrics_{kfold}.csv, per analisi o logging successivo.\n",
        "        # if task_type == \"Treatment_Response\":\n",
        "        #     test_confusion_matrix = accuracy_confusionMatrix_plot(log_dict, test_metrics_df)\n",
        "    else:\n",
        "        for key, value in test_metrics_dict.items(): #Stampa a video tutte le metriche calcolate sul test set (es. c-index, loss...), \n",
        "            #usando la dicitura \"Last_Epoch_Model/Test...\" per indicare chiaramente che si riferiscono all‚Äôultimo modello.\n",
        "                # wandb.run.summary[f\"Last_Epoch_Model/Test{log_fold_string}/{key}\"] = value\n",
        "                print(f\"Last_Epoch_Model/Test{log_fold_string}/{key}: {value}\")\n",
        "        test_df.to_hdf(f\"{path}/last_epoch_test_df{df_fold_suffix}.h5\", key=\"df\", mode=\"w\")\n",
        "        KaplanMeier(test_df)\n",
        "        test_metrics_df = pd.DataFrame(test_metrics_dict, index=[0])\n",
        "        test_metrics_df.to_csv(f\"{path}/last_epoch_test_metrics{df_fold_suffix}.csv\")\n",
        "        # if task_type == \"Treatment_Response\":\n",
        "        #     test_confusion_matrix = accuracy_confusionMatrix_plot(log_dict, test_metrics_df)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "z_F5VwbRg5zl"
      },
      "source": [
        "# Evaluate last and best model!"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "execution": {
          "iopub.execute_input": "2024-12-13T17:44:01.52546Z",
          "iopub.status.busy": "2024-12-13T17:44:01.52508Z",
          "iopub.status.idle": "2024-12-13T17:44:04.644175Z",
          "shell.execute_reply": "2024-12-13T17:44:04.643195Z",
          "shell.execute_reply.started": "2024-12-13T17:44:01.525423Z"
        },
        "id": "T44EK387g5zm",
        "trusted": true
      },
      "outputs": [],
      "source": [
        "evaluate(net, test_dataloader, task_type=\"Survival\", checkpoint=None, device=device, best=False, path=\".\", kfold=\"\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "execution": {
          "iopub.execute_input": "2024-12-13T17:44:21.477242Z",
          "iopub.status.busy": "2024-12-13T17:44:21.476868Z",
          "iopub.status.idle": "2024-12-13T17:44:24.613581Z",
          "shell.execute_reply": "2024-12-13T17:44:24.612571Z",
          "shell.execute_reply.started": "2024-12-13T17:44:21.477205Z"
        },
        "id": "MzLfO0EYg5zm",
        "trusted": true
      },
      "outputs": [],
      "source": [
        "evaluate(net, test_dataloader, task_type=\"Survival\", checkpoint=\"best_model.pt\", device=device, best=True, path=\".\", kfold=\"\")"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kaggle": {
      "accelerator": "gpu",
      "dataSources": [],
      "dockerImageVersionId": 30804,
      "isGpuEnabled": true,
      "isInternetEnabled": true,
      "language": "python",
      "sourceType": "notebook"
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.18"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
